import os
from pathlib import Path
import logging
import pandas as pd
from dotenv import load_dotenv

import mlflow
import mlflow.sklearn

from pycaret.regression import (
    setup,
    compare_models,
    pull,
    finalize_model,
    save_model,
)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Configuraci√≥n de logging
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


def load_data(path: Path) -> pd.DataFrame:
    """Carga el dataset desde una ruta dada."""
    if not path.exists():
        raise FileNotFoundError(f"Archivo no encontrado: {path}")
    return pd.read_csv(path)


def prepare_data(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """Separa caracter√≠sticas (X) y variable objetivo (y)."""
    drop_cols = [
        'Unnamed: 0', 'state_alpha', 'county_code', 'stationTriplet',
        'stationId', 'name', 'lat_centroid', 'lon_centroid', 'unit_desc'
    ]
    X = df.drop(columns=drop_cols + ['Value'], errors='ignore')
    y = df['Value']
    return X, y


def run_experiment(
    X: pd.DataFrame,
    y: pd.Series,
    config: dict,
    experiment_name: str
) -> tuple:
    """
    Ejecuta un experimento de PyCaret con la configuraci√≥n dada.
    Retorna el modelo final y el leaderboard resultante.
    """
    # Habilitar autolog de scikit-learn en MLflow
    mlflow.sklearn.autolog()  # autolog registra hiperpar√°metros, m√©tricas y artefactos autom√°ticamente :contentReference[oaicite:3]{index=3}

    # Concatenar X e y para pasarlos a setup()
    df_exp = pd.concat([X, y.rename("target")], axis=1)

    # Setup sin silent (eliminado en PyCaret 3.x) y con configuraci√≥n completa
    setup(
        data=df_exp,
        target="target",
        log_experiment=config['log_experiment'],
        experiment_name=experiment_name,
        log_plots=True,
        remove_outliers=config['outliers'],
        normalize=config['normalize'],
        rare_to_value=0.05 if config['rare'] else None,
        remove_multicollinearity=config['multicol'],
        multicollinearity_threshold=0.9,
        pca=config['pca'],
        pca_components=0.95
    )  # silent ya no existe en PyCaret 3.x :contentReference[oaicite:4]{index=4}

    # Ejecutar y finalizar modelo dentro de un run de MLflow
    with mlflow.start_run(run_name=experiment_name, nested=True):
        best_model = compare_models(sort='RMSE', verbose=False)
        final_model = finalize_model(best_model)

    leaderboard = pull()  # extrae m√©tricas del √∫ltimo experimento :contentReference[oaicite:5]{index=5}
    return final_model, leaderboard


def save_results(
    model,
    leaderboard: pd.DataFrame,
    base_dir: Path,
    best_models_dir: Path,
    summary_path: Path
):
    """Guarda el modelo, el leaderboard completo y un resumen del mejor run."""
    # 1) Guardar pipeline final
    model_file = best_models_dir / "pycaret_best_model"
    save_model(model, model_file)

    # 2) Leaderboard completo
    leaderboard.to_csv(base_dir / "pycaret_leaderboard.csv", index=False)

    # 3) Resumen del mejor run
    best_row = leaderboard.iloc[0][['Model', 'MAE', 'MSE', 'RMSE', 'R2', 'MAPE']]
    best_row.to_frame().T.to_csv(summary_path, index=False)


def main():
    # Cargar variables de entorno
    load_dotenv()
    data_dir = os.getenv("SOURCE_DATA_DIRECTORY")
    if not data_dir:
        logger.error("La variable SOURCE_DATA_DIRECTORY no est√° definida en .env")
        return

    # 1) Carga de datos
    data_path = Path(data_dir) / "historical_monthly_climate_data_apr_sept_by_scan_stations_and_nasa_final.csv"
    df = load_data(data_path)
    X, y = prepare_data(df)

    # 2) Configuraci√≥n del experimento
    config = {
        'log_experiment': True,
        'outliers'     : False,
        'normalize'    : True,
        'rare'         : False,
        'multicol'     : False,
        'pca'          : False
    }
    experiment = f"auto_ml_norm_{config['normalize']}"

    # 3) Rutas de salida
    base_dir        = Path("results") / "models_results" / experiment
    best_models_dir = base_dir / "best_models"
    summary_path    = base_dir / "summary_best_models.csv"

    # Crear directorios necesarios
    best_models_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"Directorios creados en {base_dir}")  # uso de pathlib para creaci√≥n de carpetas 

    # 4) Ejecuci√≥n del experimento
    logger.info("üîß Iniciando experimento AutoML con PyCaret")
    best_model, leaderboard = run_experiment(X, y, config, experiment)

    # 5) Guardado de resultados
    logger.info("üíæ Guardando resultados")
    save_results(best_model, leaderboard, base_dir, best_models_dir, summary_path)
    logger.info("‚úÖ Proceso completado exitosamente")


if __name__ == "__main__":
    main()
