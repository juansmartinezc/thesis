2025-04-22 14:59:02,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 14:59:02,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 14:59:02,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 14:59:02,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:00:30,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:00:30,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:00:30,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:00:30,809:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:00:31,190:INFO:PyCaret RegressionExperiment
2025-04-22 15:00:31,190:INFO:Logging name: automl_experiment
2025-04-22 15:00:31,190:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-22 15:00:31,190:INFO:version 3.3.2
2025-04-22 15:00:31,190:INFO:Initializing setup()
2025-04-22 15:00:31,190:INFO:self.USI: 48da
2025-04-22 15:00:31,190:INFO:self._variable_keys: {'gpu_param', 'fold_generator', 'html_param', '_available_plots', 'USI', 'target_param', 'y', 'memory', 'X_test', 'X_train', 'logging_param', 'transform_target_param', 'log_plots_param', 'idx', 'exp_name_log', 'fold_shuffle_param', 'gpu_n_jobs_param', 'y_test', 'data', 'n_jobs_param', 'pipeline', '_ml_usecase', 'y_train', 'exp_id', 'fold_groups_param', 'seed', 'X'}
2025-04-22 15:00:31,190:INFO:Checking environment
2025-04-22 15:00:31,190:INFO:python_version: 3.11.9
2025-04-22 15:00:31,190:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-04-22 15:00:31,190:INFO:machine: AMD64
2025-04-22 15:00:31,199:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-22 15:00:31,208:INFO:Memory: svmem(total=51455639552, available=30232260608, percent=41.2, used=21223378944, free=30232260608)
2025-04-22 15:00:31,208:INFO:Physical Core: 8
2025-04-22 15:00:31,208:INFO:Logical Core: 16
2025-04-22 15:00:31,208:INFO:Checking libraries
2025-04-22 15:00:31,208:INFO:System:
2025-04-22 15:00:31,208:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-04-22 15:00:31,208:INFO:executable: C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Scripts\python.exe
2025-04-22 15:00:31,208:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-22 15:00:31,208:INFO:PyCaret required dependencies:
2025-04-22 15:00:32,940:INFO:                 pip: 24.0
2025-04-22 15:00:32,941:INFO:          setuptools: 65.5.0
2025-04-22 15:00:32,941:INFO:             pycaret: 3.3.2
2025-04-22 15:00:32,941:INFO:             IPython: 9.0.1
2025-04-22 15:00:32,941:INFO:          ipywidgets: 7.8.5
2025-04-22 15:00:32,941:INFO:                tqdm: 4.67.1
2025-04-22 15:00:32,941:INFO:               numpy: 1.26.4
2025-04-22 15:00:32,941:INFO:              pandas: 2.1.4
2025-04-22 15:00:32,941:INFO:              jinja2: 3.1.6
2025-04-22 15:00:32,941:INFO:               scipy: 1.11.4
2025-04-22 15:00:32,941:INFO:              joblib: 1.3.2
2025-04-22 15:00:32,941:INFO:             sklearn: 1.4.2
2025-04-22 15:00:32,941:INFO:                pyod: 2.0.4
2025-04-22 15:00:32,941:INFO:            imblearn: 0.13.0
2025-04-22 15:00:32,941:INFO:   category_encoders: 2.7.0
2025-04-22 15:00:32,941:INFO:            lightgbm: 4.6.0
2025-04-22 15:00:32,941:INFO:               numba: 0.61.0
2025-04-22 15:00:32,941:INFO:            requests: 2.32.3
2025-04-22 15:00:32,941:INFO:          matplotlib: 3.7.5
2025-04-22 15:00:32,941:INFO:          scikitplot: 0.3.7
2025-04-22 15:00:32,941:INFO:         yellowbrick: 1.5
2025-04-22 15:00:32,941:INFO:              plotly: 5.24.1
2025-04-22 15:00:32,941:INFO:    plotly-resampler: Not installed
2025-04-22 15:00:32,941:INFO:             kaleido: 0.2.1
2025-04-22 15:00:32,941:INFO:           schemdraw: 0.15
2025-04-22 15:00:32,941:INFO:         statsmodels: 0.14.4
2025-04-22 15:00:32,941:INFO:              sktime: 0.26.0
2025-04-22 15:00:32,941:INFO:               tbats: 1.1.3
2025-04-22 15:00:32,941:INFO:            pmdarima: 2.0.4
2025-04-22 15:00:32,941:INFO:              psutil: 7.0.0
2025-04-22 15:00:32,942:INFO:          markupsafe: 3.0.2
2025-04-22 15:00:32,942:INFO:             pickle5: Not installed
2025-04-22 15:00:32,942:INFO:         cloudpickle: 3.1.1
2025-04-22 15:00:32,942:INFO:         deprecation: 2.1.0
2025-04-22 15:00:32,942:INFO:              xxhash: 3.5.0
2025-04-22 15:00:32,942:INFO:           wurlitzer: Not installed
2025-04-22 15:00:32,942:INFO:PyCaret optional dependencies:
2025-04-22 15:00:38,355:INFO:                shap: 0.44.1
2025-04-22 15:00:38,355:INFO:           interpret: 0.6.10
2025-04-22 15:00:38,355:INFO:                umap: 0.5.7
2025-04-22 15:00:38,355:INFO:     ydata_profiling: 4.16.1
2025-04-22 15:00:38,355:INFO:  explainerdashboard: 0.4.8
2025-04-22 15:00:38,355:INFO:             autoviz: Not installed
2025-04-22 15:00:38,355:INFO:           fairlearn: 0.7.0
2025-04-22 15:00:38,355:INFO:          deepchecks: Not installed
2025-04-22 15:00:38,355:INFO:             xgboost: 3.0.0
2025-04-22 15:00:38,355:INFO:            catboost: 1.2.8
2025-04-22 15:00:38,355:INFO:              kmodes: 0.12.2
2025-04-22 15:00:38,355:INFO:             mlxtend: 0.23.4
2025-04-22 15:00:38,355:INFO:       statsforecast: 1.5.0
2025-04-22 15:00:38,355:INFO:        tune_sklearn: Not installed
2025-04-22 15:00:38,356:INFO:                 ray: Not installed
2025-04-22 15:00:38,356:INFO:            hyperopt: 0.2.7
2025-04-22 15:00:38,356:INFO:              optuna: 4.3.0
2025-04-22 15:00:38,356:INFO:               skopt: 0.10.2
2025-04-22 15:00:38,356:INFO:              mlflow: 2.21.3
2025-04-22 15:00:38,356:INFO:              gradio: 5.25.2
2025-04-22 15:00:38,356:INFO:             fastapi: 0.115.12
2025-04-22 15:00:38,356:INFO:             uvicorn: 0.34.2
2025-04-22 15:00:38,356:INFO:              m2cgen: 0.10.0
2025-04-22 15:00:38,356:INFO:           evidently: 0.4.40
2025-04-22 15:00:38,356:INFO:               fugue: 0.8.7
2025-04-22 15:00:38,356:INFO:           streamlit: Not installed
2025-04-22 15:00:38,356:INFO:             prophet: Not installed
2025-04-22 15:00:38,356:INFO:None
2025-04-22 15:00:38,356:INFO:Set up data.
2025-04-22 15:00:38,447:INFO:Set up folding strategy.
2025-04-22 15:00:38,447:INFO:Set up train/test split.
2025-04-22 15:00:38,503:INFO:Set up index.
2025-04-22 15:00:38,507:INFO:Assigning column types.
2025-04-22 15:00:38,571:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 15:00:38,571:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,732:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:38,735:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:38,841:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,850:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:38,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,002:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,004:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,005:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-22 15:00:39,009:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,014:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,163:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,166:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,171:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,327:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,329:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,330:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-22 15:00:39,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,446:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,490:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,492:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,502:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,654:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,656:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,657:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-22 15:00:39,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,816:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,819:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:00:39,979:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:39,982:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:39,982:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 15:00:40,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:40,138:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:40,140:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:40,257:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:00:40,300:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:40,303:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:40,303:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-22 15:00:40,459:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:40,462:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:40,619:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:40,621:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:40,624:INFO:Preparing preprocessing pipeline...
2025-04-22 15:00:40,624:INFO:Set up simple imputation.
2025-04-22 15:00:40,657:INFO:Set up encoding of categorical features.
2025-04-22 15:00:40,666:INFO:Set up column name cleaning.
2025-04-22 15:00:41,744:INFO:Finished creating preprocessing pipeline.
2025-04-22 15:00:41,752:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-04-22 15:00:41,752:INFO:Creating final display dataframe.
2025-04-22 15:00:42,784:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target             target
2                   Target type         Regression
3           Original data shape       (128603, 29)
4        Transformed data shape       (128603, 49)
5   Transformed train set shape        (90022, 49)
6    Transformed test set shape        (38581, 49)
7              Numeric features                 22
8          Categorical features                  6
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name  automl_experiment
21                          USI               48da
2025-04-22 15:00:42,951:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:42,954:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:43,113:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:00:43,116:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:00:43,117:INFO:setup() successfully completed in 11.93s...............
2025-04-22 15:00:43,117:INFO:Initializing compare_models()
2025-04-22 15:00:43,117:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-22 15:00:43,117:INFO:Checking exceptions
2025-04-22 15:00:43,148:INFO:Preparing display monitor
2025-04-22 15:00:43,151:INFO:Initializing Linear Regression
2025-04-22 15:00:43,151:INFO:Total runtime is 8.90493392944336e-06 minutes
2025-04-22 15:00:43,151:INFO:SubProcess create_model() called ==================================
2025-04-22 15:00:43,151:INFO:Initializing create_model()
2025-04-22 15:00:43,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:00:43,151:INFO:Checking exceptions
2025-04-22 15:00:43,151:INFO:Importing libraries
2025-04-22 15:00:43,151:INFO:Copying training dataset
2025-04-22 15:00:43,234:INFO:Defining folds
2025-04-22 15:00:43,234:INFO:Declaring metric variables
2025-04-22 15:00:43,235:INFO:Importing untrained model
2025-04-22 15:00:43,235:INFO:Linear Regression Imported successfully
2025-04-22 15:00:43,235:INFO:Starting cross validation
2025-04-22 15:00:43,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:00:51,838:INFO:Calculating mean and std
2025-04-22 15:00:51,840:INFO:Creating metrics dataframe
2025-04-22 15:00:51,841:INFO:Uploading results into container
2025-04-22 15:00:51,842:INFO:Uploading model into container now
2025-04-22 15:00:51,842:INFO:_master_model_container: 1
2025-04-22 15:00:51,842:INFO:_display_container: 2
2025-04-22 15:00:51,842:INFO:LinearRegression(n_jobs=-1)
2025-04-22 15:00:51,842:INFO:create_model() successfully completed......................................
2025-04-22 15:00:52,056:INFO:SubProcess create_model() end ==================================
2025-04-22 15:00:52,056:INFO:Creating metrics dataframe
2025-04-22 15:00:52,058:INFO:Initializing Lasso Regression
2025-04-22 15:00:52,058:INFO:Total runtime is 0.14846720298131305 minutes
2025-04-22 15:00:52,058:INFO:SubProcess create_model() called ==================================
2025-04-22 15:00:52,058:INFO:Initializing create_model()
2025-04-22 15:00:52,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:00:52,058:INFO:Checking exceptions
2025-04-22 15:00:52,058:INFO:Importing libraries
2025-04-22 15:00:52,058:INFO:Copying training dataset
2025-04-22 15:00:52,130:INFO:Defining folds
2025-04-22 15:00:52,130:INFO:Declaring metric variables
2025-04-22 15:00:52,130:INFO:Importing untrained model
2025-04-22 15:00:52,130:INFO:Lasso Regression Imported successfully
2025-04-22 15:00:52,131:INFO:Starting cross validation
2025-04-22 15:00:52,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:10,643:INFO:Calculating mean and std
2025-04-22 15:01:10,644:INFO:Creating metrics dataframe
2025-04-22 15:01:10,645:INFO:Uploading results into container
2025-04-22 15:01:10,646:INFO:Uploading model into container now
2025-04-22 15:01:10,646:INFO:_master_model_container: 2
2025-04-22 15:01:10,646:INFO:_display_container: 2
2025-04-22 15:01:10,646:INFO:Lasso(random_state=42)
2025-04-22 15:01:10,646:INFO:create_model() successfully completed......................................
2025-04-22 15:01:10,801:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:10,801:INFO:Creating metrics dataframe
2025-04-22 15:01:10,803:INFO:Initializing Ridge Regression
2025-04-22 15:01:10,803:INFO:Total runtime is 0.46087169249852494 minutes
2025-04-22 15:01:10,803:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:10,803:INFO:Initializing create_model()
2025-04-22 15:01:10,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:10,803:INFO:Checking exceptions
2025-04-22 15:01:10,803:INFO:Importing libraries
2025-04-22 15:01:10,803:INFO:Copying training dataset
2025-04-22 15:01:10,875:INFO:Defining folds
2025-04-22 15:01:10,875:INFO:Declaring metric variables
2025-04-22 15:01:10,875:INFO:Importing untrained model
2025-04-22 15:01:10,875:INFO:Ridge Regression Imported successfully
2025-04-22 15:01:10,875:INFO:Starting cross validation
2025-04-22 15:01:10,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:13,716:INFO:Calculating mean and std
2025-04-22 15:01:13,717:INFO:Creating metrics dataframe
2025-04-22 15:01:13,718:INFO:Uploading results into container
2025-04-22 15:01:13,719:INFO:Uploading model into container now
2025-04-22 15:01:13,719:INFO:_master_model_container: 3
2025-04-22 15:01:13,719:INFO:_display_container: 2
2025-04-22 15:01:13,719:INFO:Ridge(random_state=42)
2025-04-22 15:01:13,719:INFO:create_model() successfully completed......................................
2025-04-22 15:01:13,866:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:13,866:INFO:Creating metrics dataframe
2025-04-22 15:01:13,868:INFO:Initializing Elastic Net
2025-04-22 15:01:13,868:INFO:Total runtime is 0.5119671384493509 minutes
2025-04-22 15:01:13,868:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:13,868:INFO:Initializing create_model()
2025-04-22 15:01:13,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:13,868:INFO:Checking exceptions
2025-04-22 15:01:13,868:INFO:Importing libraries
2025-04-22 15:01:13,868:INFO:Copying training dataset
2025-04-22 15:01:13,942:INFO:Defining folds
2025-04-22 15:01:13,942:INFO:Declaring metric variables
2025-04-22 15:01:13,942:INFO:Importing untrained model
2025-04-22 15:01:13,943:INFO:Elastic Net Imported successfully
2025-04-22 15:01:13,943:INFO:Starting cross validation
2025-04-22 15:01:13,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:37,390:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:37,900:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.439e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,025:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+04, tolerance: 1.405e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,369:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.405e+04, tolerance: 1.403e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,404:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e+04, tolerance: 1.402e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+05, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,653:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,708:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.425e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,771:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e+04, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:38,935:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+04, tolerance: 1.400e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:01:39,018:INFO:Calculating mean and std
2025-04-22 15:01:39,019:INFO:Creating metrics dataframe
2025-04-22 15:01:39,020:INFO:Uploading results into container
2025-04-22 15:01:39,021:INFO:Uploading model into container now
2025-04-22 15:01:39,021:INFO:_master_model_container: 4
2025-04-22 15:01:39,021:INFO:_display_container: 2
2025-04-22 15:01:39,021:INFO:ElasticNet(random_state=42)
2025-04-22 15:01:39,021:INFO:create_model() successfully completed......................................
2025-04-22 15:01:39,193:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:39,193:INFO:Creating metrics dataframe
2025-04-22 15:01:39,194:INFO:Initializing Least Angle Regression
2025-04-22 15:01:39,195:INFO:Total runtime is 0.9340720931688944 minutes
2025-04-22 15:01:39,195:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:39,195:INFO:Initializing create_model()
2025-04-22 15:01:39,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:39,195:INFO:Checking exceptions
2025-04-22 15:01:39,195:INFO:Importing libraries
2025-04-22 15:01:39,195:INFO:Copying training dataset
2025-04-22 15:01:39,270:INFO:Defining folds
2025-04-22 15:01:39,270:INFO:Declaring metric variables
2025-04-22 15:01:39,270:INFO:Importing untrained model
2025-04-22 15:01:39,270:INFO:Least Angle Regression Imported successfully
2025-04-22 15:01:39,271:INFO:Starting cross validation
2025-04-22 15:01:39,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:41,458:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,460:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.247e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,461:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.767e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,462:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.334e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,462:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.274e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,463:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.168e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,464:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.009e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,465:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.259e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,465:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.932e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,465:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.135e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,466:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.011e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.600e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.254e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.174e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.154e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,468:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,468:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.169e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.124e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.151e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.810e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.895e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.019e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.733e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.527e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,493:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.772e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,494:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.377e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,495:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.216e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,496:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.430e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,499:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.653e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,499:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.615e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,499:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,500:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.298e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,500:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.229e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,500:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.058e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,500:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.365e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,500:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.360e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,502:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.173e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,502:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.071e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,502:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.781e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,502:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.593e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,503:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.555e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,503:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.375e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,543:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,545:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.140e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,547:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.721e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,547:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.340e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,548:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.654e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,549:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.736e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,549:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.306e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,550:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.557e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,551:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.134e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,551:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.008e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,552:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.448e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,552:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.193e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,553:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.097e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,553:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.628e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,554:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.128e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,554:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.083e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,554:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.043e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,555:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.618e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,555:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.561e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,555:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.016e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,556:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.673e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,556:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.332e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,556:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.518e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,556:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.370e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,557:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.306e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,558:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.748e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,558:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.456e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,558:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.165e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,559:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.874e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,560:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.583e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,680:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.520e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,682:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.391e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,685:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.067e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,685:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.165e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,687:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.354e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,688:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.478e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,688:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.096e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,689:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.291e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,690:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.227e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.180e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.173e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.131e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.845e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.295e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.076e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,780:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,783:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.015e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,785:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.878e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,787:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.934e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,789:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.778e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,792:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=3.334e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,794:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.416e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,796:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.992e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,797:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.088e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,799:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.558e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,800:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.142e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,800:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.141e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,800:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.140e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,801:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.087e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,801:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.086e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,801:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.066e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,803:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.052e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,803:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.909e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,804:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.155e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,804:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.338e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,804:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.645e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,805:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.448e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,805:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.256e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,805:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.966e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,805:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.899e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,805:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.606e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,806:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.504e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,857:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,860:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.828e+02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,860:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.378e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,862:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.876e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,862:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.733e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,863:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.715e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,865:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.132e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,866:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.726e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,866:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.554e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,867:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.449e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,867:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.277e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,867:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.656e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,868:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.896e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,869:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.492e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,869:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.484e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,870:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.157e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,870:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.675e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,870:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.601e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,870:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.381e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,871:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.122e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,871:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.119e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,871:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.091e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,872:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.157e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,872:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=7.118e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,873:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.166e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,873:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.721e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,873:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.711e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,874:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.544e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,874:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.428e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,874:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.201e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,875:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.946e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,875:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.561e-06, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,928:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.145e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.606e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,931:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.958e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,931:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.855e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,934:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.386e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,934:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.203e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,934:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.066e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,935:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.621e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,935:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.094e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,936:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.517e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,937:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.483e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,937:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.193e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,937:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.875e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,938:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.747e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,938:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.604e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,938:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.271e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,939:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.682e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,939:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.603e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,939:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.551e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,940:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.525e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,940:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.445e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,940:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.429e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,940:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.243e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,940:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.749e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,975:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.602e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,976:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.582e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,977:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.384e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,978:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.264e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,978:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.577e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,982:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.963e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,982:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.823e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,982:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.166e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,983:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.947e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,983:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.135e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,983:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.749e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,983:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.664e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,983:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.424e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,984:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.672e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,984:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.203e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:41,984:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.469e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,058:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.373e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,059:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.372e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,059:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.003e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,060:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.264e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.173e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.599e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.572e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.287e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.678e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.654e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.716e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.477e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.534e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.047e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.853e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,062:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.279e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,087:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,087:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.175e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,088:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.717e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,088:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.310e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,088:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.973e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,090:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.844e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,091:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.620e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,091:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.591e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,091:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.962e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,091:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.784e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,092:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.413e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,092:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.187e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,093:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.279e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,093:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.859e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,093:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.003e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.633e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.145e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.699e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.259e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.859e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.208e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,094:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.604e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:42,172:INFO:Calculating mean and std
2025-04-22 15:01:42,173:INFO:Creating metrics dataframe
2025-04-22 15:01:42,174:INFO:Uploading results into container
2025-04-22 15:01:42,174:INFO:Uploading model into container now
2025-04-22 15:01:42,174:INFO:_master_model_container: 5
2025-04-22 15:01:42,175:INFO:_display_container: 2
2025-04-22 15:01:42,175:INFO:Lars(random_state=42)
2025-04-22 15:01:42,175:INFO:create_model() successfully completed......................................
2025-04-22 15:01:42,326:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:42,327:INFO:Creating metrics dataframe
2025-04-22 15:01:42,328:INFO:Initializing Lasso Least Angle Regression
2025-04-22 15:01:42,328:INFO:Total runtime is 0.9863005479176838 minutes
2025-04-22 15:01:42,328:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:42,329:INFO:Initializing create_model()
2025-04-22 15:01:42,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:42,329:INFO:Checking exceptions
2025-04-22 15:01:42,329:INFO:Importing libraries
2025-04-22 15:01:42,329:INFO:Copying training dataset
2025-04-22 15:01:42,401:INFO:Defining folds
2025-04-22 15:01:42,401:INFO:Declaring metric variables
2025-04-22 15:01:42,401:INFO:Importing untrained model
2025-04-22 15:01:42,402:INFO:Lasso Least Angle Regression Imported successfully
2025-04-22 15:01:42,402:INFO:Starting cross validation
2025-04-22 15:01:42,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:44,507:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,511:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.526e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,513:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.681e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,514:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.446e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,514:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.092e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,516:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.660e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,517:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.406e+01, previous alpha=5.200e+00, with an active set of 17 regressors.
  warnings.warn(

2025-04-22 15:01:44,600:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=2.031e+00, previous alpha=1.152e+00, with an active set of 21 regressors.
  warnings.warn(

2025-04-22 15:01:44,664:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,666:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.426e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,667:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.362e+01, previous alpha=2.899e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:01:44,762:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=9.705e+01, previous alpha=9.696e+01, with an active set of 5 regressors.
  warnings.warn(

2025-04-22 15:01:44,864:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,868:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.685e+02, previous alpha=2.933e+01, with an active set of 12 regressors.
  warnings.warn(

2025-04-22 15:01:44,905:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,908:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.532e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,909:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.744e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,909:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,910:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.009e+01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:44,910:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.616e+01, previous alpha=9.605e+00, with an active set of 14 regressors.
  warnings.warn(

2025-04-22 15:01:44,955:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=7.797e+01, previous alpha=7.593e+01, with an active set of 7 regressors.
  warnings.warn(

2025-04-22 15:01:45,112:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.159e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:45,123:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.295e+01, previous alpha=2.787e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:01:45,162:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:01:45,164:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.623e+01, previous alpha=4.556e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:01:45,240:INFO:Calculating mean and std
2025-04-22 15:01:45,241:INFO:Creating metrics dataframe
2025-04-22 15:01:45,242:INFO:Uploading results into container
2025-04-22 15:01:45,242:INFO:Uploading model into container now
2025-04-22 15:01:45,243:INFO:_master_model_container: 6
2025-04-22 15:01:45,243:INFO:_display_container: 2
2025-04-22 15:01:45,243:INFO:LassoLars(random_state=42)
2025-04-22 15:01:45,243:INFO:create_model() successfully completed......................................
2025-04-22 15:01:45,392:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:45,393:INFO:Creating metrics dataframe
2025-04-22 15:01:45,394:INFO:Initializing Orthogonal Matching Pursuit
2025-04-22 15:01:45,394:INFO:Total runtime is 1.037397491931915 minutes
2025-04-22 15:01:45,395:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:45,395:INFO:Initializing create_model()
2025-04-22 15:01:45,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:45,395:INFO:Checking exceptions
2025-04-22 15:01:45,395:INFO:Importing libraries
2025-04-22 15:01:45,395:INFO:Copying training dataset
2025-04-22 15:01:45,464:INFO:Defining folds
2025-04-22 15:01:45,465:INFO:Declaring metric variables
2025-04-22 15:01:45,465:INFO:Importing untrained model
2025-04-22 15:01:45,465:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-22 15:01:45,465:INFO:Starting cross validation
2025-04-22 15:01:45,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:48,339:INFO:Calculating mean and std
2025-04-22 15:01:48,340:INFO:Creating metrics dataframe
2025-04-22 15:01:48,341:INFO:Uploading results into container
2025-04-22 15:01:48,341:INFO:Uploading model into container now
2025-04-22 15:01:48,341:INFO:_master_model_container: 7
2025-04-22 15:01:48,341:INFO:_display_container: 2
2025-04-22 15:01:48,342:INFO:OrthogonalMatchingPursuit()
2025-04-22 15:01:48,342:INFO:create_model() successfully completed......................................
2025-04-22 15:01:48,499:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:48,499:INFO:Creating metrics dataframe
2025-04-22 15:01:48,502:INFO:Initializing Bayesian Ridge
2025-04-22 15:01:48,502:INFO:Total runtime is 1.089187399546305 minutes
2025-04-22 15:01:48,502:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:48,502:INFO:Initializing create_model()
2025-04-22 15:01:48,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:48,502:INFO:Checking exceptions
2025-04-22 15:01:48,502:INFO:Importing libraries
2025-04-22 15:01:48,502:INFO:Copying training dataset
2025-04-22 15:01:48,574:INFO:Defining folds
2025-04-22 15:01:48,574:INFO:Declaring metric variables
2025-04-22 15:01:48,575:INFO:Importing untrained model
2025-04-22 15:01:48,575:INFO:Bayesian Ridge Imported successfully
2025-04-22 15:01:48,575:INFO:Starting cross validation
2025-04-22 15:01:48,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:53,438:INFO:Calculating mean and std
2025-04-22 15:01:53,439:INFO:Creating metrics dataframe
2025-04-22 15:01:53,440:INFO:Uploading results into container
2025-04-22 15:01:53,440:INFO:Uploading model into container now
2025-04-22 15:01:53,441:INFO:_master_model_container: 8
2025-04-22 15:01:53,441:INFO:_display_container: 2
2025-04-22 15:01:53,441:INFO:BayesianRidge()
2025-04-22 15:01:53,441:INFO:create_model() successfully completed......................................
2025-04-22 15:01:53,596:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:53,597:INFO:Creating metrics dataframe
2025-04-22 15:01:53,599:INFO:Initializing Passive Aggressive Regressor
2025-04-22 15:01:53,599:INFO:Total runtime is 1.1741373101870216 minutes
2025-04-22 15:01:53,599:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:53,599:INFO:Initializing create_model()
2025-04-22 15:01:53,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:53,599:INFO:Checking exceptions
2025-04-22 15:01:53,599:INFO:Importing libraries
2025-04-22 15:01:53,599:INFO:Copying training dataset
2025-04-22 15:01:53,666:INFO:Defining folds
2025-04-22 15:01:53,666:INFO:Declaring metric variables
2025-04-22 15:01:53,666:INFO:Importing untrained model
2025-04-22 15:01:53,667:INFO:Passive Aggressive Regressor Imported successfully
2025-04-22 15:01:53,667:INFO:Starting cross validation
2025-04-22 15:01:53,668:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:01:58,267:INFO:Calculating mean and std
2025-04-22 15:01:58,268:INFO:Creating metrics dataframe
2025-04-22 15:01:58,269:INFO:Uploading results into container
2025-04-22 15:01:58,269:INFO:Uploading model into container now
2025-04-22 15:01:58,270:INFO:_master_model_container: 9
2025-04-22 15:01:58,270:INFO:_display_container: 2
2025-04-22 15:01:58,270:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-22 15:01:58,270:INFO:create_model() successfully completed......................................
2025-04-22 15:01:58,420:INFO:SubProcess create_model() end ==================================
2025-04-22 15:01:58,420:INFO:Creating metrics dataframe
2025-04-22 15:01:58,422:INFO:Initializing Huber Regressor
2025-04-22 15:01:58,422:INFO:Total runtime is 1.2545286218325293 minutes
2025-04-22 15:01:58,422:INFO:SubProcess create_model() called ==================================
2025-04-22 15:01:58,422:INFO:Initializing create_model()
2025-04-22 15:01:58,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:01:58,422:INFO:Checking exceptions
2025-04-22 15:01:58,423:INFO:Importing libraries
2025-04-22 15:01:58,423:INFO:Copying training dataset
2025-04-22 15:01:58,492:INFO:Defining folds
2025-04-22 15:01:58,493:INFO:Declaring metric variables
2025-04-22 15:01:58,493:INFO:Importing untrained model
2025-04-22 15:01:58,493:INFO:Huber Regressor Imported successfully
2025-04-22 15:01:58,493:INFO:Starting cross validation
2025-04-22 15:01:58,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:02:10,492:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,035:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,036:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,355:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,374:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,388:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:11,445:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:12,245:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:12,272:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:02:12,342:INFO:Calculating mean and std
2025-04-22 15:02:12,342:INFO:Creating metrics dataframe
2025-04-22 15:02:12,344:INFO:Uploading results into container
2025-04-22 15:02:12,344:INFO:Uploading model into container now
2025-04-22 15:02:12,344:INFO:_master_model_container: 10
2025-04-22 15:02:12,344:INFO:_display_container: 2
2025-04-22 15:02:12,345:INFO:HuberRegressor()
2025-04-22 15:02:12,345:INFO:create_model() successfully completed......................................
2025-04-22 15:02:12,494:INFO:SubProcess create_model() end ==================================
2025-04-22 15:02:12,495:INFO:Creating metrics dataframe
2025-04-22 15:02:12,496:INFO:Initializing K Neighbors Regressor
2025-04-22 15:02:12,496:INFO:Total runtime is 1.4890931924184159 minutes
2025-04-22 15:02:12,496:INFO:SubProcess create_model() called ==================================
2025-04-22 15:02:12,497:INFO:Initializing create_model()
2025-04-22 15:02:12,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:02:12,497:INFO:Checking exceptions
2025-04-22 15:02:12,497:INFO:Importing libraries
2025-04-22 15:02:12,497:INFO:Copying training dataset
2025-04-22 15:02:12,565:INFO:Defining folds
2025-04-22 15:02:12,565:INFO:Declaring metric variables
2025-04-22 15:02:12,565:INFO:Importing untrained model
2025-04-22 15:02:12,566:INFO:K Neighbors Regressor Imported successfully
2025-04-22 15:02:12,566:INFO:Starting cross validation
2025-04-22 15:02:12,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:02:20,757:INFO:Calculating mean and std
2025-04-22 15:02:20,758:INFO:Creating metrics dataframe
2025-04-22 15:02:20,759:INFO:Uploading results into container
2025-04-22 15:02:20,760:INFO:Uploading model into container now
2025-04-22 15:02:20,760:INFO:_master_model_container: 11
2025-04-22 15:02:20,760:INFO:_display_container: 2
2025-04-22 15:02:20,760:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-22 15:02:20,760:INFO:create_model() successfully completed......................................
2025-04-22 15:02:20,909:INFO:SubProcess create_model() end ==================================
2025-04-22 15:02:20,909:INFO:Creating metrics dataframe
2025-04-22 15:02:20,910:INFO:Initializing Decision Tree Regressor
2025-04-22 15:02:20,910:INFO:Total runtime is 1.6293350815773007 minutes
2025-04-22 15:02:20,911:INFO:SubProcess create_model() called ==================================
2025-04-22 15:02:20,911:INFO:Initializing create_model()
2025-04-22 15:02:20,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:02:20,911:INFO:Checking exceptions
2025-04-22 15:02:20,911:INFO:Importing libraries
2025-04-22 15:02:20,911:INFO:Copying training dataset
2025-04-22 15:02:20,979:INFO:Defining folds
2025-04-22 15:02:20,979:INFO:Declaring metric variables
2025-04-22 15:02:20,979:INFO:Importing untrained model
2025-04-22 15:02:20,980:INFO:Decision Tree Regressor Imported successfully
2025-04-22 15:02:20,980:INFO:Starting cross validation
2025-04-22 15:02:20,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:02:25,142:INFO:Calculating mean and std
2025-04-22 15:02:25,143:INFO:Creating metrics dataframe
2025-04-22 15:02:25,144:INFO:Uploading results into container
2025-04-22 15:02:25,144:INFO:Uploading model into container now
2025-04-22 15:02:25,144:INFO:_master_model_container: 12
2025-04-22 15:02:25,145:INFO:_display_container: 2
2025-04-22 15:02:25,145:INFO:DecisionTreeRegressor(random_state=42)
2025-04-22 15:02:25,145:INFO:create_model() successfully completed......................................
2025-04-22 15:02:25,294:INFO:SubProcess create_model() end ==================================
2025-04-22 15:02:25,294:INFO:Creating metrics dataframe
2025-04-22 15:02:25,296:INFO:Initializing Random Forest Regressor
2025-04-22 15:02:25,296:INFO:Total runtime is 1.7024300456047055 minutes
2025-04-22 15:02:25,296:INFO:SubProcess create_model() called ==================================
2025-04-22 15:02:25,296:INFO:Initializing create_model()
2025-04-22 15:02:25,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:02:25,296:INFO:Checking exceptions
2025-04-22 15:02:25,297:INFO:Importing libraries
2025-04-22 15:02:25,297:INFO:Copying training dataset
2025-04-22 15:02:25,365:INFO:Defining folds
2025-04-22 15:02:25,365:INFO:Declaring metric variables
2025-04-22 15:02:25,365:INFO:Importing untrained model
2025-04-22 15:02:25,365:INFO:Random Forest Regressor Imported successfully
2025-04-22 15:02:25,365:INFO:Starting cross validation
2025-04-22 15:02:25,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:03:46,608:INFO:Calculating mean and std
2025-04-22 15:03:46,609:INFO:Creating metrics dataframe
2025-04-22 15:03:46,610:INFO:Uploading results into container
2025-04-22 15:03:46,611:INFO:Uploading model into container now
2025-04-22 15:03:46,611:INFO:_master_model_container: 13
2025-04-22 15:03:46,611:INFO:_display_container: 2
2025-04-22 15:03:46,611:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:03:46,611:INFO:create_model() successfully completed......................................
2025-04-22 15:03:46,820:INFO:SubProcess create_model() end ==================================
2025-04-22 15:03:46,820:INFO:Creating metrics dataframe
2025-04-22 15:03:46,822:INFO:Initializing Extra Trees Regressor
2025-04-22 15:03:46,822:INFO:Total runtime is 3.0611913243929543 minutes
2025-04-22 15:03:46,822:INFO:SubProcess create_model() called ==================================
2025-04-22 15:03:46,822:INFO:Initializing create_model()
2025-04-22 15:03:46,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:03:46,822:INFO:Checking exceptions
2025-04-22 15:03:46,822:INFO:Importing libraries
2025-04-22 15:03:46,822:INFO:Copying training dataset
2025-04-22 15:03:46,901:INFO:Defining folds
2025-04-22 15:03:46,901:INFO:Declaring metric variables
2025-04-22 15:03:46,902:INFO:Importing untrained model
2025-04-22 15:03:46,902:INFO:Extra Trees Regressor Imported successfully
2025-04-22 15:03:46,902:INFO:Starting cross validation
2025-04-22 15:03:46,904:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:04:51,180:INFO:Calculating mean and std
2025-04-22 15:04:51,181:INFO:Creating metrics dataframe
2025-04-22 15:04:51,183:INFO:Uploading results into container
2025-04-22 15:04:51,183:INFO:Uploading model into container now
2025-04-22 15:04:51,183:INFO:_master_model_container: 14
2025-04-22 15:04:51,184:INFO:_display_container: 2
2025-04-22 15:04:51,184:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:04:51,184:INFO:create_model() successfully completed......................................
2025-04-22 15:04:51,356:INFO:SubProcess create_model() end ==================================
2025-04-22 15:04:51,356:INFO:Creating metrics dataframe
2025-04-22 15:04:51,358:INFO:Initializing AdaBoost Regressor
2025-04-22 15:04:51,358:INFO:Total runtime is 4.1367946068445836 minutes
2025-04-22 15:04:51,358:INFO:SubProcess create_model() called ==================================
2025-04-22 15:04:51,358:INFO:Initializing create_model()
2025-04-22 15:04:51,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:04:51,358:INFO:Checking exceptions
2025-04-22 15:04:51,358:INFO:Importing libraries
2025-04-22 15:04:51,359:INFO:Copying training dataset
2025-04-22 15:04:51,437:INFO:Defining folds
2025-04-22 15:04:51,437:INFO:Declaring metric variables
2025-04-22 15:04:51,437:INFO:Importing untrained model
2025-04-22 15:04:51,438:INFO:AdaBoost Regressor Imported successfully
2025-04-22 15:04:51,438:INFO:Starting cross validation
2025-04-22 15:04:51,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:05:21,952:INFO:Calculating mean and std
2025-04-22 15:05:21,953:INFO:Creating metrics dataframe
2025-04-22 15:05:21,954:INFO:Uploading results into container
2025-04-22 15:05:21,955:INFO:Uploading model into container now
2025-04-22 15:05:21,955:INFO:_master_model_container: 15
2025-04-22 15:05:21,955:INFO:_display_container: 2
2025-04-22 15:05:21,955:INFO:AdaBoostRegressor(random_state=42)
2025-04-22 15:05:21,955:INFO:create_model() successfully completed......................................
2025-04-22 15:05:22,116:INFO:SubProcess create_model() end ==================================
2025-04-22 15:05:22,116:INFO:Creating metrics dataframe
2025-04-22 15:05:22,118:INFO:Initializing Gradient Boosting Regressor
2025-04-22 15:05:22,118:INFO:Total runtime is 4.649465004603067 minutes
2025-04-22 15:05:22,118:INFO:SubProcess create_model() called ==================================
2025-04-22 15:05:22,118:INFO:Initializing create_model()
2025-04-22 15:05:22,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:05:22,119:INFO:Checking exceptions
2025-04-22 15:05:22,119:INFO:Importing libraries
2025-04-22 15:05:22,119:INFO:Copying training dataset
2025-04-22 15:05:22,185:INFO:Defining folds
2025-04-22 15:05:22,185:INFO:Declaring metric variables
2025-04-22 15:05:22,185:INFO:Importing untrained model
2025-04-22 15:05:22,185:INFO:Gradient Boosting Regressor Imported successfully
2025-04-22 15:05:22,185:INFO:Starting cross validation
2025-04-22 15:05:22,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:05:54,523:INFO:Calculating mean and std
2025-04-22 15:05:54,523:INFO:Creating metrics dataframe
2025-04-22 15:05:54,525:INFO:Uploading results into container
2025-04-22 15:05:54,525:INFO:Uploading model into container now
2025-04-22 15:05:54,525:INFO:_master_model_container: 16
2025-04-22 15:05:54,525:INFO:_display_container: 2
2025-04-22 15:05:54,525:INFO:GradientBoostingRegressor(random_state=42)
2025-04-22 15:05:54,525:INFO:create_model() successfully completed......................................
2025-04-22 15:05:54,686:INFO:SubProcess create_model() end ==================================
2025-04-22 15:05:54,686:INFO:Creating metrics dataframe
2025-04-22 15:05:54,688:INFO:Initializing Extreme Gradient Boosting
2025-04-22 15:05:54,688:INFO:Total runtime is 5.192288517951964 minutes
2025-04-22 15:05:54,688:INFO:SubProcess create_model() called ==================================
2025-04-22 15:05:54,688:INFO:Initializing create_model()
2025-04-22 15:05:54,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:05:54,688:INFO:Checking exceptions
2025-04-22 15:05:54,688:INFO:Importing libraries
2025-04-22 15:05:54,688:INFO:Copying training dataset
2025-04-22 15:05:54,750:INFO:Defining folds
2025-04-22 15:05:54,751:INFO:Declaring metric variables
2025-04-22 15:05:54,751:INFO:Importing untrained model
2025-04-22 15:05:54,751:INFO:Extreme Gradient Boosting Imported successfully
2025-04-22 15:05:54,751:INFO:Starting cross validation
2025-04-22 15:05:54,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:05:59,741:INFO:Calculating mean and std
2025-04-22 15:05:59,742:INFO:Creating metrics dataframe
2025-04-22 15:05:59,743:INFO:Uploading results into container
2025-04-22 15:05:59,743:INFO:Uploading model into container now
2025-04-22 15:05:59,743:INFO:_master_model_container: 17
2025-04-22 15:05:59,743:INFO:_display_container: 2
2025-04-22 15:05:59,744:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-04-22 15:05:59,744:INFO:create_model() successfully completed......................................
2025-04-22 15:05:59,895:INFO:SubProcess create_model() end ==================================
2025-04-22 15:05:59,895:INFO:Creating metrics dataframe
2025-04-22 15:05:59,897:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 15:05:59,897:INFO:Total runtime is 5.27911273241043 minutes
2025-04-22 15:05:59,897:INFO:SubProcess create_model() called ==================================
2025-04-22 15:05:59,897:INFO:Initializing create_model()
2025-04-22 15:05:59,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:05:59,897:INFO:Checking exceptions
2025-04-22 15:05:59,897:INFO:Importing libraries
2025-04-22 15:05:59,897:INFO:Copying training dataset
2025-04-22 15:05:59,959:INFO:Defining folds
2025-04-22 15:05:59,959:INFO:Declaring metric variables
2025-04-22 15:05:59,959:INFO:Importing untrained model
2025-04-22 15:05:59,960:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 15:05:59,960:INFO:Starting cross validation
2025-04-22 15:05:59,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:06:05,227:INFO:Calculating mean and std
2025-04-22 15:06:05,228:INFO:Creating metrics dataframe
2025-04-22 15:06:05,229:INFO:Uploading results into container
2025-04-22 15:06:05,230:INFO:Uploading model into container now
2025-04-22 15:06:05,230:INFO:_master_model_container: 18
2025-04-22 15:06:05,230:INFO:_display_container: 2
2025-04-22 15:06:05,230:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:06:05,230:INFO:create_model() successfully completed......................................
2025-04-22 15:06:05,429:INFO:SubProcess create_model() end ==================================
2025-04-22 15:06:05,429:INFO:Creating metrics dataframe
2025-04-22 15:06:05,431:INFO:Initializing CatBoost Regressor
2025-04-22 15:06:05,431:INFO:Total runtime is 5.371339058876036 minutes
2025-04-22 15:06:05,431:INFO:SubProcess create_model() called ==================================
2025-04-22 15:06:05,431:INFO:Initializing create_model()
2025-04-22 15:06:05,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:06:05,431:INFO:Checking exceptions
2025-04-22 15:06:05,431:INFO:Importing libraries
2025-04-22 15:06:05,431:INFO:Copying training dataset
2025-04-22 15:06:05,495:INFO:Defining folds
2025-04-22 15:06:05,495:INFO:Declaring metric variables
2025-04-22 15:06:05,495:INFO:Importing untrained model
2025-04-22 15:06:05,495:INFO:CatBoost Regressor Imported successfully
2025-04-22 15:06:05,495:INFO:Starting cross validation
2025-04-22 15:06:05,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:06:49,505:INFO:Calculating mean and std
2025-04-22 15:06:49,506:INFO:Creating metrics dataframe
2025-04-22 15:06:49,508:INFO:Uploading results into container
2025-04-22 15:06:49,508:INFO:Uploading model into container now
2025-04-22 15:06:49,508:INFO:_master_model_container: 19
2025-04-22 15:06:49,508:INFO:_display_container: 2
2025-04-22 15:06:49,509:INFO:<catboost.core.CatBoostRegressor object at 0x00000252E5AF9E50>
2025-04-22 15:06:49,509:INFO:create_model() successfully completed......................................
2025-04-22 15:06:49,711:INFO:SubProcess create_model() end ==================================
2025-04-22 15:06:49,711:INFO:Creating metrics dataframe
2025-04-22 15:06:49,713:INFO:Initializing Dummy Regressor
2025-04-22 15:06:49,713:INFO:Total runtime is 6.1093810041745495 minutes
2025-04-22 15:06:49,714:INFO:SubProcess create_model() called ==================================
2025-04-22 15:06:49,714:INFO:Initializing create_model()
2025-04-22 15:06:49,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000252E594F210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:06:49,714:INFO:Checking exceptions
2025-04-22 15:06:49,714:INFO:Importing libraries
2025-04-22 15:06:49,714:INFO:Copying training dataset
2025-04-22 15:06:49,782:INFO:Defining folds
2025-04-22 15:06:49,782:INFO:Declaring metric variables
2025-04-22 15:06:49,782:INFO:Importing untrained model
2025-04-22 15:06:49,782:INFO:Dummy Regressor Imported successfully
2025-04-22 15:06:49,783:INFO:Starting cross validation
2025-04-22 15:06:49,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:06:52,743:INFO:Calculating mean and std
2025-04-22 15:06:52,744:INFO:Creating metrics dataframe
2025-04-22 15:06:52,745:INFO:Uploading results into container
2025-04-22 15:06:52,746:INFO:Uploading model into container now
2025-04-22 15:06:52,746:INFO:_master_model_container: 20
2025-04-22 15:06:52,746:INFO:_display_container: 2
2025-04-22 15:06:52,746:INFO:DummyRegressor()
2025-04-22 15:06:52,746:INFO:create_model() successfully completed......................................
2025-04-22 15:06:52,913:INFO:SubProcess create_model() end ==================================
2025-04-22 15:06:52,914:INFO:Creating metrics dataframe
2025-04-22 15:06:52,917:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 15:06:52,918:INFO:Initializing create_model()
2025-04-22 15:06:52,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252DB72C990>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:06:52,918:INFO:Checking exceptions
2025-04-22 15:06:52,919:INFO:Importing libraries
2025-04-22 15:06:52,919:INFO:Copying training dataset
2025-04-22 15:06:52,990:INFO:Defining folds
2025-04-22 15:06:52,990:INFO:Declaring metric variables
2025-04-22 15:06:52,990:INFO:Importing untrained model
2025-04-22 15:06:52,990:INFO:Declaring custom model
2025-04-22 15:06:52,991:INFO:Extra Trees Regressor Imported successfully
2025-04-22 15:06:52,992:INFO:Cross validation set to False
2025-04-22 15:06:52,992:INFO:Fitting Model
2025-04-22 15:06:59,627:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:06:59,627:INFO:create_model() successfully completed......................................
2025-04-22 15:06:59,794:INFO:_master_model_container: 20
2025-04-22 15:06:59,794:INFO:_display_container: 2
2025-04-22 15:06:59,794:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:06:59,795:INFO:compare_models() successfully completed......................................
2025-04-22 15:06:59,802:INFO:Initializing save_model()
2025-04-22 15:06:59,803:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=42), model_name=results\models_results\auto_ml\pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-22 15:06:59,803:INFO:Adding model into prep_pipe
2025-04-22 15:07:00,099:INFO:results\models_results\auto_ml\pycaret_best_model.pkl saved in current working directory
2025-04-22 15:07:00,107:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=42))])
2025-04-22 15:07:00,107:INFO:save_model() successfully completed......................................
2025-04-22 15:08:40,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:08:40,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:08:40,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:08:40,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 15:08:40,647:INFO:PyCaret RegressionExperiment
2025-04-22 15:08:40,647:INFO:Logging name: automl_experiment
2025-04-22 15:08:40,647:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-22 15:08:40,647:INFO:version 3.3.2
2025-04-22 15:08:40,648:INFO:Initializing setup()
2025-04-22 15:08:40,648:INFO:self.USI: f7ba
2025-04-22 15:08:40,648:INFO:self._variable_keys: {'X', 'y', 'USI', 'exp_name_log', 'X_test', '_ml_usecase', 'data', 'X_train', 'exp_id', 'gpu_n_jobs_param', 'y_test', 'memory', 'log_plots_param', 'gpu_param', 'fold_shuffle_param', 'seed', 'pipeline', 'y_train', 'idx', 'transform_target_param', '_available_plots', 'target_param', 'n_jobs_param', 'logging_param', 'html_param', 'fold_groups_param', 'fold_generator'}
2025-04-22 15:08:40,648:INFO:Checking environment
2025-04-22 15:08:40,648:INFO:python_version: 3.11.9
2025-04-22 15:08:40,648:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-04-22 15:08:40,648:INFO:machine: AMD64
2025-04-22 15:08:40,656:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-22 15:08:40,664:INFO:Memory: svmem(total=51455639552, available=30732292096, percent=40.3, used=20723347456, free=30732292096)
2025-04-22 15:08:40,664:INFO:Physical Core: 8
2025-04-22 15:08:40,664:INFO:Logical Core: 16
2025-04-22 15:08:40,664:INFO:Checking libraries
2025-04-22 15:08:40,665:INFO:System:
2025-04-22 15:08:40,665:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-04-22 15:08:40,665:INFO:executable: C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Scripts\python.exe
2025-04-22 15:08:40,665:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-22 15:08:40,665:INFO:PyCaret required dependencies:
2025-04-22 15:08:41,210:INFO:                 pip: 24.0
2025-04-22 15:08:41,210:INFO:          setuptools: 65.5.0
2025-04-22 15:08:41,210:INFO:             pycaret: 3.3.2
2025-04-22 15:08:41,210:INFO:             IPython: 9.0.1
2025-04-22 15:08:41,210:INFO:          ipywidgets: 7.8.5
2025-04-22 15:08:41,210:INFO:                tqdm: 4.67.1
2025-04-22 15:08:41,210:INFO:               numpy: 1.26.4
2025-04-22 15:08:41,210:INFO:              pandas: 2.1.4
2025-04-22 15:08:41,210:INFO:              jinja2: 3.1.6
2025-04-22 15:08:41,211:INFO:               scipy: 1.11.4
2025-04-22 15:08:41,211:INFO:              joblib: 1.3.2
2025-04-22 15:08:41,211:INFO:             sklearn: 1.4.2
2025-04-22 15:08:41,211:INFO:                pyod: 2.0.4
2025-04-22 15:08:41,211:INFO:            imblearn: 0.13.0
2025-04-22 15:08:41,211:INFO:   category_encoders: 2.7.0
2025-04-22 15:08:41,211:INFO:            lightgbm: 4.6.0
2025-04-22 15:08:41,211:INFO:               numba: 0.61.0
2025-04-22 15:08:41,211:INFO:            requests: 2.32.3
2025-04-22 15:08:41,211:INFO:          matplotlib: 3.7.5
2025-04-22 15:08:41,211:INFO:          scikitplot: 0.3.7
2025-04-22 15:08:41,211:INFO:         yellowbrick: 1.5
2025-04-22 15:08:41,211:INFO:              plotly: 5.24.1
2025-04-22 15:08:41,211:INFO:    plotly-resampler: Not installed
2025-04-22 15:08:41,211:INFO:             kaleido: 0.2.1
2025-04-22 15:08:41,211:INFO:           schemdraw: 0.15
2025-04-22 15:08:41,211:INFO:         statsmodels: 0.14.4
2025-04-22 15:08:41,211:INFO:              sktime: 0.26.0
2025-04-22 15:08:41,211:INFO:               tbats: 1.1.3
2025-04-22 15:08:41,211:INFO:            pmdarima: 2.0.4
2025-04-22 15:08:41,211:INFO:              psutil: 7.0.0
2025-04-22 15:08:41,211:INFO:          markupsafe: 3.0.2
2025-04-22 15:08:41,211:INFO:             pickle5: Not installed
2025-04-22 15:08:41,211:INFO:         cloudpickle: 3.1.1
2025-04-22 15:08:41,211:INFO:         deprecation: 2.1.0
2025-04-22 15:08:41,211:INFO:              xxhash: 3.5.0
2025-04-22 15:08:41,211:INFO:           wurlitzer: Not installed
2025-04-22 15:08:41,211:INFO:PyCaret optional dependencies:
2025-04-22 15:08:44,053:INFO:                shap: 0.44.1
2025-04-22 15:08:44,053:INFO:           interpret: 0.6.10
2025-04-22 15:08:44,053:INFO:                umap: 0.5.7
2025-04-22 15:08:44,053:INFO:     ydata_profiling: 4.16.1
2025-04-22 15:08:44,053:INFO:  explainerdashboard: 0.4.8
2025-04-22 15:08:44,053:INFO:             autoviz: Not installed
2025-04-22 15:08:44,053:INFO:           fairlearn: 0.7.0
2025-04-22 15:08:44,053:INFO:          deepchecks: Not installed
2025-04-22 15:08:44,053:INFO:             xgboost: 3.0.0
2025-04-22 15:08:44,053:INFO:            catboost: 1.2.8
2025-04-22 15:08:44,053:INFO:              kmodes: 0.12.2
2025-04-22 15:08:44,053:INFO:             mlxtend: 0.23.4
2025-04-22 15:08:44,053:INFO:       statsforecast: 1.5.0
2025-04-22 15:08:44,053:INFO:        tune_sklearn: Not installed
2025-04-22 15:08:44,053:INFO:                 ray: Not installed
2025-04-22 15:08:44,053:INFO:            hyperopt: 0.2.7
2025-04-22 15:08:44,053:INFO:              optuna: 4.3.0
2025-04-22 15:08:44,053:INFO:               skopt: 0.10.2
2025-04-22 15:08:44,053:INFO:              mlflow: 2.21.3
2025-04-22 15:08:44,053:INFO:              gradio: 5.25.2
2025-04-22 15:08:44,053:INFO:             fastapi: 0.115.12
2025-04-22 15:08:44,053:INFO:             uvicorn: 0.34.2
2025-04-22 15:08:44,053:INFO:              m2cgen: 0.10.0
2025-04-22 15:08:44,053:INFO:           evidently: 0.4.40
2025-04-22 15:08:44,053:INFO:               fugue: 0.8.7
2025-04-22 15:08:44,053:INFO:           streamlit: Not installed
2025-04-22 15:08:44,053:INFO:             prophet: Not installed
2025-04-22 15:08:44,053:INFO:None
2025-04-22 15:08:44,053:INFO:Set up data.
2025-04-22 15:08:44,143:INFO:Set up folding strategy.
2025-04-22 15:08:44,143:INFO:Set up train/test split.
2025-04-22 15:08:44,201:INFO:Set up index.
2025-04-22 15:08:44,205:INFO:Assigning column types.
2025-04-22 15:08:44,270:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 15:08:44,270:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,275:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,279:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,431:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:44,433:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:44,453:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,457:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,610:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:44,613:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:44,613:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-22 15:08:44,618:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,622:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,770:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:44,773:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:44,777:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,782:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,894:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:44,937:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:44,940:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:44,940:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-22 15:08:44,949:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,097:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,099:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,257:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,259:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,260:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-22 15:08:45,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,423:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,426:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,583:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,585:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,586:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 15:08:45,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,743:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,745:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 15:08:45,915:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:45,918:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:45,918:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-22 15:08:46,076:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:46,078:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:46,241:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:46,243:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:46,245:INFO:Preparing preprocessing pipeline...
2025-04-22 15:08:46,245:INFO:Set up simple imputation.
2025-04-22 15:08:46,277:INFO:Set up encoding of categorical features.
2025-04-22 15:08:46,286:INFO:Set up column name cleaning.
2025-04-22 15:08:47,051:INFO:Finished creating preprocessing pipeline.
2025-04-22 15:08:47,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-04-22 15:08:47,059:INFO:Creating final display dataframe.
2025-04-22 15:08:48,041:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target             target
2                   Target type         Regression
3           Original data shape       (128603, 29)
4        Transformed data shape       (128603, 49)
5   Transformed train set shape        (90022, 49)
6    Transformed test set shape        (38581, 49)
7              Numeric features                 22
8          Categorical features                  6
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name  automl_experiment
21                          USI               f7ba
2025-04-22 15:08:48,211:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:48,214:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:48,374:INFO:Soft dependency imported: xgboost: 3.0.0
2025-04-22 15:08:48,377:INFO:Soft dependency imported: catboost: 1.2.8
2025-04-22 15:08:48,377:INFO:setup() successfully completed in 7.74s...............
2025-04-22 15:08:48,378:INFO:Initializing compare_models()
2025-04-22 15:08:48,378:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-04-22 15:08:48,378:INFO:Checking exceptions
2025-04-22 15:08:48,407:INFO:Preparing display monitor
2025-04-22 15:08:48,410:INFO:Initializing Linear Regression
2025-04-22 15:08:48,410:INFO:Total runtime is 0.0 minutes
2025-04-22 15:08:48,410:INFO:SubProcess create_model() called ==================================
2025-04-22 15:08:48,410:INFO:Initializing create_model()
2025-04-22 15:08:48,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:08:48,410:INFO:Checking exceptions
2025-04-22 15:08:48,410:INFO:Importing libraries
2025-04-22 15:08:48,410:INFO:Copying training dataset
2025-04-22 15:08:48,484:INFO:Defining folds
2025-04-22 15:08:48,484:INFO:Declaring metric variables
2025-04-22 15:08:48,484:INFO:Importing untrained model
2025-04-22 15:08:48,484:INFO:Linear Regression Imported successfully
2025-04-22 15:08:48,484:INFO:Starting cross validation
2025-04-22 15:08:48,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:08:56,931:INFO:Calculating mean and std
2025-04-22 15:08:56,932:INFO:Creating metrics dataframe
2025-04-22 15:08:56,934:INFO:Uploading results into container
2025-04-22 15:08:56,934:INFO:Uploading model into container now
2025-04-22 15:08:56,934:INFO:_master_model_container: 1
2025-04-22 15:08:56,934:INFO:_display_container: 2
2025-04-22 15:08:56,935:INFO:LinearRegression(n_jobs=-1)
2025-04-22 15:08:56,935:INFO:create_model() successfully completed......................................
2025-04-22 15:08:57,114:INFO:SubProcess create_model() end ==================================
2025-04-22 15:08:57,114:INFO:Creating metrics dataframe
2025-04-22 15:08:57,115:INFO:Initializing Lasso Regression
2025-04-22 15:08:57,116:INFO:Total runtime is 0.14509876569112143 minutes
2025-04-22 15:08:57,116:INFO:SubProcess create_model() called ==================================
2025-04-22 15:08:57,116:INFO:Initializing create_model()
2025-04-22 15:08:57,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:08:57,116:INFO:Checking exceptions
2025-04-22 15:08:57,116:INFO:Importing libraries
2025-04-22 15:08:57,116:INFO:Copying training dataset
2025-04-22 15:08:57,188:INFO:Defining folds
2025-04-22 15:08:57,188:INFO:Declaring metric variables
2025-04-22 15:08:57,188:INFO:Importing untrained model
2025-04-22 15:08:57,188:INFO:Lasso Regression Imported successfully
2025-04-22 15:08:57,188:INFO:Starting cross validation
2025-04-22 15:08:57,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:15,593:INFO:Calculating mean and std
2025-04-22 15:09:15,594:INFO:Creating metrics dataframe
2025-04-22 15:09:15,595:INFO:Uploading results into container
2025-04-22 15:09:15,596:INFO:Uploading model into container now
2025-04-22 15:09:15,596:INFO:_master_model_container: 2
2025-04-22 15:09:15,596:INFO:_display_container: 2
2025-04-22 15:09:15,596:INFO:Lasso(random_state=42)
2025-04-22 15:09:15,596:INFO:create_model() successfully completed......................................
2025-04-22 15:09:15,755:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:15,755:INFO:Creating metrics dataframe
2025-04-22 15:09:15,757:INFO:Initializing Ridge Regression
2025-04-22 15:09:15,757:INFO:Total runtime is 0.45578523079554245 minutes
2025-04-22 15:09:15,757:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:15,757:INFO:Initializing create_model()
2025-04-22 15:09:15,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:15,757:INFO:Checking exceptions
2025-04-22 15:09:15,757:INFO:Importing libraries
2025-04-22 15:09:15,757:INFO:Copying training dataset
2025-04-22 15:09:15,827:INFO:Defining folds
2025-04-22 15:09:15,827:INFO:Declaring metric variables
2025-04-22 15:09:15,827:INFO:Importing untrained model
2025-04-22 15:09:15,828:INFO:Ridge Regression Imported successfully
2025-04-22 15:09:15,828:INFO:Starting cross validation
2025-04-22 15:09:15,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:18,644:INFO:Calculating mean and std
2025-04-22 15:09:18,644:INFO:Creating metrics dataframe
2025-04-22 15:09:18,646:INFO:Uploading results into container
2025-04-22 15:09:18,646:INFO:Uploading model into container now
2025-04-22 15:09:18,646:INFO:_master_model_container: 3
2025-04-22 15:09:18,647:INFO:_display_container: 2
2025-04-22 15:09:18,647:INFO:Ridge(random_state=42)
2025-04-22 15:09:18,647:INFO:create_model() successfully completed......................................
2025-04-22 15:09:18,814:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:18,814:INFO:Creating metrics dataframe
2025-04-22 15:09:18,815:INFO:Initializing Elastic Net
2025-04-22 15:09:18,815:INFO:Total runtime is 0.5067609270413718 minutes
2025-04-22 15:09:18,815:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:18,816:INFO:Initializing create_model()
2025-04-22 15:09:18,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:18,816:INFO:Checking exceptions
2025-04-22 15:09:18,816:INFO:Importing libraries
2025-04-22 15:09:18,816:INFO:Copying training dataset
2025-04-22 15:09:18,892:INFO:Defining folds
2025-04-22 15:09:18,892:INFO:Declaring metric variables
2025-04-22 15:09:18,892:INFO:Importing untrained model
2025-04-22 15:09:18,892:INFO:Elastic Net Imported successfully
2025-04-22 15:09:18,892:INFO:Starting cross validation
2025-04-22 15:09:18,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:41,880:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,002:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.439e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,305:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e+04, tolerance: 1.402e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,615:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.405e+04, tolerance: 1.403e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,737:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+04, tolerance: 1.405e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,820:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.425e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:42,990:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:43,047:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+05, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:43,160:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e+04, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:43,190:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+04, tolerance: 1.400e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 15:09:43,258:INFO:Calculating mean and std
2025-04-22 15:09:43,259:INFO:Creating metrics dataframe
2025-04-22 15:09:43,260:INFO:Uploading results into container
2025-04-22 15:09:43,260:INFO:Uploading model into container now
2025-04-22 15:09:43,261:INFO:_master_model_container: 4
2025-04-22 15:09:43,261:INFO:_display_container: 2
2025-04-22 15:09:43,261:INFO:ElasticNet(random_state=42)
2025-04-22 15:09:43,261:INFO:create_model() successfully completed......................................
2025-04-22 15:09:43,417:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:43,417:INFO:Creating metrics dataframe
2025-04-22 15:09:43,419:INFO:Initializing Least Angle Regression
2025-04-22 15:09:43,419:INFO:Total runtime is 0.9168224374453228 minutes
2025-04-22 15:09:43,419:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:43,419:INFO:Initializing create_model()
2025-04-22 15:09:43,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:43,419:INFO:Checking exceptions
2025-04-22 15:09:43,419:INFO:Importing libraries
2025-04-22 15:09:43,419:INFO:Copying training dataset
2025-04-22 15:09:43,493:INFO:Defining folds
2025-04-22 15:09:43,494:INFO:Declaring metric variables
2025-04-22 15:09:43,494:INFO:Importing untrained model
2025-04-22 15:09:43,494:INFO:Least Angle Regression Imported successfully
2025-04-22 15:09:43,494:INFO:Starting cross validation
2025-04-22 15:09:43,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:45,543:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,546:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.247e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,547:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.767e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,548:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.334e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,549:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.274e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,552:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.168e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,553:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.009e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,555:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.259e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,555:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.932e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,557:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.135e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,559:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.011e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,560:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.600e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,560:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.254e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,561:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.174e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,561:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.154e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,564:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,565:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.169e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,565:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.124e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,566:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.151e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,566:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.810e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,566:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.895e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,567:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.019e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,567:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.733e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,567:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.527e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,680:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,682:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.140e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,683:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.721e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,684:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.340e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,685:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.654e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,686:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.772e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,686:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.736e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,687:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.377e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,687:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.216e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,687:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.306e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,688:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.557e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,689:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.430e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,690:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.134e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.008e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.653e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.448e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,691:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.615e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.298e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.229e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.058e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.193e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.365e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,692:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.360e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,693:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.097e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,693:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.628e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.173e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.128e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.071e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.781e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.083e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.593e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.043e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.555e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,694:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.375e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,695:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.618e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,695:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.561e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,695:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.016e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,695:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.673e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,695:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.332e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,696:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.518e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,696:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.370e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,696:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.306e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,696:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.748e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,697:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.456e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,697:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.165e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,697:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.874e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,697:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.583e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,836:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.520e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,839:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.391e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,844:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.067e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,844:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.165e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,845:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.354e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,846:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.478e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,846:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.096e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,847:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.291e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,847:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.227e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,847:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.180e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.173e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.131e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.845e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.295e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.076e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,905:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,909:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.015e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,910:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.878e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,913:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.934e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,915:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.778e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,916:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=3.334e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,920:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.416e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,922:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.992e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,923:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.088e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,925:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.558e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,926:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.142e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,926:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.141e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,926:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.140e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,927:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.087e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,927:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.086e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,927:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.066e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,928:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.052e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,929:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.909e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,929:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.155e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,929:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.338e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,929:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.645e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.448e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.256e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.966e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.899e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,930:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.606e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:45,931:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.504e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,050:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,053:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.828e+02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,054:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.378e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,056:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.876e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,057:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.733e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,058:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.715e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,059:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.132e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.726e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,061:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.554e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,063:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.449e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,063:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.277e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,063:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.656e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,065:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.896e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,068:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.492e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,070:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.484e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,070:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.157e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,070:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.675e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.601e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.381e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.122e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.119e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.091e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,071:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.157e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,072:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=7.118e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,072:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.166e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,072:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.721e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,072:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.711e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,073:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.544e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,073:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.428e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,073:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.201e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,073:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.946e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,073:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.561e-06, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,120:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.145e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,122:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.606e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,122:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.958e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,123:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.855e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,124:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.386e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,124:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.203e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,124:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.066e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,125:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.621e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,125:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.094e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,125:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.517e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,125:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.483e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,125:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.193e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,126:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.875e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,126:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.747e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,126:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.604e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,126:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.271e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,127:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.682e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,127:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.603e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,127:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.551e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,127:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.525e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,127:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.445e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,128:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.429e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,128:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.243e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,128:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.749e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,155:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.602e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,157:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.582e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,157:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.384e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,158:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.264e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,158:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.577e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,163:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.963e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,163:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.823e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,164:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.166e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,164:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.947e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.135e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.749e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.664e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.424e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.672e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.203e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,166:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.469e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,208:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.373e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,209:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.372e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,209:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.003e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,210:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.264e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.173e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.599e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.572e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.287e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.678e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,211:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.654e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.716e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.477e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.534e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.047e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.853e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,212:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.279e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,253:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,255:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.175e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,255:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.717e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,255:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.310e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,256:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.973e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,258:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.844e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,258:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.620e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,258:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.591e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,259:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.962e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,259:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.784e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,259:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.413e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,259:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.187e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.279e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.859e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.003e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.633e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.145e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.699e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.259e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.859e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.208e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.604e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:46,339:INFO:Calculating mean and std
2025-04-22 15:09:46,340:INFO:Creating metrics dataframe
2025-04-22 15:09:46,342:INFO:Uploading results into container
2025-04-22 15:09:46,343:INFO:Uploading model into container now
2025-04-22 15:09:46,343:INFO:_master_model_container: 5
2025-04-22 15:09:46,343:INFO:_display_container: 2
2025-04-22 15:09:46,344:INFO:Lars(random_state=42)
2025-04-22 15:09:46,344:INFO:create_model() successfully completed......................................
2025-04-22 15:09:46,493:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:46,493:INFO:Creating metrics dataframe
2025-04-22 15:09:46,494:INFO:Initializing Lasso Least Angle Regression
2025-04-22 15:09:46,494:INFO:Total runtime is 0.96806671222051 minutes
2025-04-22 15:09:46,495:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:46,495:INFO:Initializing create_model()
2025-04-22 15:09:46,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:46,495:INFO:Checking exceptions
2025-04-22 15:09:46,495:INFO:Importing libraries
2025-04-22 15:09:46,495:INFO:Copying training dataset
2025-04-22 15:09:46,567:INFO:Defining folds
2025-04-22 15:09:46,567:INFO:Declaring metric variables
2025-04-22 15:09:46,567:INFO:Importing untrained model
2025-04-22 15:09:46,568:INFO:Lasso Least Angle Regression Imported successfully
2025-04-22 15:09:46,568:INFO:Starting cross validation
2025-04-22 15:09:46,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:48,517:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,519:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.526e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,521:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.681e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,521:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.446e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,522:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.092e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,524:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.660e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,525:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.406e+01, previous alpha=5.200e+00, with an active set of 17 regressors.
  warnings.warn(

2025-04-22 15:09:48,710:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=2.031e+00, previous alpha=1.152e+00, with an active set of 21 regressors.
  warnings.warn(

2025-04-22 15:09:48,768:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,773:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.426e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,776:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.362e+01, previous alpha=2.899e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:09:48,801:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=9.705e+01, previous alpha=9.696e+01, with an active set of 5 regressors.
  warnings.warn(

2025-04-22 15:09:48,982:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:48,986:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.685e+02, previous alpha=2.933e+01, with an active set of 12 regressors.
  warnings.warn(

2025-04-22 15:09:49,006:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,011:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.532e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,014:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.744e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,015:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,016:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.009e+01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,017:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.616e+01, previous alpha=9.605e+00, with an active set of 14 regressors.
  warnings.warn(

2025-04-22 15:09:49,079:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=7.797e+01, previous alpha=7.593e+01, with an active set of 7 regressors.
  warnings.warn(

2025-04-22 15:09:49,184:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.159e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,215:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.295e+01, previous alpha=2.787e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:09:49,274:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 15:09:49,275:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.623e+01, previous alpha=4.556e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 15:09:49,340:INFO:Calculating mean and std
2025-04-22 15:09:49,341:INFO:Creating metrics dataframe
2025-04-22 15:09:49,342:INFO:Uploading results into container
2025-04-22 15:09:49,342:INFO:Uploading model into container now
2025-04-22 15:09:49,342:INFO:_master_model_container: 6
2025-04-22 15:09:49,343:INFO:_display_container: 2
2025-04-22 15:09:49,343:INFO:LassoLars(random_state=42)
2025-04-22 15:09:49,343:INFO:create_model() successfully completed......................................
2025-04-22 15:09:49,492:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:49,492:INFO:Creating metrics dataframe
2025-04-22 15:09:49,494:INFO:Initializing Orthogonal Matching Pursuit
2025-04-22 15:09:49,494:INFO:Total runtime is 1.018080222606659 minutes
2025-04-22 15:09:49,494:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:49,494:INFO:Initializing create_model()
2025-04-22 15:09:49,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:49,495:INFO:Checking exceptions
2025-04-22 15:09:49,495:INFO:Importing libraries
2025-04-22 15:09:49,495:INFO:Copying training dataset
2025-04-22 15:09:49,565:INFO:Defining folds
2025-04-22 15:09:49,565:INFO:Declaring metric variables
2025-04-22 15:09:49,565:INFO:Importing untrained model
2025-04-22 15:09:49,565:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-22 15:09:49,566:INFO:Starting cross validation
2025-04-22 15:09:49,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:52,403:INFO:Calculating mean and std
2025-04-22 15:09:52,404:INFO:Creating metrics dataframe
2025-04-22 15:09:52,405:INFO:Uploading results into container
2025-04-22 15:09:52,406:INFO:Uploading model into container now
2025-04-22 15:09:52,406:INFO:_master_model_container: 7
2025-04-22 15:09:52,406:INFO:_display_container: 2
2025-04-22 15:09:52,406:INFO:OrthogonalMatchingPursuit()
2025-04-22 15:09:52,406:INFO:create_model() successfully completed......................................
2025-04-22 15:09:52,558:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:52,558:INFO:Creating metrics dataframe
2025-04-22 15:09:52,561:INFO:Initializing Bayesian Ridge
2025-04-22 15:09:52,561:INFO:Total runtime is 1.06918177207311 minutes
2025-04-22 15:09:52,561:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:52,562:INFO:Initializing create_model()
2025-04-22 15:09:52,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:52,562:INFO:Checking exceptions
2025-04-22 15:09:52,562:INFO:Importing libraries
2025-04-22 15:09:52,562:INFO:Copying training dataset
2025-04-22 15:09:52,636:INFO:Defining folds
2025-04-22 15:09:52,636:INFO:Declaring metric variables
2025-04-22 15:09:52,636:INFO:Importing untrained model
2025-04-22 15:09:52,637:INFO:Bayesian Ridge Imported successfully
2025-04-22 15:09:52,637:INFO:Starting cross validation
2025-04-22 15:09:52,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:09:57,462:INFO:Calculating mean and std
2025-04-22 15:09:57,463:INFO:Creating metrics dataframe
2025-04-22 15:09:57,464:INFO:Uploading results into container
2025-04-22 15:09:57,464:INFO:Uploading model into container now
2025-04-22 15:09:57,465:INFO:_master_model_container: 8
2025-04-22 15:09:57,465:INFO:_display_container: 2
2025-04-22 15:09:57,465:INFO:BayesianRidge()
2025-04-22 15:09:57,465:INFO:create_model() successfully completed......................................
2025-04-22 15:09:57,612:INFO:SubProcess create_model() end ==================================
2025-04-22 15:09:57,613:INFO:Creating metrics dataframe
2025-04-22 15:09:57,614:INFO:Initializing Passive Aggressive Regressor
2025-04-22 15:09:57,614:INFO:Total runtime is 1.1534099141756695 minutes
2025-04-22 15:09:57,614:INFO:SubProcess create_model() called ==================================
2025-04-22 15:09:57,615:INFO:Initializing create_model()
2025-04-22 15:09:57,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:09:57,615:INFO:Checking exceptions
2025-04-22 15:09:57,615:INFO:Importing libraries
2025-04-22 15:09:57,615:INFO:Copying training dataset
2025-04-22 15:09:57,683:INFO:Defining folds
2025-04-22 15:09:57,683:INFO:Declaring metric variables
2025-04-22 15:09:57,683:INFO:Importing untrained model
2025-04-22 15:09:57,683:INFO:Passive Aggressive Regressor Imported successfully
2025-04-22 15:09:57,683:INFO:Starting cross validation
2025-04-22 15:09:57,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:10:02,324:INFO:Calculating mean and std
2025-04-22 15:10:02,324:INFO:Creating metrics dataframe
2025-04-22 15:10:02,326:INFO:Uploading results into container
2025-04-22 15:10:02,326:INFO:Uploading model into container now
2025-04-22 15:10:02,326:INFO:_master_model_container: 9
2025-04-22 15:10:02,326:INFO:_display_container: 2
2025-04-22 15:10:02,327:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-22 15:10:02,327:INFO:create_model() successfully completed......................................
2025-04-22 15:10:02,477:INFO:SubProcess create_model() end ==================================
2025-04-22 15:10:02,477:INFO:Creating metrics dataframe
2025-04-22 15:10:02,479:INFO:Initializing Huber Regressor
2025-04-22 15:10:02,479:INFO:Total runtime is 1.2344954649607343 minutes
2025-04-22 15:10:02,479:INFO:SubProcess create_model() called ==================================
2025-04-22 15:10:02,479:INFO:Initializing create_model()
2025-04-22 15:10:02,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:10:02,479:INFO:Checking exceptions
2025-04-22 15:10:02,479:INFO:Importing libraries
2025-04-22 15:10:02,479:INFO:Copying training dataset
2025-04-22 15:10:02,547:INFO:Defining folds
2025-04-22 15:10:02,547:INFO:Declaring metric variables
2025-04-22 15:10:02,548:INFO:Importing untrained model
2025-04-22 15:10:02,548:INFO:Huber Regressor Imported successfully
2025-04-22 15:10:02,548:INFO:Starting cross validation
2025-04-22 15:10:02,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:10:14,379:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:14,885:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:14,960:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:14,968:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:15,173:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:15,236:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:15,239:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:15,256:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:16,038:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:16,089:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 15:10:16,155:INFO:Calculating mean and std
2025-04-22 15:10:16,156:INFO:Creating metrics dataframe
2025-04-22 15:10:16,158:INFO:Uploading results into container
2025-04-22 15:10:16,158:INFO:Uploading model into container now
2025-04-22 15:10:16,158:INFO:_master_model_container: 10
2025-04-22 15:10:16,158:INFO:_display_container: 2
2025-04-22 15:10:16,158:INFO:HuberRegressor()
2025-04-22 15:10:16,158:INFO:create_model() successfully completed......................................
2025-04-22 15:10:16,310:INFO:SubProcess create_model() end ==================================
2025-04-22 15:10:16,310:INFO:Creating metrics dataframe
2025-04-22 15:10:16,312:INFO:Initializing K Neighbors Regressor
2025-04-22 15:10:16,312:INFO:Total runtime is 1.4650435845057173 minutes
2025-04-22 15:10:16,312:INFO:SubProcess create_model() called ==================================
2025-04-22 15:10:16,312:INFO:Initializing create_model()
2025-04-22 15:10:16,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:10:16,312:INFO:Checking exceptions
2025-04-22 15:10:16,312:INFO:Importing libraries
2025-04-22 15:10:16,312:INFO:Copying training dataset
2025-04-22 15:10:16,381:INFO:Defining folds
2025-04-22 15:10:16,381:INFO:Declaring metric variables
2025-04-22 15:10:16,381:INFO:Importing untrained model
2025-04-22 15:10:16,382:INFO:K Neighbors Regressor Imported successfully
2025-04-22 15:10:16,382:INFO:Starting cross validation
2025-04-22 15:10:16,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:10:24,387:INFO:Calculating mean and std
2025-04-22 15:10:24,388:INFO:Creating metrics dataframe
2025-04-22 15:10:24,389:INFO:Uploading results into container
2025-04-22 15:10:24,390:INFO:Uploading model into container now
2025-04-22 15:10:24,390:INFO:_master_model_container: 11
2025-04-22 15:10:24,390:INFO:_display_container: 2
2025-04-22 15:10:24,390:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-22 15:10:24,390:INFO:create_model() successfully completed......................................
2025-04-22 15:10:24,548:INFO:SubProcess create_model() end ==================================
2025-04-22 15:10:24,548:INFO:Creating metrics dataframe
2025-04-22 15:10:24,550:INFO:Initializing Decision Tree Regressor
2025-04-22 15:10:24,550:INFO:Total runtime is 1.6023330251375838 minutes
2025-04-22 15:10:24,550:INFO:SubProcess create_model() called ==================================
2025-04-22 15:10:24,550:INFO:Initializing create_model()
2025-04-22 15:10:24,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:10:24,550:INFO:Checking exceptions
2025-04-22 15:10:24,551:INFO:Importing libraries
2025-04-22 15:10:24,551:INFO:Copying training dataset
2025-04-22 15:10:24,619:INFO:Defining folds
2025-04-22 15:10:24,619:INFO:Declaring metric variables
2025-04-22 15:10:24,619:INFO:Importing untrained model
2025-04-22 15:10:24,619:INFO:Decision Tree Regressor Imported successfully
2025-04-22 15:10:24,619:INFO:Starting cross validation
2025-04-22 15:10:24,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:10:28,719:INFO:Calculating mean and std
2025-04-22 15:10:28,720:INFO:Creating metrics dataframe
2025-04-22 15:10:28,721:INFO:Uploading results into container
2025-04-22 15:10:28,721:INFO:Uploading model into container now
2025-04-22 15:10:28,721:INFO:_master_model_container: 12
2025-04-22 15:10:28,721:INFO:_display_container: 2
2025-04-22 15:10:28,722:INFO:DecisionTreeRegressor(random_state=42)
2025-04-22 15:10:28,722:INFO:create_model() successfully completed......................................
2025-04-22 15:10:28,869:INFO:SubProcess create_model() end ==================================
2025-04-22 15:10:28,869:INFO:Creating metrics dataframe
2025-04-22 15:10:28,870:INFO:Initializing Random Forest Regressor
2025-04-22 15:10:28,870:INFO:Total runtime is 1.67434356212616 minutes
2025-04-22 15:10:28,871:INFO:SubProcess create_model() called ==================================
2025-04-22 15:10:28,871:INFO:Initializing create_model()
2025-04-22 15:10:28,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:10:28,871:INFO:Checking exceptions
2025-04-22 15:10:28,871:INFO:Importing libraries
2025-04-22 15:10:28,871:INFO:Copying training dataset
2025-04-22 15:10:28,942:INFO:Defining folds
2025-04-22 15:10:28,942:INFO:Declaring metric variables
2025-04-22 15:10:28,942:INFO:Importing untrained model
2025-04-22 15:10:28,942:INFO:Random Forest Regressor Imported successfully
2025-04-22 15:10:28,942:INFO:Starting cross validation
2025-04-22 15:10:28,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:11:46,892:INFO:Calculating mean and std
2025-04-22 15:11:46,893:INFO:Creating metrics dataframe
2025-04-22 15:11:46,895:INFO:Uploading results into container
2025-04-22 15:11:46,895:INFO:Uploading model into container now
2025-04-22 15:11:46,895:INFO:_master_model_container: 13
2025-04-22 15:11:46,895:INFO:_display_container: 2
2025-04-22 15:11:46,896:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:11:46,896:INFO:create_model() successfully completed......................................
2025-04-22 15:11:47,070:INFO:SubProcess create_model() end ==================================
2025-04-22 15:11:47,070:INFO:Creating metrics dataframe
2025-04-22 15:11:47,072:INFO:Initializing Extra Trees Regressor
2025-04-22 15:11:47,072:INFO:Total runtime is 2.9776999115943914 minutes
2025-04-22 15:11:47,072:INFO:SubProcess create_model() called ==================================
2025-04-22 15:11:47,072:INFO:Initializing create_model()
2025-04-22 15:11:47,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:11:47,072:INFO:Checking exceptions
2025-04-22 15:11:47,073:INFO:Importing libraries
2025-04-22 15:11:47,073:INFO:Copying training dataset
2025-04-22 15:11:47,150:INFO:Defining folds
2025-04-22 15:11:47,150:INFO:Declaring metric variables
2025-04-22 15:11:47,151:INFO:Importing untrained model
2025-04-22 15:11:47,151:INFO:Extra Trees Regressor Imported successfully
2025-04-22 15:11:47,151:INFO:Starting cross validation
2025-04-22 15:11:47,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:12:52,552:INFO:Calculating mean and std
2025-04-22 15:12:52,553:INFO:Creating metrics dataframe
2025-04-22 15:12:52,555:INFO:Uploading results into container
2025-04-22 15:12:52,555:INFO:Uploading model into container now
2025-04-22 15:12:52,556:INFO:_master_model_container: 14
2025-04-22 15:12:52,556:INFO:_display_container: 2
2025-04-22 15:12:52,556:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:12:52,556:INFO:create_model() successfully completed......................................
2025-04-22 15:12:52,855:INFO:SubProcess create_model() end ==================================
2025-04-22 15:12:52,856:INFO:Creating metrics dataframe
2025-04-22 15:12:52,858:INFO:Initializing AdaBoost Regressor
2025-04-22 15:12:52,858:INFO:Total runtime is 4.0741454879442855 minutes
2025-04-22 15:12:52,858:INFO:SubProcess create_model() called ==================================
2025-04-22 15:12:52,858:INFO:Initializing create_model()
2025-04-22 15:12:52,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:12:52,858:INFO:Checking exceptions
2025-04-22 15:12:52,858:INFO:Importing libraries
2025-04-22 15:12:52,858:INFO:Copying training dataset
2025-04-22 15:12:52,937:INFO:Defining folds
2025-04-22 15:12:52,937:INFO:Declaring metric variables
2025-04-22 15:12:52,937:INFO:Importing untrained model
2025-04-22 15:12:52,937:INFO:AdaBoost Regressor Imported successfully
2025-04-22 15:12:52,937:INFO:Starting cross validation
2025-04-22 15:12:52,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:13:24,367:INFO:Calculating mean and std
2025-04-22 15:13:24,368:INFO:Creating metrics dataframe
2025-04-22 15:13:24,369:INFO:Uploading results into container
2025-04-22 15:13:24,369:INFO:Uploading model into container now
2025-04-22 15:13:24,369:INFO:_master_model_container: 15
2025-04-22 15:13:24,369:INFO:_display_container: 2
2025-04-22 15:13:24,370:INFO:AdaBoostRegressor(random_state=42)
2025-04-22 15:13:24,370:INFO:create_model() successfully completed......................................
2025-04-22 15:13:24,520:INFO:SubProcess create_model() end ==================================
2025-04-22 15:13:24,521:INFO:Creating metrics dataframe
2025-04-22 15:13:24,522:INFO:Initializing Gradient Boosting Regressor
2025-04-22 15:13:24,522:INFO:Total runtime is 4.601874049504598 minutes
2025-04-22 15:13:24,523:INFO:SubProcess create_model() called ==================================
2025-04-22 15:13:24,523:INFO:Initializing create_model()
2025-04-22 15:13:24,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:13:24,523:INFO:Checking exceptions
2025-04-22 15:13:24,523:INFO:Importing libraries
2025-04-22 15:13:24,523:INFO:Copying training dataset
2025-04-22 15:13:24,590:INFO:Defining folds
2025-04-22 15:13:24,590:INFO:Declaring metric variables
2025-04-22 15:13:24,590:INFO:Importing untrained model
2025-04-22 15:13:24,590:INFO:Gradient Boosting Regressor Imported successfully
2025-04-22 15:13:24,590:INFO:Starting cross validation
2025-04-22 15:13:24,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:13:59,700:INFO:Calculating mean and std
2025-04-22 15:13:59,701:INFO:Creating metrics dataframe
2025-04-22 15:13:59,702:INFO:Uploading results into container
2025-04-22 15:13:59,702:INFO:Uploading model into container now
2025-04-22 15:13:59,702:INFO:_master_model_container: 16
2025-04-22 15:13:59,703:INFO:_display_container: 2
2025-04-22 15:13:59,703:INFO:GradientBoostingRegressor(random_state=42)
2025-04-22 15:13:59,703:INFO:create_model() successfully completed......................................
2025-04-22 15:13:59,874:INFO:SubProcess create_model() end ==================================
2025-04-22 15:13:59,874:INFO:Creating metrics dataframe
2025-04-22 15:13:59,876:INFO:Initializing Extreme Gradient Boosting
2025-04-22 15:13:59,876:INFO:Total runtime is 5.191101928551992 minutes
2025-04-22 15:13:59,876:INFO:SubProcess create_model() called ==================================
2025-04-22 15:13:59,876:INFO:Initializing create_model()
2025-04-22 15:13:59,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:13:59,876:INFO:Checking exceptions
2025-04-22 15:13:59,876:INFO:Importing libraries
2025-04-22 15:13:59,876:INFO:Copying training dataset
2025-04-22 15:13:59,947:INFO:Defining folds
2025-04-22 15:13:59,947:INFO:Declaring metric variables
2025-04-22 15:13:59,947:INFO:Importing untrained model
2025-04-22 15:13:59,948:INFO:Extreme Gradient Boosting Imported successfully
2025-04-22 15:13:59,948:INFO:Starting cross validation
2025-04-22 15:13:59,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:14:05,201:INFO:Calculating mean and std
2025-04-22 15:14:05,201:INFO:Creating metrics dataframe
2025-04-22 15:14:05,203:INFO:Uploading results into container
2025-04-22 15:14:05,203:INFO:Uploading model into container now
2025-04-22 15:14:05,204:INFO:_master_model_container: 17
2025-04-22 15:14:05,204:INFO:_display_container: 2
2025-04-22 15:14:05,204:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             feature_weights=None, gamma=None, grow_policy=None,
             importance_type=None, interaction_constraints=None,
             learning_rate=None, max_bin=None, max_cat_threshold=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, multi_strategy=None, n_estimators=None,
             n_jobs=-1, num_parallel_tree=None, ...)
2025-04-22 15:14:05,204:INFO:create_model() successfully completed......................................
2025-04-22 15:14:05,362:INFO:SubProcess create_model() end ==================================
2025-04-22 15:14:05,362:INFO:Creating metrics dataframe
2025-04-22 15:14:05,364:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 15:14:05,364:INFO:Total runtime is 5.282564389705659 minutes
2025-04-22 15:14:05,364:INFO:SubProcess create_model() called ==================================
2025-04-22 15:14:05,364:INFO:Initializing create_model()
2025-04-22 15:14:05,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:14:05,365:INFO:Checking exceptions
2025-04-22 15:14:05,365:INFO:Importing libraries
2025-04-22 15:14:05,365:INFO:Copying training dataset
2025-04-22 15:14:05,434:INFO:Defining folds
2025-04-22 15:14:05,434:INFO:Declaring metric variables
2025-04-22 15:14:05,434:INFO:Importing untrained model
2025-04-22 15:14:05,434:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 15:14:05,434:INFO:Starting cross validation
2025-04-22 15:14:05,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:14:10,658:INFO:Calculating mean and std
2025-04-22 15:14:10,659:INFO:Creating metrics dataframe
2025-04-22 15:14:10,661:INFO:Uploading results into container
2025-04-22 15:14:10,661:INFO:Uploading model into container now
2025-04-22 15:14:10,661:INFO:_master_model_container: 18
2025-04-22 15:14:10,661:INFO:_display_container: 2
2025-04-22 15:14:10,662:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:14:10,662:INFO:create_model() successfully completed......................................
2025-04-22 15:14:10,835:INFO:SubProcess create_model() end ==================================
2025-04-22 15:14:10,836:INFO:Creating metrics dataframe
2025-04-22 15:14:10,837:INFO:Initializing CatBoost Regressor
2025-04-22 15:14:10,837:INFO:Total runtime is 5.37379452387492 minutes
2025-04-22 15:14:10,837:INFO:SubProcess create_model() called ==================================
2025-04-22 15:14:10,838:INFO:Initializing create_model()
2025-04-22 15:14:10,838:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:14:10,838:INFO:Checking exceptions
2025-04-22 15:14:10,838:INFO:Importing libraries
2025-04-22 15:14:10,838:INFO:Copying training dataset
2025-04-22 15:14:10,904:INFO:Defining folds
2025-04-22 15:14:10,905:INFO:Declaring metric variables
2025-04-22 15:14:10,905:INFO:Importing untrained model
2025-04-22 15:14:10,905:INFO:CatBoost Regressor Imported successfully
2025-04-22 15:14:10,905:INFO:Starting cross validation
2025-04-22 15:14:10,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:14:53,240:INFO:Calculating mean and std
2025-04-22 15:14:53,241:INFO:Creating metrics dataframe
2025-04-22 15:14:53,242:INFO:Uploading results into container
2025-04-22 15:14:53,242:INFO:Uploading model into container now
2025-04-22 15:14:53,242:INFO:_master_model_container: 19
2025-04-22 15:14:53,243:INFO:_display_container: 2
2025-04-22 15:14:53,243:INFO:<catboost.core.CatBoostRegressor object at 0x000001F8EE411050>
2025-04-22 15:14:53,243:INFO:create_model() successfully completed......................................
2025-04-22 15:14:53,443:INFO:SubProcess create_model() end ==================================
2025-04-22 15:14:53,443:INFO:Creating metrics dataframe
2025-04-22 15:14:53,445:INFO:Initializing Dummy Regressor
2025-04-22 15:14:53,445:INFO:Total runtime is 6.083928294976554 minutes
2025-04-22 15:14:53,446:INFO:SubProcess create_model() called ==================================
2025-04-22 15:14:53,446:INFO:Initializing create_model()
2025-04-22 15:14:53,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8EE53BC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:14:53,446:INFO:Checking exceptions
2025-04-22 15:14:53,446:INFO:Importing libraries
2025-04-22 15:14:53,446:INFO:Copying training dataset
2025-04-22 15:14:53,524:INFO:Defining folds
2025-04-22 15:14:53,524:INFO:Declaring metric variables
2025-04-22 15:14:53,524:INFO:Importing untrained model
2025-04-22 15:14:53,524:INFO:Dummy Regressor Imported successfully
2025-04-22 15:14:53,524:INFO:Starting cross validation
2025-04-22 15:14:53,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 15:14:56,474:INFO:Calculating mean and std
2025-04-22 15:14:56,475:INFO:Creating metrics dataframe
2025-04-22 15:14:56,476:INFO:Uploading results into container
2025-04-22 15:14:56,476:INFO:Uploading model into container now
2025-04-22 15:14:56,477:INFO:_master_model_container: 20
2025-04-22 15:14:56,477:INFO:_display_container: 2
2025-04-22 15:14:56,477:INFO:DummyRegressor()
2025-04-22 15:14:56,477:INFO:create_model() successfully completed......................................
2025-04-22 15:14:56,652:INFO:SubProcess create_model() end ==================================
2025-04-22 15:14:56,653:INFO:Creating metrics dataframe
2025-04-22 15:14:56,656:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\plot_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-04-22 15:14:56,657:INFO:Initializing create_model()
2025-04-22 15:14:56,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F8E47D3590>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 15:14:56,658:INFO:Checking exceptions
2025-04-22 15:14:56,658:INFO:Importing libraries
2025-04-22 15:14:56,658:INFO:Copying training dataset
2025-04-22 15:14:56,731:INFO:Defining folds
2025-04-22 15:14:56,731:INFO:Declaring metric variables
2025-04-22 15:14:56,731:INFO:Importing untrained model
2025-04-22 15:14:56,731:INFO:Declaring custom model
2025-04-22 15:14:56,732:INFO:Extra Trees Regressor Imported successfully
2025-04-22 15:14:56,733:INFO:Cross validation set to False
2025-04-22 15:14:56,733:INFO:Fitting Model
2025-04-22 15:15:03,902:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:15:03,902:INFO:create_model() successfully completed......................................
2025-04-22 15:15:04,094:INFO:_master_model_container: 20
2025-04-22 15:15:04,094:INFO:_display_container: 2
2025-04-22 15:15:04,095:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 15:15:04,095:INFO:compare_models() successfully completed......................................
2025-04-22 15:15:04,104:INFO:Initializing save_model()
2025-04-22 15:15:04,105:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=42), model_name=results\models_results\auto_ml\pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-22 15:15:04,105:INFO:Adding model into prep_pipe
2025-04-22 15:15:04,492:INFO:results\models_results\auto_ml\pycaret_best_model.pkl saved in current working directory
2025-04-22 15:15:04,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=42))])
2025-04-22 15:15:04,500:INFO:save_model() successfully completed......................................
2025-04-22 21:39:24,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:39:24,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:39:24,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:39:24,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:39:25,486:INFO:PyCaret RegressionExperiment
2025-04-22 21:39:25,487:INFO:Logging name: automl_experiment
2025-04-22 21:39:25,487:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-22 21:39:25,487:INFO:version 3.3.2
2025-04-22 21:39:25,487:INFO:Initializing setup()
2025-04-22 21:39:25,487:INFO:self.USI: 2412
2025-04-22 21:39:25,487:INFO:self._variable_keys: {'memory', 'USI', 'idx', 'target_param', 'gpu_param', 'y_train', 'pipeline', 'log_plots_param', '_available_plots', 'y_test', 'n_jobs_param', 'html_param', 'fold_generator', 'X', 'X_test', 'X_train', 'fold_groups_param', 'exp_id', 'transform_target_param', 'y', 'fold_shuffle_param', '_ml_usecase', 'seed', 'logging_param', 'exp_name_log', 'data', 'gpu_n_jobs_param'}
2025-04-22 21:39:25,487:INFO:Checking environment
2025-04-22 21:39:25,487:INFO:python_version: 3.10.0
2025-04-22 21:39:25,487:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-22 21:39:25,487:INFO:machine: AMD64
2025-04-22 21:39:25,495:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-22 21:39:25,504:INFO:Memory: svmem(total=51455639552, available=28500541440, percent=44.6, used=22955098112, free=28500541440)
2025-04-22 21:39:25,504:INFO:Physical Core: 8
2025-04-22 21:39:25,504:INFO:Logical Core: 16
2025-04-22 21:39:25,505:INFO:Checking libraries
2025-04-22 21:39:25,505:INFO:System:
2025-04-22 21:39:25,505:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-22 21:39:25,505:INFO:executable: C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\Scripts\python.exe
2025-04-22 21:39:25,505:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-22 21:39:25,505:INFO:PyCaret required dependencies:
2025-04-22 21:39:25,543:INFO:                 pip: 21.2.3
2025-04-22 21:39:25,543:INFO:          setuptools: 57.4.0
2025-04-22 21:39:25,543:INFO:             pycaret: 3.3.2
2025-04-22 21:39:25,543:INFO:             IPython: 8.35.0
2025-04-22 21:39:25,543:INFO:          ipywidgets: 8.1.6
2025-04-22 21:39:25,543:INFO:                tqdm: 4.67.1
2025-04-22 21:39:25,543:INFO:               numpy: 1.26.4
2025-04-22 21:39:25,543:INFO:              pandas: 2.1.4
2025-04-22 21:39:25,543:INFO:              jinja2: 3.1.6
2025-04-22 21:39:25,543:INFO:               scipy: 1.11.4
2025-04-22 21:39:25,543:INFO:              joblib: 1.3.2
2025-04-22 21:39:25,543:INFO:             sklearn: 1.4.2
2025-04-22 21:39:25,544:INFO:                pyod: 2.0.4
2025-04-22 21:39:25,544:INFO:            imblearn: 0.13.0
2025-04-22 21:39:25,544:INFO:   category_encoders: 2.7.0
2025-04-22 21:39:25,544:INFO:            lightgbm: 4.6.0
2025-04-22 21:39:25,544:INFO:               numba: 0.61.2
2025-04-22 21:39:25,544:INFO:            requests: 2.32.3
2025-04-22 21:39:25,544:INFO:          matplotlib: 3.7.5
2025-04-22 21:39:25,544:INFO:          scikitplot: 0.3.7
2025-04-22 21:39:25,544:INFO:         yellowbrick: 1.5
2025-04-22 21:39:25,544:INFO:              plotly: 5.24.1
2025-04-22 21:39:25,544:INFO:    plotly-resampler: Not installed
2025-04-22 21:39:25,544:INFO:             kaleido: 0.2.1
2025-04-22 21:39:25,544:INFO:           schemdraw: 0.15
2025-04-22 21:39:25,544:INFO:         statsmodels: 0.14.4
2025-04-22 21:39:25,544:INFO:              sktime: 0.26.0
2025-04-22 21:39:25,544:INFO:               tbats: 1.1.3
2025-04-22 21:39:25,544:INFO:            pmdarima: 2.0.4
2025-04-22 21:39:25,544:INFO:              psutil: 7.0.0
2025-04-22 21:39:25,544:INFO:          markupsafe: 3.0.2
2025-04-22 21:39:25,544:INFO:             pickle5: Not installed
2025-04-22 21:39:25,544:INFO:         cloudpickle: 3.1.1
2025-04-22 21:39:25,544:INFO:         deprecation: 2.1.0
2025-04-22 21:39:25,544:INFO:              xxhash: 3.5.0
2025-04-22 21:39:25,544:INFO:           wurlitzer: Not installed
2025-04-22 21:39:25,544:INFO:PyCaret optional dependencies:
2025-04-22 21:39:25,558:INFO:                shap: Not installed
2025-04-22 21:39:25,558:INFO:           interpret: Not installed
2025-04-22 21:39:25,558:INFO:                umap: Not installed
2025-04-22 21:39:25,558:INFO:     ydata_profiling: Not installed
2025-04-22 21:39:25,558:INFO:  explainerdashboard: Not installed
2025-04-22 21:39:25,558:INFO:             autoviz: Not installed
2025-04-22 21:39:25,558:INFO:           fairlearn: Not installed
2025-04-22 21:39:25,558:INFO:          deepchecks: Not installed
2025-04-22 21:39:25,558:INFO:             xgboost: Not installed
2025-04-22 21:39:25,558:INFO:            catboost: Not installed
2025-04-22 21:39:25,558:INFO:              kmodes: Not installed
2025-04-22 21:39:25,558:INFO:             mlxtend: Not installed
2025-04-22 21:39:25,558:INFO:       statsforecast: Not installed
2025-04-22 21:39:25,558:INFO:        tune_sklearn: Not installed
2025-04-22 21:39:25,558:INFO:                 ray: Not installed
2025-04-22 21:39:25,559:INFO:            hyperopt: Not installed
2025-04-22 21:39:25,559:INFO:              optuna: Not installed
2025-04-22 21:39:25,559:INFO:               skopt: Not installed
2025-04-22 21:39:25,559:INFO:              mlflow: Not installed
2025-04-22 21:39:25,559:INFO:              gradio: Not installed
2025-04-22 21:39:25,559:INFO:             fastapi: Not installed
2025-04-22 21:39:25,559:INFO:             uvicorn: Not installed
2025-04-22 21:39:25,559:INFO:              m2cgen: Not installed
2025-04-22 21:39:25,559:INFO:           evidently: Not installed
2025-04-22 21:39:25,559:INFO:               fugue: Not installed
2025-04-22 21:39:25,559:INFO:           streamlit: Not installed
2025-04-22 21:39:25,559:INFO:             prophet: Not installed
2025-04-22 21:39:25,559:INFO:None
2025-04-22 21:39:25,559:INFO:Set up data.
2025-04-22 21:39:25,679:INFO:Set up folding strategy.
2025-04-22 21:39:25,679:INFO:Set up train/test split.
2025-04-22 21:39:25,775:INFO:Set up index.
2025-04-22 21:39:25,780:INFO:Assigning column types.
2025-04-22 21:39:25,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 21:39:25,857:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 21:39:25,863:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:39:25,869:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,062:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,068:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,264:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-22 21:39:26,270:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,276:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,477:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,678:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-22 21:39:26,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:26,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:26,899:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,090:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-22 21:39:27,238:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,449:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,508:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 21:39:27,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:39:27,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:27,916:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-22 21:39:28,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:28,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:28,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:28,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:28,333:INFO:Preparing preprocessing pipeline...
2025-04-22 21:39:28,333:INFO:Set up simple imputation.
2025-04-22 21:39:28,368:INFO:Set up encoding of categorical features.
2025-04-22 21:39:28,380:INFO:Set up column name cleaning.
2025-04-22 21:39:29,224:INFO:Finished creating preprocessing pipeline.
2025-04-22 21:39:29,233:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-04-22 21:39:29,233:INFO:Creating final display dataframe.
2025-04-22 21:39:30,449:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target             target
2                   Target type         Regression
3           Original data shape       (128603, 29)
4        Transformed data shape       (128603, 49)
5   Transformed train set shape        (90022, 49)
6    Transformed test set shape        (38581, 49)
7              Numeric features                 22
8          Categorical features                  6
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name  automl_experiment
21                          USI               2412
2025-04-22 21:39:30,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:30,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:30,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:30,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:39:30,856:INFO:setup() successfully completed in 5.38s...............
2025-04-22 21:39:30,856:INFO:Initializing compare_models()
2025-04-22 21:39:30,856:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-22 21:39:30,856:INFO:Checking exceptions
2025-04-22 21:39:30,891:INFO:Preparing display monitor
2025-04-22 21:39:30,895:INFO:Initializing Linear Regression
2025-04-22 21:39:30,895:INFO:Total runtime is 0.0 minutes
2025-04-22 21:39:30,895:INFO:SubProcess create_model() called ==================================
2025-04-22 21:39:30,895:INFO:Initializing create_model()
2025-04-22 21:39:30,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002476C105120>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:39:30,896:INFO:Checking exceptions
2025-04-22 21:39:30,896:INFO:Importing libraries
2025-04-22 21:39:30,896:INFO:Copying training dataset
2025-04-22 21:39:30,979:INFO:Defining folds
2025-04-22 21:39:30,979:INFO:Declaring metric variables
2025-04-22 21:39:30,980:INFO:Importing untrained model
2025-04-22 21:39:30,980:INFO:Linear Regression Imported successfully
2025-04-22 21:39:30,980:INFO:Starting cross validation
2025-04-22 21:39:30,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:39:37,847:INFO:Calculating mean and std
2025-04-22 21:39:37,848:INFO:Creating metrics dataframe
2025-04-22 21:39:37,850:INFO:Uploading results into container
2025-04-22 21:39:37,851:INFO:Uploading model into container now
2025-04-22 21:39:37,851:INFO:_master_model_container: 1
2025-04-22 21:39:37,851:INFO:_display_container: 2
2025-04-22 21:39:37,851:INFO:LinearRegression(n_jobs=-1)
2025-04-22 21:39:37,851:INFO:create_model() successfully completed......................................
2025-04-22 21:39:37,942:INFO:SubProcess create_model() end ==================================
2025-04-22 21:39:37,943:INFO:Creating metrics dataframe
2025-04-22 21:39:37,944:INFO:Initializing Lasso Regression
2025-04-22 21:39:37,944:INFO:Total runtime is 0.11748031377792359 minutes
2025-04-22 21:39:37,945:INFO:SubProcess create_model() called ==================================
2025-04-22 21:39:37,945:INFO:Initializing create_model()
2025-04-22 21:39:37,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002476C105120>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:39:37,945:INFO:Checking exceptions
2025-04-22 21:39:37,945:INFO:Importing libraries
2025-04-22 21:39:37,945:INFO:Copying training dataset
2025-04-22 21:39:38,025:INFO:Defining folds
2025-04-22 21:39:38,025:INFO:Declaring metric variables
2025-04-22 21:39:38,025:INFO:Importing untrained model
2025-04-22 21:39:38,025:INFO:Lasso Regression Imported successfully
2025-04-22 21:39:38,025:INFO:Starting cross validation
2025-04-22 21:39:38,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:39:57,996:INFO:Calculating mean and std
2025-04-22 21:39:57,997:INFO:Creating metrics dataframe
2025-04-22 21:39:57,999:INFO:Uploading results into container
2025-04-22 21:39:57,999:INFO:Uploading model into container now
2025-04-22 21:39:58,000:INFO:_master_model_container: 2
2025-04-22 21:39:58,000:INFO:_display_container: 2
2025-04-22 21:39:58,000:INFO:Lasso(random_state=42)
2025-04-22 21:39:58,000:INFO:create_model() successfully completed......................................
2025-04-22 21:39:58,081:INFO:SubProcess create_model() end ==================================
2025-04-22 21:39:58,081:INFO:Creating metrics dataframe
2025-04-22 21:39:58,083:INFO:Initializing Ridge Regression
2025-04-22 21:39:58,083:INFO:Total runtime is 0.45313085714976 minutes
2025-04-22 21:39:58,083:INFO:SubProcess create_model() called ==================================
2025-04-22 21:39:58,084:INFO:Initializing create_model()
2025-04-22 21:39:58,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002476C105120>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:39:58,084:INFO:Checking exceptions
2025-04-22 21:39:58,084:INFO:Importing libraries
2025-04-22 21:39:58,084:INFO:Copying training dataset
2025-04-22 21:39:58,180:INFO:Defining folds
2025-04-22 21:39:58,181:INFO:Declaring metric variables
2025-04-22 21:39:58,181:INFO:Importing untrained model
2025-04-22 21:39:58,181:INFO:Ridge Regression Imported successfully
2025-04-22 21:39:58,181:INFO:Starting cross validation
2025-04-22 21:39:58,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:40:01,302:INFO:Calculating mean and std
2025-04-22 21:40:01,303:INFO:Creating metrics dataframe
2025-04-22 21:40:01,305:INFO:Uploading results into container
2025-04-22 21:40:01,305:INFO:Uploading model into container now
2025-04-22 21:40:01,305:INFO:_master_model_container: 3
2025-04-22 21:40:01,305:INFO:_display_container: 2
2025-04-22 21:40:01,306:INFO:Ridge(random_state=42)
2025-04-22 21:40:01,306:INFO:create_model() successfully completed......................................
2025-04-22 21:40:01,374:INFO:SubProcess create_model() end ==================================
2025-04-22 21:40:01,375:INFO:Creating metrics dataframe
2025-04-22 21:40:01,377:INFO:Initializing Elastic Net
2025-04-22 21:40:01,377:INFO:Total runtime is 0.508031713962555 minutes
2025-04-22 21:40:01,377:INFO:SubProcess create_model() called ==================================
2025-04-22 21:40:01,377:INFO:Initializing create_model()
2025-04-22 21:40:01,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024768CE10F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002476C105120>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:40:01,377:INFO:Checking exceptions
2025-04-22 21:40:01,377:INFO:Importing libraries
2025-04-22 21:40:01,377:INFO:Copying training dataset
2025-04-22 21:40:01,458:INFO:Defining folds
2025-04-22 21:40:01,459:INFO:Declaring metric variables
2025-04-22 21:40:01,459:INFO:Importing untrained model
2025-04-22 21:40:01,459:INFO:Elastic Net Imported successfully
2025-04-22 21:40:01,459:INFO:Starting cross validation
2025-04-22 21:40:01,461:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:40:15,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:40:15,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:40:15,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:40:15,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-22 21:40:15,438:INFO:PyCaret RegressionExperiment
2025-04-22 21:40:15,438:INFO:Logging name: automl_experiment
2025-04-22 21:40:15,438:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-22 21:40:15,438:INFO:version 3.3.2
2025-04-22 21:40:15,438:INFO:Initializing setup()
2025-04-22 21:40:15,438:INFO:self.USI: 0d60
2025-04-22 21:40:15,438:INFO:self._variable_keys: {'X', 'fold_groups_param', 'fold_shuffle_param', 'target_param', 'pipeline', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'exp_name_log', '_available_plots', 'gpu_param', 'idx', 'y_test', 'data', 'seed', 'y_train', 'X_train', 'USI', 'n_jobs_param', 'memory', 'y', 'X_test', 'transform_target_param', 'html_param', 'exp_id', 'fold_generator', 'logging_param'}
2025-04-22 21:40:15,439:INFO:Checking environment
2025-04-22 21:40:15,439:INFO:python_version: 3.10.0
2025-04-22 21:40:15,439:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-22 21:40:15,439:INFO:machine: AMD64
2025-04-22 21:40:15,446:INFO:platform: Windows-10-10.0.19045-SP0
2025-04-22 21:40:15,455:INFO:Memory: svmem(total=51455639552, available=28422823936, percent=44.8, used=23032815616, free=28422823936)
2025-04-22 21:40:15,455:INFO:Physical Core: 8
2025-04-22 21:40:15,456:INFO:Logical Core: 16
2025-04-22 21:40:15,456:INFO:Checking libraries
2025-04-22 21:40:15,456:INFO:System:
2025-04-22 21:40:15,456:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-22 21:40:15,456:INFO:executable: C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\Scripts\python.exe
2025-04-22 21:40:15,456:INFO:   machine: Windows-10-10.0.19045-SP0
2025-04-22 21:40:15,456:INFO:PyCaret required dependencies:
2025-04-22 21:40:15,475:INFO:                 pip: 21.2.3
2025-04-22 21:40:15,475:INFO:          setuptools: 57.4.0
2025-04-22 21:40:15,475:INFO:             pycaret: 3.3.2
2025-04-22 21:40:15,475:INFO:             IPython: 8.35.0
2025-04-22 21:40:15,475:INFO:          ipywidgets: 8.1.6
2025-04-22 21:40:15,475:INFO:                tqdm: 4.67.1
2025-04-22 21:40:15,475:INFO:               numpy: 1.26.4
2025-04-22 21:40:15,475:INFO:              pandas: 2.1.4
2025-04-22 21:40:15,475:INFO:              jinja2: 3.1.6
2025-04-22 21:40:15,475:INFO:               scipy: 1.11.4
2025-04-22 21:40:15,475:INFO:              joblib: 1.3.2
2025-04-22 21:40:15,476:INFO:             sklearn: 1.4.2
2025-04-22 21:40:15,476:INFO:                pyod: 2.0.4
2025-04-22 21:40:15,476:INFO:            imblearn: 0.13.0
2025-04-22 21:40:15,476:INFO:   category_encoders: 2.7.0
2025-04-22 21:40:15,476:INFO:            lightgbm: 4.6.0
2025-04-22 21:40:15,476:INFO:               numba: 0.61.2
2025-04-22 21:40:15,476:INFO:            requests: 2.32.3
2025-04-22 21:40:15,476:INFO:          matplotlib: 3.7.5
2025-04-22 21:40:15,476:INFO:          scikitplot: 0.3.7
2025-04-22 21:40:15,476:INFO:         yellowbrick: 1.5
2025-04-22 21:40:15,476:INFO:              plotly: 5.24.1
2025-04-22 21:40:15,476:INFO:    plotly-resampler: Not installed
2025-04-22 21:40:15,476:INFO:             kaleido: 0.2.1
2025-04-22 21:40:15,476:INFO:           schemdraw: 0.15
2025-04-22 21:40:15,476:INFO:         statsmodels: 0.14.4
2025-04-22 21:40:15,476:INFO:              sktime: 0.26.0
2025-04-22 21:40:15,476:INFO:               tbats: 1.1.3
2025-04-22 21:40:15,476:INFO:            pmdarima: 2.0.4
2025-04-22 21:40:15,476:INFO:              psutil: 7.0.0
2025-04-22 21:40:15,476:INFO:          markupsafe: 3.0.2
2025-04-22 21:40:15,476:INFO:             pickle5: Not installed
2025-04-22 21:40:15,476:INFO:         cloudpickle: 3.1.1
2025-04-22 21:40:15,476:INFO:         deprecation: 2.1.0
2025-04-22 21:40:15,476:INFO:              xxhash: 3.5.0
2025-04-22 21:40:15,476:INFO:           wurlitzer: Not installed
2025-04-22 21:40:15,476:INFO:PyCaret optional dependencies:
2025-04-22 21:40:15,490:INFO:                shap: Not installed
2025-04-22 21:40:15,490:INFO:           interpret: Not installed
2025-04-22 21:40:15,490:INFO:                umap: Not installed
2025-04-22 21:40:15,490:INFO:     ydata_profiling: Not installed
2025-04-22 21:40:15,490:INFO:  explainerdashboard: Not installed
2025-04-22 21:40:15,490:INFO:             autoviz: Not installed
2025-04-22 21:40:15,490:INFO:           fairlearn: Not installed
2025-04-22 21:40:15,490:INFO:          deepchecks: Not installed
2025-04-22 21:40:15,490:INFO:             xgboost: Not installed
2025-04-22 21:40:15,490:INFO:            catboost: Not installed
2025-04-22 21:40:15,490:INFO:              kmodes: Not installed
2025-04-22 21:40:15,490:INFO:             mlxtend: Not installed
2025-04-22 21:40:15,490:INFO:       statsforecast: Not installed
2025-04-22 21:40:15,490:INFO:        tune_sklearn: Not installed
2025-04-22 21:40:15,490:INFO:                 ray: Not installed
2025-04-22 21:40:15,490:INFO:            hyperopt: Not installed
2025-04-22 21:40:15,490:INFO:              optuna: Not installed
2025-04-22 21:40:15,490:INFO:               skopt: Not installed
2025-04-22 21:40:15,490:INFO:              mlflow: Not installed
2025-04-22 21:40:15,490:INFO:              gradio: Not installed
2025-04-22 21:40:15,490:INFO:             fastapi: Not installed
2025-04-22 21:40:15,491:INFO:             uvicorn: Not installed
2025-04-22 21:40:15,491:INFO:              m2cgen: Not installed
2025-04-22 21:40:15,491:INFO:           evidently: Not installed
2025-04-22 21:40:15,491:INFO:               fugue: Not installed
2025-04-22 21:40:15,491:INFO:           streamlit: Not installed
2025-04-22 21:40:15,491:INFO:             prophet: Not installed
2025-04-22 21:40:15,491:INFO:None
2025-04-22 21:40:15,491:INFO:Set up data.
2025-04-22 21:40:15,585:INFO:Set up folding strategy.
2025-04-22 21:40:15,585:INFO:Set up train/test split.
2025-04-22 21:40:15,646:INFO:Set up index.
2025-04-22 21:40:15,650:INFO:Assigning column types.
2025-04-22 21:40:15,718:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-22 21:40:15,718:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,726:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,735:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:15,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:15,948:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,955:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:40:15,962:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,104:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,174:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-22 21:40:16,181:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,416:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,641:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-22 21:40:16,657:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,799:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:16,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:16,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,102:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-22 21:40:17,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,556:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-22 21:40:17,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:17,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:17,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-22 21:40:18,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,011:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-22 21:40:18,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:18,468:INFO:Preparing preprocessing pipeline...
2025-04-22 21:40:18,468:INFO:Set up simple imputation.
2025-04-22 21:40:18,501:INFO:Set up encoding of categorical features.
2025-04-22 21:40:18,511:INFO:Set up column name cleaning.
2025-04-22 21:40:19,133:INFO:Finished creating preprocessing pipeline.
2025-04-22 21:40:19,142:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-04-22 21:40:19,142:INFO:Creating final display dataframe.
2025-04-22 21:40:19,507:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target             target
2                   Target type         Regression
3           Original data shape       (128603, 29)
4        Transformed data shape       (128603, 49)
5   Transformed train set shape        (90022, 49)
6    Transformed test set shape        (38581, 49)
7              Numeric features                 22
8          Categorical features                  6
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13     Maximum one-hot encoding                 25
14              Encoding method               None
15               Fold Generator              KFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name  automl_experiment
21                          USI               0d60
2025-04-22 21:40:19,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:19,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:19,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:19,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-22 21:40:19,980:INFO:setup() successfully completed in 4.55s...............
2025-04-22 21:40:19,980:INFO:Initializing compare_models()
2025-04-22 21:40:19,980:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-22 21:40:19,980:INFO:Checking exceptions
2025-04-22 21:40:20,010:INFO:Preparing display monitor
2025-04-22 21:40:20,013:INFO:Initializing Linear Regression
2025-04-22 21:40:20,014:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-04-22 21:40:20,014:INFO:SubProcess create_model() called ==================================
2025-04-22 21:40:20,014:INFO:Initializing create_model()
2025-04-22 21:40:20,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:40:20,014:INFO:Checking exceptions
2025-04-22 21:40:20,014:INFO:Importing libraries
2025-04-22 21:40:20,014:INFO:Copying training dataset
2025-04-22 21:40:20,101:INFO:Defining folds
2025-04-22 21:40:20,101:INFO:Declaring metric variables
2025-04-22 21:40:20,101:INFO:Importing untrained model
2025-04-22 21:40:20,102:INFO:Linear Regression Imported successfully
2025-04-22 21:40:20,102:INFO:Starting cross validation
2025-04-22 21:40:20,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:40:26,959:INFO:Calculating mean and std
2025-04-22 21:40:26,960:INFO:Creating metrics dataframe
2025-04-22 21:40:26,962:INFO:Uploading results into container
2025-04-22 21:40:26,962:INFO:Uploading model into container now
2025-04-22 21:40:26,963:INFO:_master_model_container: 1
2025-04-22 21:40:26,963:INFO:_display_container: 2
2025-04-22 21:40:26,963:INFO:LinearRegression(n_jobs=-1)
2025-04-22 21:40:26,963:INFO:create_model() successfully completed......................................
2025-04-22 21:40:27,049:INFO:SubProcess create_model() end ==================================
2025-04-22 21:40:27,049:INFO:Creating metrics dataframe
2025-04-22 21:40:27,052:INFO:Initializing Lasso Regression
2025-04-22 21:40:27,052:INFO:Total runtime is 0.11732027530670167 minutes
2025-04-22 21:40:27,052:INFO:SubProcess create_model() called ==================================
2025-04-22 21:40:27,053:INFO:Initializing create_model()
2025-04-22 21:40:27,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:40:27,053:INFO:Checking exceptions
2025-04-22 21:40:27,053:INFO:Importing libraries
2025-04-22 21:40:27,053:INFO:Copying training dataset
2025-04-22 21:40:27,143:INFO:Defining folds
2025-04-22 21:40:27,144:INFO:Declaring metric variables
2025-04-22 21:40:27,144:INFO:Importing untrained model
2025-04-22 21:40:27,144:INFO:Lasso Regression Imported successfully
2025-04-22 21:40:27,144:INFO:Starting cross validation
2025-04-22 21:40:27,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:40:46,650:INFO:Calculating mean and std
2025-04-22 21:40:46,651:INFO:Creating metrics dataframe
2025-04-22 21:40:46,652:INFO:Uploading results into container
2025-04-22 21:40:46,653:INFO:Uploading model into container now
2025-04-22 21:40:46,653:INFO:_master_model_container: 2
2025-04-22 21:40:46,653:INFO:_display_container: 2
2025-04-22 21:40:46,653:INFO:Lasso(random_state=42)
2025-04-22 21:40:46,653:INFO:create_model() successfully completed......................................
2025-04-22 21:40:46,722:INFO:SubProcess create_model() end ==================================
2025-04-22 21:40:46,722:INFO:Creating metrics dataframe
2025-04-22 21:40:46,724:INFO:Initializing Ridge Regression
2025-04-22 21:40:46,724:INFO:Total runtime is 0.44518795013427737 minutes
2025-04-22 21:40:46,724:INFO:SubProcess create_model() called ==================================
2025-04-22 21:40:46,724:INFO:Initializing create_model()
2025-04-22 21:40:46,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:40:46,724:INFO:Checking exceptions
2025-04-22 21:40:46,724:INFO:Importing libraries
2025-04-22 21:40:46,724:INFO:Copying training dataset
2025-04-22 21:40:46,806:INFO:Defining folds
2025-04-22 21:40:46,807:INFO:Declaring metric variables
2025-04-22 21:40:46,807:INFO:Importing untrained model
2025-04-22 21:40:46,807:INFO:Ridge Regression Imported successfully
2025-04-22 21:40:46,807:INFO:Starting cross validation
2025-04-22 21:40:46,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:40:49,868:INFO:Calculating mean and std
2025-04-22 21:40:49,869:INFO:Creating metrics dataframe
2025-04-22 21:40:49,870:INFO:Uploading results into container
2025-04-22 21:40:49,871:INFO:Uploading model into container now
2025-04-22 21:40:49,871:INFO:_master_model_container: 3
2025-04-22 21:40:49,871:INFO:_display_container: 2
2025-04-22 21:40:49,871:INFO:Ridge(random_state=42)
2025-04-22 21:40:49,872:INFO:create_model() successfully completed......................................
2025-04-22 21:40:49,940:INFO:SubProcess create_model() end ==================================
2025-04-22 21:40:49,941:INFO:Creating metrics dataframe
2025-04-22 21:40:49,942:INFO:Initializing Elastic Net
2025-04-22 21:40:49,943:INFO:Total runtime is 0.4988337477048238 minutes
2025-04-22 21:40:49,943:INFO:SubProcess create_model() called ==================================
2025-04-22 21:40:49,943:INFO:Initializing create_model()
2025-04-22 21:40:49,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:40:49,943:INFO:Checking exceptions
2025-04-22 21:40:49,943:INFO:Importing libraries
2025-04-22 21:40:49,943:INFO:Copying training dataset
2025-04-22 21:40:50,022:INFO:Defining folds
2025-04-22 21:40:50,022:INFO:Declaring metric variables
2025-04-22 21:40:50,022:INFO:Importing untrained model
2025-04-22 21:40:50,023:INFO:Elastic Net Imported successfully
2025-04-22 21:40:50,023:INFO:Starting cross validation
2025-04-22 21:40:50,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:14,346:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.439e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:14,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:14,463:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e+04, tolerance: 1.402e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:14,984:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.405e+04, tolerance: 1.403e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,037:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+04, tolerance: 1.405e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,215:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.425e+04, tolerance: 1.407e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,290:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e+04, tolerance: 1.401e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,479:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e+04, tolerance: 1.400e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,569:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+05, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,617:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e+04, tolerance: 1.404e+04
  model = cd_fast.enet_coordinate_descent(

2025-04-22 21:41:15,699:INFO:Calculating mean and std
2025-04-22 21:41:15,700:INFO:Creating metrics dataframe
2025-04-22 21:41:15,701:INFO:Uploading results into container
2025-04-22 21:41:15,702:INFO:Uploading model into container now
2025-04-22 21:41:15,702:INFO:_master_model_container: 4
2025-04-22 21:41:15,702:INFO:_display_container: 2
2025-04-22 21:41:15,702:INFO:ElasticNet(random_state=42)
2025-04-22 21:41:15,702:INFO:create_model() successfully completed......................................
2025-04-22 21:41:15,778:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:15,778:INFO:Creating metrics dataframe
2025-04-22 21:41:15,780:INFO:Initializing Least Angle Regression
2025-04-22 21:41:15,780:INFO:Total runtime is 0.9294589440027873 minutes
2025-04-22 21:41:15,780:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:15,780:INFO:Initializing create_model()
2025-04-22 21:41:15,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:15,780:INFO:Checking exceptions
2025-04-22 21:41:15,780:INFO:Importing libraries
2025-04-22 21:41:15,781:INFO:Copying training dataset
2025-04-22 21:41:15,865:INFO:Defining folds
2025-04-22 21:41:15,865:INFO:Declaring metric variables
2025-04-22 21:41:15,866:INFO:Importing untrained model
2025-04-22 21:41:15,866:INFO:Least Angle Regression Imported successfully
2025-04-22 21:41:15,866:INFO:Starting cross validation
2025-04-22 21:41:15,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:18,250:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,252:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.247e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,253:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.767e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,253:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.334e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,254:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.274e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,256:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.168e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,257:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.009e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,257:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.259e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,258:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.932e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,258:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.135e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,259:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.011e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.600e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,261:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.254e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.174e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,262:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.154e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,265:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,265:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.169e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,266:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.124e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,266:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.151e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,266:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.810e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,266:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.895e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,267:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.019e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,267:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.733e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,267:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.527e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,359:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.772e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,361:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.377e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,361:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.216e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,363:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=7.430e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,365:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.653e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,366:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.615e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,366:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.357e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,366:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.298e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,366:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.229e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,366:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.058e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,367:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.365e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,367:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.360e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,368:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.173e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,368:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.071e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,369:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.781e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,370:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.593e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,370:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.555e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,370:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.375e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,436:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,438:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.140e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,440:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.721e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,441:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.340e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,442:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.654e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,443:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.736e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,444:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=8.306e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,444:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=6.557e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,446:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.134e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,446:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.008e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,447:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.448e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,448:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.193e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,448:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.097e-01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,449:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.628e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,449:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.128e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,449:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.083e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,450:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.043e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,450:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.618e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,450:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.561e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,450:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.016e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.673e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.332e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.518e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.370e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,451:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.306e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,452:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.748e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,452:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.456e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,452:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.165e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,452:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.874e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,452:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.583e-06, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,462:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.520e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,464:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.391e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,466:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.067e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.165e-02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,467:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.354e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,468:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.478e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,468:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.096e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.291e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.227e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,469:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.180e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,470:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.173e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,470:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=7.131e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,470:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.845e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,470:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.295e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,470:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=8.076e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,620:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,622:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=6.015e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,623:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.878e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,624:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.934e+00, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,625:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.778e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,626:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=3.334e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,627:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.416e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,629:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.992e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,630:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=8.088e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,632:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.558e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,633:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.142e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,634:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.141e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,634:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.140e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,634:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.087e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,635:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.086e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,635:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.066e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,636:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.052e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,637:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.909e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,637:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.155e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,637:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.338e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.645e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.448e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.256e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.966e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.899e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,638:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.606e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,639:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.504e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,706:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,709:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.828e+02, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,710:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.378e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,711:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.876e+01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,711:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.733e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,712:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.715e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,713:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.132e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,714:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.726e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,715:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=7.554e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,715:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.449e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,715:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.277e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,715:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.656e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,716:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.896e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,718:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.492e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,718:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.484e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,718:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.157e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,718:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.675e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.601e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.381e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.122e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.119e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.091e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,719:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.157e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,720:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=7.118e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,720:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.166e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,720:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.721e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.711e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.544e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.428e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.201e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.946e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,721:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=5.561e-06, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,844:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.145e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,845:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.606e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,846:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.958e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,846:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.855e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,847:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.386e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,847:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.203e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.066e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.621e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.094e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=9.517e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.483e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,848:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=6.193e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.875e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.747e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.604e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.271e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.682e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.603e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,849:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.551e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,850:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.525e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,850:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.445e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,850:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.429e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,850:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.243e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,850:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.749e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,880:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.602e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,881:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.582e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,882:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.384e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,883:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.264e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,883:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.577e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,886:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.963e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,886:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.823e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,886:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.166e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,886:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.947e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,887:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.135e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,887:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=7.749e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,887:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.664e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,887:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=6.424e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,887:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.672e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,888:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.203e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,888:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.469e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,960:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.373e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,961:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.372e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,961:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.003e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,962:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.264e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=9.173e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.599e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.572e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.287e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.678e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,963:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.654e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.716e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.477e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.534e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.047e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.853e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:18,964:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.279e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,015:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,016:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.175e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,016:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.717e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,016:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.310e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,017:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.973e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,019:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.844e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,019:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.620e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,019:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=3.591e-01, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,019:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.962e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,020:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.784e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,020:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.413e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,020:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.187e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,022:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.279e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,022:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.859e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,022:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.003e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,022:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.633e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,022:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.145e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,023:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.699e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,023:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.259e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,023:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.859e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,023:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.208e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,023:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.604e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:19,104:INFO:Calculating mean and std
2025-04-22 21:41:19,105:INFO:Creating metrics dataframe
2025-04-22 21:41:19,106:INFO:Uploading results into container
2025-04-22 21:41:19,107:INFO:Uploading model into container now
2025-04-22 21:41:19,107:INFO:_master_model_container: 5
2025-04-22 21:41:19,107:INFO:_display_container: 2
2025-04-22 21:41:19,107:INFO:Lars(random_state=42)
2025-04-22 21:41:19,107:INFO:create_model() successfully completed......................................
2025-04-22 21:41:19,174:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:19,175:INFO:Creating metrics dataframe
2025-04-22 21:41:19,177:INFO:Initializing Lasso Least Angle Regression
2025-04-22 21:41:19,177:INFO:Total runtime is 0.9860658288002014 minutes
2025-04-22 21:41:19,177:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:19,177:INFO:Initializing create_model()
2025-04-22 21:41:19,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:19,177:INFO:Checking exceptions
2025-04-22 21:41:19,177:INFO:Importing libraries
2025-04-22 21:41:19,177:INFO:Copying training dataset
2025-04-22 21:41:19,260:INFO:Defining folds
2025-04-22 21:41:19,260:INFO:Declaring metric variables
2025-04-22 21:41:19,261:INFO:Importing untrained model
2025-04-22 21:41:19,261:INFO:Lasso Least Angle Regression Imported successfully
2025-04-22 21:41:19,261:INFO:Starting cross validation
2025-04-22 21:41:19,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:21,464:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=2.031e+00, previous alpha=1.152e+00, with an active set of 21 regressors.
  warnings.warn(

2025-04-22 21:41:21,517:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.108e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,520:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.526e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,522:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.681e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,522:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.446e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,523:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.092e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,525:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.660e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,526:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=1.406e+01, previous alpha=5.200e+00, with an active set of 17 regressors.
  warnings.warn(

2025-04-22 21:41:21,646:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.089e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,649:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.426e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,652:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=3.362e+01, previous alpha=2.899e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 21:41:21,718:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=9.705e+01, previous alpha=9.696e+01, with an active set of 5 regressors.
  warnings.warn(

2025-04-22 21:41:21,939:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.094e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,946:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.685e+02, previous alpha=2.933e+01, with an active set of 12 regressors.
  warnings.warn(

2025-04-22 21:41:21,949:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.110e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,951:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.532e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,952:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.744e+01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,952:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.513e+01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,953:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.009e+01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:21,953:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.616e+01, previous alpha=9.605e+00, with an active set of 14 regressors.
  warnings.warn(

2025-04-22 21:41:22,024:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 10 iterations, alpha=7.797e+01, previous alpha=7.593e+01, with an active set of 7 regressors.
  warnings.warn(

2025-04-22 21:41:22,108:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.159e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:22,183:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=3.295e+01, previous alpha=2.787e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 21:41:22,235:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.095e+02, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-04-22 21:41:22,237:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=5.623e+01, previous alpha=4.556e+01, with an active set of 10 regressors.
  warnings.warn(

2025-04-22 21:41:22,319:INFO:Calculating mean and std
2025-04-22 21:41:22,320:INFO:Creating metrics dataframe
2025-04-22 21:41:22,322:INFO:Uploading results into container
2025-04-22 21:41:22,322:INFO:Uploading model into container now
2025-04-22 21:41:22,322:INFO:_master_model_container: 6
2025-04-22 21:41:22,322:INFO:_display_container: 2
2025-04-22 21:41:22,323:INFO:LassoLars(random_state=42)
2025-04-22 21:41:22,323:INFO:create_model() successfully completed......................................
2025-04-22 21:41:22,396:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:22,397:INFO:Creating metrics dataframe
2025-04-22 21:41:22,399:INFO:Initializing Orthogonal Matching Pursuit
2025-04-22 21:41:22,399:INFO:Total runtime is 1.039762588342031 minutes
2025-04-22 21:41:22,399:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:22,399:INFO:Initializing create_model()
2025-04-22 21:41:22,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:22,399:INFO:Checking exceptions
2025-04-22 21:41:22,399:INFO:Importing libraries
2025-04-22 21:41:22,399:INFO:Copying training dataset
2025-04-22 21:41:22,486:INFO:Defining folds
2025-04-22 21:41:22,486:INFO:Declaring metric variables
2025-04-22 21:41:22,486:INFO:Importing untrained model
2025-04-22 21:41:22,486:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-22 21:41:22,487:INFO:Starting cross validation
2025-04-22 21:41:22,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:25,578:INFO:Calculating mean and std
2025-04-22 21:41:25,579:INFO:Creating metrics dataframe
2025-04-22 21:41:25,581:INFO:Uploading results into container
2025-04-22 21:41:25,582:INFO:Uploading model into container now
2025-04-22 21:41:25,582:INFO:_master_model_container: 7
2025-04-22 21:41:25,582:INFO:_display_container: 2
2025-04-22 21:41:25,582:INFO:OrthogonalMatchingPursuit()
2025-04-22 21:41:25,582:INFO:create_model() successfully completed......................................
2025-04-22 21:41:25,658:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:25,658:INFO:Creating metrics dataframe
2025-04-22 21:41:25,660:INFO:Initializing Bayesian Ridge
2025-04-22 21:41:25,660:INFO:Total runtime is 1.0941255132357282 minutes
2025-04-22 21:41:25,661:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:25,661:INFO:Initializing create_model()
2025-04-22 21:41:25,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:25,661:INFO:Checking exceptions
2025-04-22 21:41:25,661:INFO:Importing libraries
2025-04-22 21:41:25,661:INFO:Copying training dataset
2025-04-22 21:41:25,740:INFO:Defining folds
2025-04-22 21:41:25,741:INFO:Declaring metric variables
2025-04-22 21:41:25,741:INFO:Importing untrained model
2025-04-22 21:41:25,741:INFO:Bayesian Ridge Imported successfully
2025-04-22 21:41:25,741:INFO:Starting cross validation
2025-04-22 21:41:25,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:30,897:INFO:Calculating mean and std
2025-04-22 21:41:30,898:INFO:Creating metrics dataframe
2025-04-22 21:41:30,899:INFO:Uploading results into container
2025-04-22 21:41:30,900:INFO:Uploading model into container now
2025-04-22 21:41:30,900:INFO:_master_model_container: 8
2025-04-22 21:41:30,900:INFO:_display_container: 2
2025-04-22 21:41:30,900:INFO:BayesianRidge()
2025-04-22 21:41:30,900:INFO:create_model() successfully completed......................................
2025-04-22 21:41:30,969:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:30,969:INFO:Creating metrics dataframe
2025-04-22 21:41:30,971:INFO:Initializing Passive Aggressive Regressor
2025-04-22 21:41:30,971:INFO:Total runtime is 1.1826345403989158 minutes
2025-04-22 21:41:30,971:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:30,971:INFO:Initializing create_model()
2025-04-22 21:41:30,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:30,971:INFO:Checking exceptions
2025-04-22 21:41:30,972:INFO:Importing libraries
2025-04-22 21:41:30,972:INFO:Copying training dataset
2025-04-22 21:41:31,052:INFO:Defining folds
2025-04-22 21:41:31,053:INFO:Declaring metric variables
2025-04-22 21:41:31,053:INFO:Importing untrained model
2025-04-22 21:41:31,053:INFO:Passive Aggressive Regressor Imported successfully
2025-04-22 21:41:31,053:INFO:Starting cross validation
2025-04-22 21:41:31,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:35,881:INFO:Calculating mean and std
2025-04-22 21:41:35,882:INFO:Creating metrics dataframe
2025-04-22 21:41:35,884:INFO:Uploading results into container
2025-04-22 21:41:35,884:INFO:Uploading model into container now
2025-04-22 21:41:35,884:INFO:_master_model_container: 9
2025-04-22 21:41:35,884:INFO:_display_container: 2
2025-04-22 21:41:35,884:INFO:PassiveAggressiveRegressor(random_state=42)
2025-04-22 21:41:35,884:INFO:create_model() successfully completed......................................
2025-04-22 21:41:35,950:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:35,950:INFO:Creating metrics dataframe
2025-04-22 21:41:35,952:INFO:Initializing Huber Regressor
2025-04-22 21:41:35,952:INFO:Total runtime is 1.2656470378239952 minutes
2025-04-22 21:41:35,953:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:35,953:INFO:Initializing create_model()
2025-04-22 21:41:35,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:35,953:INFO:Checking exceptions
2025-04-22 21:41:35,953:INFO:Importing libraries
2025-04-22 21:41:35,953:INFO:Copying training dataset
2025-04-22 21:41:36,028:INFO:Defining folds
2025-04-22 21:41:36,028:INFO:Declaring metric variables
2025-04-22 21:41:36,029:INFO:Importing untrained model
2025-04-22 21:41:36,029:INFO:Huber Regressor Imported successfully
2025-04-22 21:41:36,029:INFO:Starting cross validation
2025-04-22 21:41:36,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:41:49,359:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:49,597:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:49,752:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:49,868:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:50,141:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:50,206:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:50,336:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:50,400:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:51,189:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:51,210:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-22 21:41:51,306:INFO:Calculating mean and std
2025-04-22 21:41:51,307:INFO:Creating metrics dataframe
2025-04-22 21:41:51,308:INFO:Uploading results into container
2025-04-22 21:41:51,309:INFO:Uploading model into container now
2025-04-22 21:41:51,309:INFO:_master_model_container: 10
2025-04-22 21:41:51,309:INFO:_display_container: 2
2025-04-22 21:41:51,309:INFO:HuberRegressor()
2025-04-22 21:41:51,309:INFO:create_model() successfully completed......................................
2025-04-22 21:41:51,380:INFO:SubProcess create_model() end ==================================
2025-04-22 21:41:51,380:INFO:Creating metrics dataframe
2025-04-22 21:41:51,382:INFO:Initializing K Neighbors Regressor
2025-04-22 21:41:51,382:INFO:Total runtime is 1.522828014691671 minutes
2025-04-22 21:41:51,382:INFO:SubProcess create_model() called ==================================
2025-04-22 21:41:51,383:INFO:Initializing create_model()
2025-04-22 21:41:51,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:41:51,383:INFO:Checking exceptions
2025-04-22 21:41:51,383:INFO:Importing libraries
2025-04-22 21:41:51,383:INFO:Copying training dataset
2025-04-22 21:41:51,460:INFO:Defining folds
2025-04-22 21:41:51,460:INFO:Declaring metric variables
2025-04-22 21:41:51,461:INFO:Importing untrained model
2025-04-22 21:41:51,461:INFO:K Neighbors Regressor Imported successfully
2025-04-22 21:41:51,461:INFO:Starting cross validation
2025-04-22 21:41:51,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:42:01,166:INFO:Calculating mean and std
2025-04-22 21:42:01,166:INFO:Creating metrics dataframe
2025-04-22 21:42:01,168:INFO:Uploading results into container
2025-04-22 21:42:01,168:INFO:Uploading model into container now
2025-04-22 21:42:01,169:INFO:_master_model_container: 11
2025-04-22 21:42:01,169:INFO:_display_container: 2
2025-04-22 21:42:01,169:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-22 21:42:01,169:INFO:create_model() successfully completed......................................
2025-04-22 21:42:01,242:INFO:SubProcess create_model() end ==================================
2025-04-22 21:42:01,242:INFO:Creating metrics dataframe
2025-04-22 21:42:01,244:INFO:Initializing Decision Tree Regressor
2025-04-22 21:42:01,244:INFO:Total runtime is 1.6871928493181867 minutes
2025-04-22 21:42:01,244:INFO:SubProcess create_model() called ==================================
2025-04-22 21:42:01,245:INFO:Initializing create_model()
2025-04-22 21:42:01,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:42:01,245:INFO:Checking exceptions
2025-04-22 21:42:01,245:INFO:Importing libraries
2025-04-22 21:42:01,245:INFO:Copying training dataset
2025-04-22 21:42:01,325:INFO:Defining folds
2025-04-22 21:42:01,326:INFO:Declaring metric variables
2025-04-22 21:42:01,326:INFO:Importing untrained model
2025-04-22 21:42:01,326:INFO:Decision Tree Regressor Imported successfully
2025-04-22 21:42:01,326:INFO:Starting cross validation
2025-04-22 21:42:01,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:42:06,209:INFO:Calculating mean and std
2025-04-22 21:42:06,210:INFO:Creating metrics dataframe
2025-04-22 21:42:06,212:INFO:Uploading results into container
2025-04-22 21:42:06,212:INFO:Uploading model into container now
2025-04-22 21:42:06,213:INFO:_master_model_container: 12
2025-04-22 21:42:06,213:INFO:_display_container: 2
2025-04-22 21:42:06,213:INFO:DecisionTreeRegressor(random_state=42)
2025-04-22 21:42:06,213:INFO:create_model() successfully completed......................................
2025-04-22 21:42:06,308:INFO:SubProcess create_model() end ==================================
2025-04-22 21:42:06,309:INFO:Creating metrics dataframe
2025-04-22 21:42:06,311:INFO:Initializing Random Forest Regressor
2025-04-22 21:42:06,312:INFO:Total runtime is 1.771648983160655 minutes
2025-04-22 21:42:06,312:INFO:SubProcess create_model() called ==================================
2025-04-22 21:42:06,312:INFO:Initializing create_model()
2025-04-22 21:42:06,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:42:06,312:INFO:Checking exceptions
2025-04-22 21:42:06,312:INFO:Importing libraries
2025-04-22 21:42:06,312:INFO:Copying training dataset
2025-04-22 21:42:06,408:INFO:Defining folds
2025-04-22 21:42:06,408:INFO:Declaring metric variables
2025-04-22 21:42:06,408:INFO:Importing untrained model
2025-04-22 21:42:06,409:INFO:Random Forest Regressor Imported successfully
2025-04-22 21:42:06,409:INFO:Starting cross validation
2025-04-22 21:42:06,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:43:30,619:INFO:Calculating mean and std
2025-04-22 21:43:30,620:INFO:Creating metrics dataframe
2025-04-22 21:43:30,622:INFO:Uploading results into container
2025-04-22 21:43:30,622:INFO:Uploading model into container now
2025-04-22 21:43:30,622:INFO:_master_model_container: 13
2025-04-22 21:43:30,622:INFO:_display_container: 2
2025-04-22 21:43:30,623:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2025-04-22 21:43:30,623:INFO:create_model() successfully completed......................................
2025-04-22 21:43:30,698:INFO:SubProcess create_model() end ==================================
2025-04-22 21:43:30,698:INFO:Creating metrics dataframe
2025-04-22 21:43:30,701:INFO:Initializing Extra Trees Regressor
2025-04-22 21:43:30,701:INFO:Total runtime is 3.178132530053457 minutes
2025-04-22 21:43:30,701:INFO:SubProcess create_model() called ==================================
2025-04-22 21:43:30,701:INFO:Initializing create_model()
2025-04-22 21:43:30,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:43:30,701:INFO:Checking exceptions
2025-04-22 21:43:30,701:INFO:Importing libraries
2025-04-22 21:43:30,701:INFO:Copying training dataset
2025-04-22 21:43:30,781:INFO:Defining folds
2025-04-22 21:43:30,781:INFO:Declaring metric variables
2025-04-22 21:43:30,782:INFO:Importing untrained model
2025-04-22 21:43:30,782:INFO:Extra Trees Regressor Imported successfully
2025-04-22 21:43:30,782:INFO:Starting cross validation
2025-04-22 21:43:30,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:44:39,791:INFO:Calculating mean and std
2025-04-22 21:44:39,792:INFO:Creating metrics dataframe
2025-04-22 21:44:39,794:INFO:Uploading results into container
2025-04-22 21:44:39,794:INFO:Uploading model into container now
2025-04-22 21:44:39,795:INFO:_master_model_container: 14
2025-04-22 21:44:39,795:INFO:_display_container: 2
2025-04-22 21:44:39,795:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 21:44:39,795:INFO:create_model() successfully completed......................................
2025-04-22 21:44:39,871:INFO:SubProcess create_model() end ==================================
2025-04-22 21:44:39,871:INFO:Creating metrics dataframe
2025-04-22 21:44:39,873:INFO:Initializing AdaBoost Regressor
2025-04-22 21:44:39,873:INFO:Total runtime is 4.3309960563977565 minutes
2025-04-22 21:44:39,873:INFO:SubProcess create_model() called ==================================
2025-04-22 21:44:39,873:INFO:Initializing create_model()
2025-04-22 21:44:39,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:44:39,873:INFO:Checking exceptions
2025-04-22 21:44:39,873:INFO:Importing libraries
2025-04-22 21:44:39,873:INFO:Copying training dataset
2025-04-22 21:44:39,951:INFO:Defining folds
2025-04-22 21:44:39,951:INFO:Declaring metric variables
2025-04-22 21:44:39,952:INFO:Importing untrained model
2025-04-22 21:44:39,952:INFO:AdaBoost Regressor Imported successfully
2025-04-22 21:44:39,952:INFO:Starting cross validation
2025-04-22 21:44:39,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:45:12,705:INFO:Calculating mean and std
2025-04-22 21:45:12,706:INFO:Creating metrics dataframe
2025-04-22 21:45:12,708:INFO:Uploading results into container
2025-04-22 21:45:12,708:INFO:Uploading model into container now
2025-04-22 21:45:12,708:INFO:_master_model_container: 15
2025-04-22 21:45:12,708:INFO:_display_container: 2
2025-04-22 21:45:12,708:INFO:AdaBoostRegressor(random_state=42)
2025-04-22 21:45:12,708:INFO:create_model() successfully completed......................................
2025-04-22 21:45:12,777:INFO:SubProcess create_model() end ==================================
2025-04-22 21:45:12,777:INFO:Creating metrics dataframe
2025-04-22 21:45:12,779:INFO:Initializing Gradient Boosting Regressor
2025-04-22 21:45:12,779:INFO:Total runtime is 4.879434116681417 minutes
2025-04-22 21:45:12,779:INFO:SubProcess create_model() called ==================================
2025-04-22 21:45:12,779:INFO:Initializing create_model()
2025-04-22 21:45:12,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:45:12,779:INFO:Checking exceptions
2025-04-22 21:45:12,779:INFO:Importing libraries
2025-04-22 21:45:12,779:INFO:Copying training dataset
2025-04-22 21:45:12,846:INFO:Defining folds
2025-04-22 21:45:12,846:INFO:Declaring metric variables
2025-04-22 21:45:12,846:INFO:Importing untrained model
2025-04-22 21:45:12,846:INFO:Gradient Boosting Regressor Imported successfully
2025-04-22 21:45:12,847:INFO:Starting cross validation
2025-04-22 21:45:12,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:45:47,166:INFO:Calculating mean and std
2025-04-22 21:45:47,167:INFO:Creating metrics dataframe
2025-04-22 21:45:47,168:INFO:Uploading results into container
2025-04-22 21:45:47,169:INFO:Uploading model into container now
2025-04-22 21:45:47,169:INFO:_master_model_container: 16
2025-04-22 21:45:47,169:INFO:_display_container: 2
2025-04-22 21:45:47,169:INFO:GradientBoostingRegressor(random_state=42)
2025-04-22 21:45:47,169:INFO:create_model() successfully completed......................................
2025-04-22 21:45:47,243:INFO:SubProcess create_model() end ==================================
2025-04-22 21:45:47,243:INFO:Creating metrics dataframe
2025-04-22 21:45:47,245:INFO:Initializing Light Gradient Boosting Machine
2025-04-22 21:45:47,245:INFO:Total runtime is 5.453869291146597 minutes
2025-04-22 21:45:47,245:INFO:SubProcess create_model() called ==================================
2025-04-22 21:45:47,245:INFO:Initializing create_model()
2025-04-22 21:45:47,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:45:47,245:INFO:Checking exceptions
2025-04-22 21:45:47,245:INFO:Importing libraries
2025-04-22 21:45:47,246:INFO:Copying training dataset
2025-04-22 21:45:47,312:INFO:Defining folds
2025-04-22 21:45:47,312:INFO:Declaring metric variables
2025-04-22 21:45:47,312:INFO:Importing untrained model
2025-04-22 21:45:47,313:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-22 21:45:47,313:INFO:Starting cross validation
2025-04-22 21:45:47,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:45:52,571:INFO:Calculating mean and std
2025-04-22 21:45:52,572:INFO:Creating metrics dataframe
2025-04-22 21:45:52,574:INFO:Uploading results into container
2025-04-22 21:45:52,574:INFO:Uploading model into container now
2025-04-22 21:45:52,574:INFO:_master_model_container: 17
2025-04-22 21:45:52,574:INFO:_display_container: 2
2025-04-22 21:45:52,575:INFO:LGBMRegressor(n_jobs=-1, random_state=42)
2025-04-22 21:45:52,575:INFO:create_model() successfully completed......................................
2025-04-22 21:45:52,653:INFO:SubProcess create_model() end ==================================
2025-04-22 21:45:52,653:INFO:Creating metrics dataframe
2025-04-22 21:45:52,656:INFO:Initializing Dummy Regressor
2025-04-22 21:45:52,656:INFO:Total runtime is 5.544047514597575 minutes
2025-04-22 21:45:52,656:INFO:SubProcess create_model() called ==================================
2025-04-22 21:45:52,656:INFO:Initializing create_model()
2025-04-22 21:45:52,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016E821F0F40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:45:52,656:INFO:Checking exceptions
2025-04-22 21:45:52,656:INFO:Importing libraries
2025-04-22 21:45:52,656:INFO:Copying training dataset
2025-04-22 21:45:52,727:INFO:Defining folds
2025-04-22 21:45:52,727:INFO:Declaring metric variables
2025-04-22 21:45:52,728:INFO:Importing untrained model
2025-04-22 21:45:52,728:INFO:Dummy Regressor Imported successfully
2025-04-22 21:45:52,728:INFO:Starting cross validation
2025-04-22 21:45:52,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-22 21:45:55,866:INFO:Calculating mean and std
2025-04-22 21:45:55,867:INFO:Creating metrics dataframe
2025-04-22 21:45:55,868:INFO:Uploading results into container
2025-04-22 21:45:55,869:INFO:Uploading model into container now
2025-04-22 21:45:55,869:INFO:_master_model_container: 18
2025-04-22 21:45:55,869:INFO:_display_container: 2
2025-04-22 21:45:55,869:INFO:DummyRegressor()
2025-04-22 21:45:55,869:INFO:create_model() successfully completed......................................
2025-04-22 21:45:55,941:INFO:SubProcess create_model() end ==================================
2025-04-22 21:45:55,941:INFO:Creating metrics dataframe
2025-04-22 21:45:55,944:WARNING:C:\Users\juans\Documents\Thesis\2025\USDA\automl_venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-22 21:45:55,946:INFO:Initializing create_model()
2025-04-22 21:45:55,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016EF9564FD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=42), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-22 21:45:55,946:INFO:Checking exceptions
2025-04-22 21:45:55,946:INFO:Importing libraries
2025-04-22 21:45:55,946:INFO:Copying training dataset
2025-04-22 21:45:56,017:INFO:Defining folds
2025-04-22 21:45:56,017:INFO:Declaring metric variables
2025-04-22 21:45:56,017:INFO:Importing untrained model
2025-04-22 21:45:56,017:INFO:Declaring custom model
2025-04-22 21:45:56,018:INFO:Extra Trees Regressor Imported successfully
2025-04-22 21:45:56,020:INFO:Cross validation set to False
2025-04-22 21:45:56,020:INFO:Fitting Model
2025-04-22 21:46:02,892:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 21:46:02,892:INFO:create_model() successfully completed......................................
2025-04-22 21:46:02,974:INFO:_master_model_container: 18
2025-04-22 21:46:02,974:INFO:_display_container: 2
2025-04-22 21:46:02,974:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2025-04-22 21:46:02,974:INFO:compare_models() successfully completed......................................
2025-04-22 21:46:02,984:INFO:Initializing save_model()
2025-04-22 21:46:02,984:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=42), model_name=results\models_results\auto_ml\best_models\pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\juans\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=Simp...
                                    transformer=OneHotEncoder(cols=['state_name',
                                                                    'state_alpha',
                                                                    'unit_desc'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-22 21:46:02,984:INFO:Adding model into prep_pipe
2025-04-22 21:46:03,295:INFO:results\models_results\auto_ml\best_models\pycaret_best_model.pkl saved in current working directory
2025-04-22 21:46:03,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'county_code',
                                             'month', 'year', 'stationId',
                                             'lat_centroid', 'lon_centroid',
                                             'latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 Tra...
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name', 'stationTriplet',
                                             'name'],
                                    transformer=TargetEncoder(cols=['county_name',
                                                                    'stationTriplet',
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=42))])
2025-04-22 21:46:03,305:INFO:save_model() successfully completed......................................
2025-05-02 04:18:58,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:18:58,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:18:58,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:18:58,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:28:07,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:28:07,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:28:07,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:28:07,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:28:08,059:INFO:PyCaret RegressionExperiment
2025-05-02 04:28:08,059:INFO:Logging name: auto_ml_wo_time_top_3__log=True__out=False__nor=True__mul=False__pca=False
2025-05-02 04:28:08,059:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-02 04:28:08,059:INFO:version 3.3.2
2025-05-02 04:28:08,059:INFO:Initializing setup()
2025-05-02 04:28:08,059:INFO:self.USI: 50b4
2025-05-02 04:28:08,059:INFO:self._variable_keys: {'exp_id', 'log_plots_param', 'memory', 'X_test', 'idx', 'X_train', '_available_plots', 'target_param', 'exp_name_log', 'data', 'X', 'seed', 'y_train', 'gpu_n_jobs_param', 'transform_target_param', 'fold_generator', 'fold_shuffle_param', 'pipeline', 'gpu_param', 'html_param', 'y_test', 'fold_groups_param', 'logging_param', 'y', 'USI', '_ml_usecase', 'n_jobs_param'}
2025-05-02 04:28:08,059:INFO:Checking environment
2025-05-02 04:28:08,059:INFO:python_version: 3.10.12
2025-05-02 04:28:08,059:INFO:python_build: ('main', 'Feb  4 2025 14:57:36')
2025-05-02 04:28:08,059:INFO:machine: x86_64
2025-05-02 04:28:08,061:INFO:platform: Linux-5.15.0-134-generic-x86_64-with-glibc2.35
2025-05-02 04:28:08,062:INFO:Memory: svmem(total=1081902362624, available=1026913611776, percent=5.1, used=48258863104, free=414906548224, active=418929381376, inactive=232767365120, buffers=4781740032, cached=613955211264, shared=370020352, slab=12014039040)
2025-05-02 04:28:08,066:INFO:Physical Core: 56
2025-05-02 04:28:08,066:INFO:Logical Core: 112
2025-05-02 04:28:08,066:INFO:Checking libraries
2025-05-02 04:28:08,067:INFO:System:
2025-05-02 04:28:08,067:INFO:    python: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
2025-05-02 04:28:08,067:INFO:executable: /home/juansmartinez/Documents/thesis/venv/bin/python
2025-05-02 04:28:08,067:INFO:   machine: Linux-5.15.0-134-generic-x86_64-with-glibc2.35
2025-05-02 04:28:08,067:INFO:PyCaret required dependencies:
2025-05-02 04:28:08,085:INFO:                 pip: 25.0.1
2025-05-02 04:28:08,085:INFO:          setuptools: 78.1.0
2025-05-02 04:28:08,085:INFO:             pycaret: 3.3.2
2025-05-02 04:28:08,085:INFO:             IPython: 8.36.0
2025-05-02 04:28:08,085:INFO:          ipywidgets: 8.1.6
2025-05-02 04:28:08,085:INFO:                tqdm: 4.67.1
2025-05-02 04:28:08,085:INFO:               numpy: 1.26.4
2025-05-02 04:28:08,085:INFO:              pandas: 2.1.4
2025-05-02 04:28:08,085:INFO:              jinja2: 3.1.6
2025-05-02 04:28:08,085:INFO:               scipy: 1.11.4
2025-05-02 04:28:08,085:INFO:              joblib: 1.3.2
2025-05-02 04:28:08,085:INFO:             sklearn: 1.4.2
2025-05-02 04:28:08,085:INFO:                pyod: 2.0.4
2025-05-02 04:28:08,085:INFO:            imblearn: 0.13.0
2025-05-02 04:28:08,086:INFO:   category_encoders: 2.7.0
2025-05-02 04:28:08,086:INFO:            lightgbm: 4.6.0
2025-05-02 04:28:08,086:INFO:               numba: 0.61.2
2025-05-02 04:28:08,086:INFO:            requests: 2.32.3
2025-05-02 04:28:08,086:INFO:          matplotlib: 3.7.5
2025-05-02 04:28:08,086:INFO:          scikitplot: 0.3.7
2025-05-02 04:28:08,086:INFO:         yellowbrick: 1.5
2025-05-02 04:28:08,086:INFO:              plotly: 5.24.1
2025-05-02 04:28:08,086:INFO:    plotly-resampler: Not installed
2025-05-02 04:28:08,086:INFO:             kaleido: 0.2.1
2025-05-02 04:28:08,086:INFO:           schemdraw: 0.15
2025-05-02 04:28:08,086:INFO:         statsmodels: 0.14.4
2025-05-02 04:28:08,086:INFO:              sktime: 0.26.0
2025-05-02 04:28:08,086:INFO:               tbats: 1.1.3
2025-05-02 04:28:08,086:INFO:            pmdarima: 2.0.4
2025-05-02 04:28:08,086:INFO:              psutil: 7.0.0
2025-05-02 04:28:08,086:INFO:          markupsafe: 3.0.2
2025-05-02 04:28:08,086:INFO:             pickle5: Not installed
2025-05-02 04:28:08,086:INFO:         cloudpickle: 3.1.1
2025-05-02 04:28:08,086:INFO:         deprecation: 2.1.0
2025-05-02 04:28:08,086:INFO:              xxhash: 3.5.0
2025-05-02 04:28:08,086:INFO:           wurlitzer: 3.1.1
2025-05-02 04:28:08,086:INFO:PyCaret optional dependencies:
2025-05-02 04:28:08,097:INFO:                shap: Not installed
2025-05-02 04:28:08,097:INFO:           interpret: Not installed
2025-05-02 04:28:08,097:INFO:                umap: Not installed
2025-05-02 04:28:08,097:INFO:     ydata_profiling: Not installed
2025-05-02 04:28:08,097:INFO:  explainerdashboard: Not installed
2025-05-02 04:28:08,097:INFO:             autoviz: Not installed
2025-05-02 04:28:08,097:INFO:           fairlearn: Not installed
2025-05-02 04:28:08,097:INFO:          deepchecks: Not installed
2025-05-02 04:28:08,097:INFO:             xgboost: Not installed
2025-05-02 04:28:08,097:INFO:            catboost: Not installed
2025-05-02 04:28:08,097:INFO:              kmodes: Not installed
2025-05-02 04:28:08,097:INFO:             mlxtend: Not installed
2025-05-02 04:28:08,097:INFO:       statsforecast: Not installed
2025-05-02 04:28:08,097:INFO:        tune_sklearn: 0.5.0
2025-05-02 04:28:08,097:INFO:                 ray: 2.45.0
2025-05-02 04:28:08,097:INFO:            hyperopt: 0.2.7
2025-05-02 04:28:08,098:INFO:              optuna: 4.3.0
2025-05-02 04:28:08,098:INFO:               skopt: 0.10.2
2025-05-02 04:28:08,098:INFO:              mlflow: 2.16.0
2025-05-02 04:28:08,098:INFO:              gradio: Not installed
2025-05-02 04:28:08,098:INFO:             fastapi: Not installed
2025-05-02 04:28:08,098:INFO:             uvicorn: Not installed
2025-05-02 04:28:08,098:INFO:              m2cgen: Not installed
2025-05-02 04:28:08,098:INFO:           evidently: Not installed
2025-05-02 04:28:08,098:INFO:               fugue: Not installed
2025-05-02 04:28:08,098:INFO:           streamlit: Not installed
2025-05-02 04:28:08,098:INFO:             prophet: Not installed
2025-05-02 04:28:08,098:INFO:None
2025-05-02 04:28:08,098:INFO:Set up data.
2025-05-02 04:28:08,146:INFO:Set up folding strategy.
2025-05-02 04:28:08,147:INFO:Set up train/test split.
2025-05-02 04:28:08,180:INFO:Set up index.
2025-05-02 04:28:08,182:INFO:Assigning column types.
2025-05-02 04:28:08,211:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-02 04:28:08,211:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,216:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,220:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,352:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,356:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,360:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,443:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,485:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-02 04:28:08,491:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,581:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,627:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,631:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,762:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-02 04:28:08,770:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:08,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:28:08,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,033:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-02 04:28:09,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,304:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-02 04:28:09,402:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:28:09,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,576:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-02 04:28:09,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:09,843:INFO:Preparing preprocessing pipeline...
2025-05-02 04:28:09,843:INFO:Set up simple imputation.
2025-05-02 04:28:09,866:INFO:Set up encoding of categorical features.
2025-05-02 04:28:09,867:INFO:Set up feature normalization.
2025-05-02 04:28:09,872:INFO:Set up column name cleaning.
2025-05-02 04:28:10,194:INFO:Finished creating preprocessing pipeline.
2025-05-02 04:28:10,205:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-05-02 04:28:10,205:INFO:Creating final display dataframe.
2025-05-02 04:28:10,713:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               3802
1                        Target                                             target
2                   Target type                                         Regression
3           Original data shape                                       (128603, 18)
4        Transformed data shape                                       (128603, 20)
5   Transformed train set shape                                        (90022, 20)
6    Transformed test set shape                                        (38581, 20)
7              Numeric features                                                 15
8          Categorical features                                                  2
9      Rows with missing values                                              74.2%
10                   Preprocess                                               True
11              Imputation type                                             simple
12           Numeric imputation                                               mean
13       Categorical imputation                                               mode
14     Maximum one-hot encoding                                                 25
15              Encoding method                                               None
16                    Normalize                                               True
17             Normalize method                                             zscore
18               Fold Generator                                              KFold
19                  Fold Number                                                  5
20                     CPU Jobs                                                 -1
21                      Use GPU                                              False
22               Log Experiment                                       MlflowLogger
23              Experiment Name  auto_ml_wo_time_top_3__log=True__out=False__no...
24                          USI                                               50b4
2025-05-02 04:28:10,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:10,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:10,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:10,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:28:10,930:INFO:Logging experiment in loggers
2025-05-02 04:28:10,998:INFO:SubProcess save_model() called ==================================
2025-05-02 04:28:11,013:INFO:Initializing save_model()
2025-05-02 04:28:11,013:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/tmp/tmpyjdsvtnp/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-02 04:28:11,013:INFO:Adding model into prep_pipe
2025-05-02 04:28:11,013:WARNING:Only Model saved as it was a pipeline.
2025-05-02 04:28:11,018:INFO:/tmp/tmpyjdsvtnp/Transformation Pipeline.pkl saved in current working directory
2025-05-02 04:28:11,025:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-05-02 04:28:11,025:INFO:save_model() successfully completed......................................
2025-05-02 04:28:11,106:INFO:SubProcess save_model() end ==================================
2025-05-02 04:28:11,641:INFO:setup() successfully completed in 2.88s...............
2025-05-02 04:28:11,650:INFO:Initializing compare_models()
2025-05-02 04:28:11,650:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-05-02 04:28:11,650:INFO:Checking exceptions
2025-05-02 04:28:11,664:INFO:Preparing display monitor
2025-05-02 04:28:11,665:INFO:Initializing Linear Regression
2025-05-02 04:28:11,665:INFO:Total runtime is 1.140435536702474e-06 minutes
2025-05-02 04:28:11,665:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:11,666:INFO:Initializing create_model()
2025-05-02 04:28:11,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:11,666:INFO:Checking exceptions
2025-05-02 04:28:11,666:INFO:Importing libraries
2025-05-02 04:28:11,666:INFO:Copying training dataset
2025-05-02 04:28:11,701:INFO:Defining folds
2025-05-02 04:28:11,702:INFO:Declaring metric variables
2025-05-02 04:28:11,702:INFO:Importing untrained model
2025-05-02 04:28:11,702:INFO:Linear Regression Imported successfully
2025-05-02 04:28:11,702:INFO:Starting cross validation
2025-05-02 04:28:11,703:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:14,938:INFO:Calculating mean and std
2025-05-02 04:28:14,938:INFO:Creating metrics dataframe
2025-05-02 04:28:14,941:INFO:Uploading results into container
2025-05-02 04:28:14,942:INFO:Uploading model into container now
2025-05-02 04:28:14,942:INFO:_master_model_container: 1
2025-05-02 04:28:14,942:INFO:_display_container: 2
2025-05-02 04:28:14,943:INFO:LinearRegression(n_jobs=-1)
2025-05-02 04:28:14,943:INFO:create_model() successfully completed......................................
2025-05-02 04:28:15,077:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:15,077:INFO:Creating metrics dataframe
2025-05-02 04:28:15,081:INFO:Initializing Lasso Regression
2025-05-02 04:28:15,081:INFO:Total runtime is 0.05693763494491577 minutes
2025-05-02 04:28:15,082:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:15,082:INFO:Initializing create_model()
2025-05-02 04:28:15,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:15,082:INFO:Checking exceptions
2025-05-02 04:28:15,082:INFO:Importing libraries
2025-05-02 04:28:15,082:INFO:Copying training dataset
2025-05-02 04:28:15,148:INFO:Defining folds
2025-05-02 04:28:15,148:INFO:Declaring metric variables
2025-05-02 04:28:15,149:INFO:Importing untrained model
2025-05-02 04:28:15,149:INFO:Lasso Regression Imported successfully
2025-05-02 04:28:15,149:INFO:Starting cross validation
2025-05-02 04:28:15,151:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:16,956:INFO:Calculating mean and std
2025-05-02 04:28:16,957:INFO:Creating metrics dataframe
2025-05-02 04:28:16,959:INFO:Uploading results into container
2025-05-02 04:28:16,959:INFO:Uploading model into container now
2025-05-02 04:28:16,959:INFO:_master_model_container: 2
2025-05-02 04:28:16,960:INFO:_display_container: 2
2025-05-02 04:28:16,960:INFO:Lasso(random_state=3802)
2025-05-02 04:28:16,960:INFO:create_model() successfully completed......................................
2025-05-02 04:28:17,067:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:17,067:INFO:Creating metrics dataframe
2025-05-02 04:28:17,069:INFO:Initializing Ridge Regression
2025-05-02 04:28:17,070:INFO:Total runtime is 0.09007266759872437 minutes
2025-05-02 04:28:17,070:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:17,070:INFO:Initializing create_model()
2025-05-02 04:28:17,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:17,070:INFO:Checking exceptions
2025-05-02 04:28:17,070:INFO:Importing libraries
2025-05-02 04:28:17,070:INFO:Copying training dataset
2025-05-02 04:28:17,114:INFO:Defining folds
2025-05-02 04:28:17,114:INFO:Declaring metric variables
2025-05-02 04:28:17,115:INFO:Importing untrained model
2025-05-02 04:28:17,115:INFO:Ridge Regression Imported successfully
2025-05-02 04:28:17,115:INFO:Starting cross validation
2025-05-02 04:28:17,116:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:18,938:INFO:Calculating mean and std
2025-05-02 04:28:18,939:INFO:Creating metrics dataframe
2025-05-02 04:28:18,941:INFO:Uploading results into container
2025-05-02 04:28:18,941:INFO:Uploading model into container now
2025-05-02 04:28:18,941:INFO:_master_model_container: 3
2025-05-02 04:28:18,941:INFO:_display_container: 2
2025-05-02 04:28:18,942:INFO:Ridge(random_state=3802)
2025-05-02 04:28:18,942:INFO:create_model() successfully completed......................................
2025-05-02 04:28:19,028:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:19,028:INFO:Creating metrics dataframe
2025-05-02 04:28:19,031:INFO:Initializing Elastic Net
2025-05-02 04:28:19,031:INFO:Total runtime is 0.12276828686396282 minutes
2025-05-02 04:28:19,031:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:19,032:INFO:Initializing create_model()
2025-05-02 04:28:19,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:19,032:INFO:Checking exceptions
2025-05-02 04:28:19,032:INFO:Importing libraries
2025-05-02 04:28:19,032:INFO:Copying training dataset
2025-05-02 04:28:19,079:INFO:Defining folds
2025-05-02 04:28:19,079:INFO:Declaring metric variables
2025-05-02 04:28:19,079:INFO:Importing untrained model
2025-05-02 04:28:19,079:INFO:Elastic Net Imported successfully
2025-05-02 04:28:19,080:INFO:Starting cross validation
2025-05-02 04:28:19,081:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:20,892:INFO:Calculating mean and std
2025-05-02 04:28:20,893:INFO:Creating metrics dataframe
2025-05-02 04:28:20,894:INFO:Uploading results into container
2025-05-02 04:28:20,895:INFO:Uploading model into container now
2025-05-02 04:28:20,895:INFO:_master_model_container: 4
2025-05-02 04:28:20,895:INFO:_display_container: 2
2025-05-02 04:28:20,895:INFO:ElasticNet(random_state=3802)
2025-05-02 04:28:20,895:INFO:create_model() successfully completed......................................
2025-05-02 04:28:20,990:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:20,990:INFO:Creating metrics dataframe
2025-05-02 04:28:20,993:INFO:Initializing Least Angle Regression
2025-05-02 04:28:20,993:INFO:Total runtime is 0.15546128749847413 minutes
2025-05-02 04:28:20,993:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:20,993:INFO:Initializing create_model()
2025-05-02 04:28:20,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:20,993:INFO:Checking exceptions
2025-05-02 04:28:20,993:INFO:Importing libraries
2025-05-02 04:28:20,993:INFO:Copying training dataset
2025-05-02 04:28:21,037:INFO:Defining folds
2025-05-02 04:28:21,037:INFO:Declaring metric variables
2025-05-02 04:28:21,038:INFO:Importing untrained model
2025-05-02 04:28:21,039:INFO:Least Angle Regression Imported successfully
2025-05-02 04:28:21,039:INFO:Starting cross validation
2025-05-02 04:28:21,041:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:22,817:INFO:Calculating mean and std
2025-05-02 04:28:22,817:INFO:Creating metrics dataframe
2025-05-02 04:28:22,819:INFO:Uploading results into container
2025-05-02 04:28:22,819:INFO:Uploading model into container now
2025-05-02 04:28:22,820:INFO:_master_model_container: 5
2025-05-02 04:28:22,820:INFO:_display_container: 2
2025-05-02 04:28:22,820:INFO:Lars(random_state=3802)
2025-05-02 04:28:22,820:INFO:create_model() successfully completed......................................
2025-05-02 04:28:22,914:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:22,914:INFO:Creating metrics dataframe
2025-05-02 04:28:22,916:INFO:Initializing Lasso Least Angle Regression
2025-05-02 04:28:22,917:INFO:Total runtime is 0.18752293586730956 minutes
2025-05-02 04:28:22,917:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:22,917:INFO:Initializing create_model()
2025-05-02 04:28:22,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:22,917:INFO:Checking exceptions
2025-05-02 04:28:22,917:INFO:Importing libraries
2025-05-02 04:28:22,917:INFO:Copying training dataset
2025-05-02 04:28:22,962:INFO:Defining folds
2025-05-02 04:28:22,962:INFO:Declaring metric variables
2025-05-02 04:28:22,962:INFO:Importing untrained model
2025-05-02 04:28:22,962:INFO:Lasso Least Angle Regression Imported successfully
2025-05-02 04:28:22,963:INFO:Starting cross validation
2025-05-02 04:28:22,964:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:24,777:INFO:Calculating mean and std
2025-05-02 04:28:24,777:INFO:Creating metrics dataframe
2025-05-02 04:28:24,780:INFO:Uploading results into container
2025-05-02 04:28:24,780:INFO:Uploading model into container now
2025-05-02 04:28:24,781:INFO:_master_model_container: 6
2025-05-02 04:28:24,781:INFO:_display_container: 2
2025-05-02 04:28:24,781:INFO:LassoLars(random_state=3802)
2025-05-02 04:28:24,781:INFO:create_model() successfully completed......................................
2025-05-02 04:28:24,910:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:24,910:INFO:Creating metrics dataframe
2025-05-02 04:28:24,914:INFO:Initializing Orthogonal Matching Pursuit
2025-05-02 04:28:24,914:INFO:Total runtime is 0.22081960837046305 minutes
2025-05-02 04:28:24,915:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:24,915:INFO:Initializing create_model()
2025-05-02 04:28:24,915:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:24,915:INFO:Checking exceptions
2025-05-02 04:28:24,915:INFO:Importing libraries
2025-05-02 04:28:24,915:INFO:Copying training dataset
2025-05-02 04:28:24,978:INFO:Defining folds
2025-05-02 04:28:24,978:INFO:Declaring metric variables
2025-05-02 04:28:24,978:INFO:Importing untrained model
2025-05-02 04:28:24,979:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-02 04:28:24,979:INFO:Starting cross validation
2025-05-02 04:28:24,981:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:27,197:INFO:Calculating mean and std
2025-05-02 04:28:27,197:INFO:Creating metrics dataframe
2025-05-02 04:28:27,199:INFO:Uploading results into container
2025-05-02 04:28:27,199:INFO:Uploading model into container now
2025-05-02 04:28:27,200:INFO:_master_model_container: 7
2025-05-02 04:28:27,200:INFO:_display_container: 2
2025-05-02 04:28:27,200:INFO:OrthogonalMatchingPursuit()
2025-05-02 04:28:27,200:INFO:create_model() successfully completed......................................
2025-05-02 04:28:27,292:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:27,292:INFO:Creating metrics dataframe
2025-05-02 04:28:27,295:INFO:Initializing Bayesian Ridge
2025-05-02 04:28:27,295:INFO:Total runtime is 0.26050192912419634 minutes
2025-05-02 04:28:27,295:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:27,296:INFO:Initializing create_model()
2025-05-02 04:28:27,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:27,296:INFO:Checking exceptions
2025-05-02 04:28:27,296:INFO:Importing libraries
2025-05-02 04:28:27,296:INFO:Copying training dataset
2025-05-02 04:28:27,341:INFO:Defining folds
2025-05-02 04:28:27,341:INFO:Declaring metric variables
2025-05-02 04:28:27,341:INFO:Importing untrained model
2025-05-02 04:28:27,341:INFO:Bayesian Ridge Imported successfully
2025-05-02 04:28:27,342:INFO:Starting cross validation
2025-05-02 04:28:27,343:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:29,234:INFO:Calculating mean and std
2025-05-02 04:28:29,235:INFO:Creating metrics dataframe
2025-05-02 04:28:29,237:INFO:Uploading results into container
2025-05-02 04:28:29,237:INFO:Uploading model into container now
2025-05-02 04:28:29,237:INFO:_master_model_container: 8
2025-05-02 04:28:29,237:INFO:_display_container: 2
2025-05-02 04:28:29,238:INFO:BayesianRidge()
2025-05-02 04:28:29,238:INFO:create_model() successfully completed......................................
2025-05-02 04:28:29,336:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:29,336:INFO:Creating metrics dataframe
2025-05-02 04:28:29,338:INFO:Initializing Passive Aggressive Regressor
2025-05-02 04:28:29,339:INFO:Total runtime is 0.29455633163452144 minutes
2025-05-02 04:28:29,339:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:29,339:INFO:Initializing create_model()
2025-05-02 04:28:29,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:29,339:INFO:Checking exceptions
2025-05-02 04:28:29,339:INFO:Importing libraries
2025-05-02 04:28:29,339:INFO:Copying training dataset
2025-05-02 04:28:29,383:INFO:Defining folds
2025-05-02 04:28:29,384:INFO:Declaring metric variables
2025-05-02 04:28:29,384:INFO:Importing untrained model
2025-05-02 04:28:29,384:INFO:Passive Aggressive Regressor Imported successfully
2025-05-02 04:28:29,384:INFO:Starting cross validation
2025-05-02 04:28:29,386:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:31,316:INFO:Calculating mean and std
2025-05-02 04:28:31,317:INFO:Creating metrics dataframe
2025-05-02 04:28:31,319:INFO:Uploading results into container
2025-05-02 04:28:31,319:INFO:Uploading model into container now
2025-05-02 04:28:31,320:INFO:_master_model_container: 9
2025-05-02 04:28:31,320:INFO:_display_container: 2
2025-05-02 04:28:31,320:INFO:PassiveAggressiveRegressor(random_state=3802)
2025-05-02 04:28:31,320:INFO:create_model() successfully completed......................................
2025-05-02 04:28:31,433:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:31,434:INFO:Creating metrics dataframe
2025-05-02 04:28:31,436:INFO:Initializing Huber Regressor
2025-05-02 04:28:31,436:INFO:Total runtime is 0.32952179511388136 minutes
2025-05-02 04:28:31,437:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:31,437:INFO:Initializing create_model()
2025-05-02 04:28:31,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:31,437:INFO:Checking exceptions
2025-05-02 04:28:31,437:INFO:Importing libraries
2025-05-02 04:28:31,437:INFO:Copying training dataset
2025-05-02 04:28:31,481:INFO:Defining folds
2025-05-02 04:28:31,481:INFO:Declaring metric variables
2025-05-02 04:28:31,481:INFO:Importing untrained model
2025-05-02 04:28:31,481:INFO:Huber Regressor Imported successfully
2025-05-02 04:28:31,481:INFO:Starting cross validation
2025-05-02 04:28:31,483:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:34,050:INFO:Calculating mean and std
2025-05-02 04:28:34,050:INFO:Creating metrics dataframe
2025-05-02 04:28:34,052:INFO:Uploading results into container
2025-05-02 04:28:34,053:INFO:Uploading model into container now
2025-05-02 04:28:34,053:INFO:_master_model_container: 10
2025-05-02 04:28:34,053:INFO:_display_container: 2
2025-05-02 04:28:34,053:INFO:HuberRegressor()
2025-05-02 04:28:34,053:INFO:create_model() successfully completed......................................
2025-05-02 04:28:34,134:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:34,135:INFO:Creating metrics dataframe
2025-05-02 04:28:34,137:INFO:Initializing K Neighbors Regressor
2025-05-02 04:28:34,137:INFO:Total runtime is 0.37453397115071607 minutes
2025-05-02 04:28:34,137:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:34,138:INFO:Initializing create_model()
2025-05-02 04:28:34,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:34,138:INFO:Checking exceptions
2025-05-02 04:28:34,138:INFO:Importing libraries
2025-05-02 04:28:34,138:INFO:Copying training dataset
2025-05-02 04:28:34,189:INFO:Defining folds
2025-05-02 04:28:34,189:INFO:Declaring metric variables
2025-05-02 04:28:34,189:INFO:Importing untrained model
2025-05-02 04:28:34,189:INFO:K Neighbors Regressor Imported successfully
2025-05-02 04:28:34,190:INFO:Starting cross validation
2025-05-02 04:28:34,191:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:41,921:INFO:Calculating mean and std
2025-05-02 04:28:41,921:INFO:Creating metrics dataframe
2025-05-02 04:28:41,923:INFO:Uploading results into container
2025-05-02 04:28:41,923:INFO:Uploading model into container now
2025-05-02 04:28:41,923:INFO:_master_model_container: 11
2025-05-02 04:28:41,923:INFO:_display_container: 2
2025-05-02 04:28:41,924:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-02 04:28:41,924:INFO:create_model() successfully completed......................................
2025-05-02 04:28:42,018:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:42,019:INFO:Creating metrics dataframe
2025-05-02 04:28:42,021:INFO:Initializing Decision Tree Regressor
2025-05-02 04:28:42,021:INFO:Total runtime is 0.5059362530708312 minutes
2025-05-02 04:28:42,021:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:42,022:INFO:Initializing create_model()
2025-05-02 04:28:42,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:42,022:INFO:Checking exceptions
2025-05-02 04:28:42,022:INFO:Importing libraries
2025-05-02 04:28:42,022:INFO:Copying training dataset
2025-05-02 04:28:42,065:INFO:Defining folds
2025-05-02 04:28:42,065:INFO:Declaring metric variables
2025-05-02 04:28:42,065:INFO:Importing untrained model
2025-05-02 04:28:42,065:INFO:Decision Tree Regressor Imported successfully
2025-05-02 04:28:42,066:INFO:Starting cross validation
2025-05-02 04:28:42,067:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:44,723:INFO:Calculating mean and std
2025-05-02 04:28:44,723:INFO:Creating metrics dataframe
2025-05-02 04:28:44,725:INFO:Uploading results into container
2025-05-02 04:28:44,726:INFO:Uploading model into container now
2025-05-02 04:28:44,726:INFO:_master_model_container: 12
2025-05-02 04:28:44,726:INFO:_display_container: 2
2025-05-02 04:28:44,727:INFO:DecisionTreeRegressor(random_state=3802)
2025-05-02 04:28:44,727:INFO:create_model() successfully completed......................................
2025-05-02 04:28:44,820:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:44,821:INFO:Creating metrics dataframe
2025-05-02 04:28:44,823:INFO:Initializing Random Forest Regressor
2025-05-02 04:28:44,823:INFO:Total runtime is 0.5526354551315307 minutes
2025-05-02 04:28:44,823:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:44,824:INFO:Initializing create_model()
2025-05-02 04:28:44,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:44,824:INFO:Checking exceptions
2025-05-02 04:28:44,824:INFO:Importing libraries
2025-05-02 04:28:44,824:INFO:Copying training dataset
2025-05-02 04:28:44,867:INFO:Defining folds
2025-05-02 04:28:44,867:INFO:Declaring metric variables
2025-05-02 04:28:44,868:INFO:Importing untrained model
2025-05-02 04:28:44,868:INFO:Random Forest Regressor Imported successfully
2025-05-02 04:28:44,868:INFO:Starting cross validation
2025-05-02 04:28:44,870:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:48,309:INFO:Calculating mean and std
2025-05-02 04:28:48,310:INFO:Creating metrics dataframe
2025-05-02 04:28:48,312:INFO:Uploading results into container
2025-05-02 04:28:48,312:INFO:Uploading model into container now
2025-05-02 04:28:48,312:INFO:_master_model_container: 13
2025-05-02 04:28:48,312:INFO:_display_container: 2
2025-05-02 04:28:48,313:INFO:RandomForestRegressor(n_jobs=-1, random_state=3802)
2025-05-02 04:28:48,313:INFO:create_model() successfully completed......................................
2025-05-02 04:28:48,401:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:48,401:INFO:Creating metrics dataframe
2025-05-02 04:28:48,404:INFO:Initializing Extra Trees Regressor
2025-05-02 04:28:48,404:INFO:Total runtime is 0.612315531571706 minutes
2025-05-02 04:28:48,404:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:48,405:INFO:Initializing create_model()
2025-05-02 04:28:48,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:48,405:INFO:Checking exceptions
2025-05-02 04:28:48,405:INFO:Importing libraries
2025-05-02 04:28:48,405:INFO:Copying training dataset
2025-05-02 04:28:48,450:INFO:Defining folds
2025-05-02 04:28:48,450:INFO:Declaring metric variables
2025-05-02 04:28:48,450:INFO:Importing untrained model
2025-05-02 04:28:48,450:INFO:Extra Trees Regressor Imported successfully
2025-05-02 04:28:48,451:INFO:Starting cross validation
2025-05-02 04:28:48,452:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:51,542:INFO:Calculating mean and std
2025-05-02 04:28:51,543:INFO:Creating metrics dataframe
2025-05-02 04:28:51,546:INFO:Uploading results into container
2025-05-02 04:28:51,546:INFO:Uploading model into container now
2025-05-02 04:28:51,547:INFO:_master_model_container: 14
2025-05-02 04:28:51,547:INFO:_display_container: 2
2025-05-02 04:28:51,547:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3802)
2025-05-02 04:28:51,547:INFO:create_model() successfully completed......................................
2025-05-02 04:28:51,675:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:51,675:INFO:Creating metrics dataframe
2025-05-02 04:28:51,679:INFO:Initializing AdaBoost Regressor
2025-05-02 04:28:51,679:INFO:Total runtime is 0.6668953657150267 minutes
2025-05-02 04:28:51,679:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:51,679:INFO:Initializing create_model()
2025-05-02 04:28:51,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:51,679:INFO:Checking exceptions
2025-05-02 04:28:51,679:INFO:Importing libraries
2025-05-02 04:28:51,680:INFO:Copying training dataset
2025-05-02 04:28:51,732:INFO:Defining folds
2025-05-02 04:28:51,732:INFO:Declaring metric variables
2025-05-02 04:28:51,732:INFO:Importing untrained model
2025-05-02 04:28:51,733:INFO:AdaBoost Regressor Imported successfully
2025-05-02 04:28:51,733:INFO:Starting cross validation
2025-05-02 04:28:51,734:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:28:54,813:INFO:Calculating mean and std
2025-05-02 04:28:54,813:INFO:Creating metrics dataframe
2025-05-02 04:28:54,815:INFO:Uploading results into container
2025-05-02 04:28:54,815:INFO:Uploading model into container now
2025-05-02 04:28:54,816:INFO:_master_model_container: 15
2025-05-02 04:28:54,816:INFO:_display_container: 2
2025-05-02 04:28:54,816:INFO:AdaBoostRegressor(random_state=3802)
2025-05-02 04:28:54,816:INFO:create_model() successfully completed......................................
2025-05-02 04:28:54,924:INFO:SubProcess create_model() end ==================================
2025-05-02 04:28:54,924:INFO:Creating metrics dataframe
2025-05-02 04:28:54,928:INFO:Initializing Gradient Boosting Regressor
2025-05-02 04:28:54,928:INFO:Total runtime is 0.7210542201995849 minutes
2025-05-02 04:28:54,929:INFO:SubProcess create_model() called ==================================
2025-05-02 04:28:54,929:INFO:Initializing create_model()
2025-05-02 04:28:54,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:28:54,929:INFO:Checking exceptions
2025-05-02 04:28:54,929:INFO:Importing libraries
2025-05-02 04:28:54,929:INFO:Copying training dataset
2025-05-02 04:28:54,998:INFO:Defining folds
2025-05-02 04:28:54,998:INFO:Declaring metric variables
2025-05-02 04:28:54,998:INFO:Importing untrained model
2025-05-02 04:28:54,999:INFO:Gradient Boosting Regressor Imported successfully
2025-05-02 04:28:54,999:INFO:Starting cross validation
2025-05-02 04:28:55,001:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:29:01,194:INFO:Calculating mean and std
2025-05-02 04:29:01,195:INFO:Creating metrics dataframe
2025-05-02 04:29:01,198:INFO:Uploading results into container
2025-05-02 04:29:01,199:INFO:Uploading model into container now
2025-05-02 04:29:01,199:INFO:_master_model_container: 16
2025-05-02 04:29:01,199:INFO:_display_container: 2
2025-05-02 04:29:01,200:INFO:GradientBoostingRegressor(random_state=3802)
2025-05-02 04:29:01,200:INFO:create_model() successfully completed......................................
2025-05-02 04:29:01,308:INFO:SubProcess create_model() end ==================================
2025-05-02 04:29:01,308:INFO:Creating metrics dataframe
2025-05-02 04:29:01,312:INFO:Initializing Light Gradient Boosting Machine
2025-05-02 04:29:01,312:INFO:Total runtime is 0.8274454553922017 minutes
2025-05-02 04:29:01,312:INFO:SubProcess create_model() called ==================================
2025-05-02 04:29:01,312:INFO:Initializing create_model()
2025-05-02 04:29:01,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f55d081fbe0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f55cb65c940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:29:01,313:INFO:Checking exceptions
2025-05-02 04:29:01,313:INFO:Importing libraries
2025-05-02 04:29:01,313:INFO:Copying training dataset
2025-05-02 04:29:01,381:INFO:Defining folds
2025-05-02 04:29:01,381:INFO:Declaring metric variables
2025-05-02 04:29:01,381:INFO:Importing untrained model
2025-05-02 04:29:01,382:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-02 04:29:01,383:INFO:Starting cross validation
2025-05-02 04:29:01,385:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:34:06,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:34:06,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:34:06,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:34:06,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:36:02,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:36:02,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:36:02,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:36:02,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-02 04:36:02,870:INFO:PyCaret RegressionExperiment
2025-05-02 04:36:02,870:INFO:Logging name: auto_ml_wo_time_top_3__log=True__out=False__nor=True__mul=False__pca=False
2025-05-02 04:36:02,870:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-02 04:36:02,870:INFO:version 3.3.2
2025-05-02 04:36:02,870:INFO:Initializing setup()
2025-05-02 04:36:02,870:INFO:self.USI: 0bd1
2025-05-02 04:36:02,870:INFO:self._variable_keys: {'seed', 'y', 'X_test', 'exp_id', 'y_test', 'gpu_param', 'fold_shuffle_param', '_available_plots', 'transform_target_param', 'USI', 'X', 'X_train', 'log_plots_param', 'data', 'exp_name_log', 'target_param', 'logging_param', 'html_param', 'gpu_n_jobs_param', 'y_train', 'fold_generator', 'memory', 'pipeline', '_ml_usecase', 'n_jobs_param', 'fold_groups_param', 'idx'}
2025-05-02 04:36:02,871:INFO:Checking environment
2025-05-02 04:36:02,871:INFO:python_version: 3.10.12
2025-05-02 04:36:02,871:INFO:python_build: ('main', 'Feb  4 2025 14:57:36')
2025-05-02 04:36:02,871:INFO:machine: x86_64
2025-05-02 04:36:02,873:INFO:platform: Linux-5.15.0-134-generic-x86_64-with-glibc2.35
2025-05-02 04:36:02,873:INFO:Memory: svmem(total=1081902362624, available=1025729245184, percent=5.2, used=49433341952, free=413695959040, active=418930114560, inactive=233943920640, buffers=4781752320, cached=613991309312, shared=379899904, slab=12034125824)
2025-05-02 04:36:02,878:INFO:Physical Core: 56
2025-05-02 04:36:02,878:INFO:Logical Core: 112
2025-05-02 04:36:02,878:INFO:Checking libraries
2025-05-02 04:36:02,878:INFO:System:
2025-05-02 04:36:02,879:INFO:    python: 3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]
2025-05-02 04:36:02,879:INFO:executable: /home/juansmartinez/Documents/thesis/venv/bin/python
2025-05-02 04:36:02,879:INFO:   machine: Linux-5.15.0-134-generic-x86_64-with-glibc2.35
2025-05-02 04:36:02,879:INFO:PyCaret required dependencies:
2025-05-02 04:36:02,897:INFO:                 pip: 25.0.1
2025-05-02 04:36:02,897:INFO:          setuptools: 78.1.0
2025-05-02 04:36:02,897:INFO:             pycaret: 3.3.2
2025-05-02 04:36:02,897:INFO:             IPython: 8.36.0
2025-05-02 04:36:02,897:INFO:          ipywidgets: 8.1.6
2025-05-02 04:36:02,897:INFO:                tqdm: 4.67.1
2025-05-02 04:36:02,897:INFO:               numpy: 1.26.4
2025-05-02 04:36:02,897:INFO:              pandas: 2.1.4
2025-05-02 04:36:02,897:INFO:              jinja2: 3.1.6
2025-05-02 04:36:02,897:INFO:               scipy: 1.11.4
2025-05-02 04:36:02,897:INFO:              joblib: 1.3.2
2025-05-02 04:36:02,897:INFO:             sklearn: 1.4.2
2025-05-02 04:36:02,897:INFO:                pyod: 2.0.4
2025-05-02 04:36:02,897:INFO:            imblearn: 0.13.0
2025-05-02 04:36:02,897:INFO:   category_encoders: 2.7.0
2025-05-02 04:36:02,897:INFO:            lightgbm: 4.6.0
2025-05-02 04:36:02,897:INFO:               numba: 0.61.2
2025-05-02 04:36:02,897:INFO:            requests: 2.32.3
2025-05-02 04:36:02,897:INFO:          matplotlib: 3.7.5
2025-05-02 04:36:02,898:INFO:          scikitplot: 0.3.7
2025-05-02 04:36:02,898:INFO:         yellowbrick: 1.5
2025-05-02 04:36:02,898:INFO:              plotly: 5.24.1
2025-05-02 04:36:02,898:INFO:    plotly-resampler: Not installed
2025-05-02 04:36:02,898:INFO:             kaleido: 0.2.1
2025-05-02 04:36:02,898:INFO:           schemdraw: 0.15
2025-05-02 04:36:02,898:INFO:         statsmodels: 0.14.4
2025-05-02 04:36:02,898:INFO:              sktime: 0.26.0
2025-05-02 04:36:02,898:INFO:               tbats: 1.1.3
2025-05-02 04:36:02,898:INFO:            pmdarima: 2.0.4
2025-05-02 04:36:02,898:INFO:              psutil: 7.0.0
2025-05-02 04:36:02,898:INFO:          markupsafe: 3.0.2
2025-05-02 04:36:02,898:INFO:             pickle5: Not installed
2025-05-02 04:36:02,898:INFO:         cloudpickle: 3.1.1
2025-05-02 04:36:02,898:INFO:         deprecation: 2.1.0
2025-05-02 04:36:02,898:INFO:              xxhash: 3.5.0
2025-05-02 04:36:02,898:INFO:           wurlitzer: 3.1.1
2025-05-02 04:36:02,898:INFO:PyCaret optional dependencies:
2025-05-02 04:36:02,910:INFO:                shap: Not installed
2025-05-02 04:36:02,910:INFO:           interpret: Not installed
2025-05-02 04:36:02,910:INFO:                umap: Not installed
2025-05-02 04:36:02,910:INFO:     ydata_profiling: Not installed
2025-05-02 04:36:02,910:INFO:  explainerdashboard: Not installed
2025-05-02 04:36:02,910:INFO:             autoviz: Not installed
2025-05-02 04:36:02,910:INFO:           fairlearn: Not installed
2025-05-02 04:36:02,910:INFO:          deepchecks: Not installed
2025-05-02 04:36:02,910:INFO:             xgboost: Not installed
2025-05-02 04:36:02,910:INFO:            catboost: Not installed
2025-05-02 04:36:02,910:INFO:              kmodes: Not installed
2025-05-02 04:36:02,910:INFO:             mlxtend: Not installed
2025-05-02 04:36:02,910:INFO:       statsforecast: Not installed
2025-05-02 04:36:02,910:INFO:        tune_sklearn: 0.5.0
2025-05-02 04:36:02,910:INFO:                 ray: 2.45.0
2025-05-02 04:36:02,910:INFO:            hyperopt: 0.2.7
2025-05-02 04:36:02,910:INFO:              optuna: 4.3.0
2025-05-02 04:36:02,910:INFO:               skopt: 0.10.2
2025-05-02 04:36:02,910:INFO:              mlflow: 2.16.0
2025-05-02 04:36:02,910:INFO:              gradio: Not installed
2025-05-02 04:36:02,910:INFO:             fastapi: Not installed
2025-05-02 04:36:02,911:INFO:             uvicorn: Not installed
2025-05-02 04:36:02,911:INFO:              m2cgen: Not installed
2025-05-02 04:36:02,911:INFO:           evidently: Not installed
2025-05-02 04:36:02,911:INFO:               fugue: Not installed
2025-05-02 04:36:02,911:INFO:           streamlit: Not installed
2025-05-02 04:36:02,911:INFO:             prophet: Not installed
2025-05-02 04:36:02,911:INFO:None
2025-05-02 04:36:02,911:INFO:Set up data.
2025-05-02 04:36:02,924:INFO:Set up folding strategy.
2025-05-02 04:36:02,924:INFO:Set up train/test split.
2025-05-02 04:36:02,936:INFO:Set up index.
2025-05-02 04:36:02,936:INFO:Assigning column types.
2025-05-02 04:36:02,947:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-02 04:36:02,947:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-02 04:36:02,951:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:36:02,956:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,059:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,063:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,180:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-02 04:36:03,184:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,299:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,303:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,412:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-02 04:36:03,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,531:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,598:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,640:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-02 04:36:03,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,868:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-02 04:36:03,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:03,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:03,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-02 04:36:04,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,095:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-02 04:36:04,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,325:INFO:Preparing preprocessing pipeline...
2025-05-02 04:36:04,325:INFO:Set up simple imputation.
2025-05-02 04:36:04,336:INFO:Set up encoding of categorical features.
2025-05-02 04:36:04,336:INFO:Set up feature normalization.
2025-05-02 04:36:04,338:INFO:Set up column name cleaning.
2025-05-02 04:36:04,494:INFO:Finished creating preprocessing pipeline.
2025-05-02 04:36:04,505:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-05-02 04:36:04,505:INFO:Creating final display dataframe.
2025-05-02 04:36:04,823:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               1994
1                        Target                                             target
2                   Target type                                         Regression
3           Original data shape                                        (33240, 18)
4        Transformed data shape                                        (33240, 20)
5   Transformed train set shape                                        (23268, 20)
6    Transformed test set shape                                         (9972, 20)
7              Numeric features                                                 15
8          Categorical features                                                  2
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13     Maximum one-hot encoding                                                 25
14              Encoding method                                               None
15                    Normalize                                               True
16             Normalize method                                             zscore
17               Fold Generator                                              KFold
18                  Fold Number                                                  5
19                     CPU Jobs                                                 -1
20                      Use GPU                                              False
21               Log Experiment                                       MlflowLogger
22              Experiment Name  auto_ml_wo_time_top_3__log=True__out=False__no...
23                          USI                                               0bd1
2025-05-02 04:36:04,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:04,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:05,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:05,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-02 04:36:05,049:INFO:Logging experiment in loggers
2025-05-02 04:36:05,139:INFO:SubProcess save_model() called ==================================
2025-05-02 04:36:05,157:INFO:Initializing save_model()
2025-05-02 04:36:05,158:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), model_name=/tmp/tmpl88yhb4q/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-02 04:36:05,158:INFO:Adding model into prep_pipe
2025-05-02 04:36:05,158:WARNING:Only Model saved as it was a pipeline.
2025-05-02 04:36:05,163:INFO:/tmp/tmpl88yhb4q/Transformation Pipeline.pkl saved in current working directory
2025-05-02 04:36:05,174:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-05-02 04:36:05,175:INFO:save_model() successfully completed......................................
2025-05-02 04:36:05,283:INFO:SubProcess save_model() end ==================================
2025-05-02 04:36:05,514:INFO:setup() successfully completed in 2.19s...............
2025-05-02 04:36:05,523:INFO:Initializing compare_models()
2025-05-02 04:36:05,523:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, include=None, fold=None, round=4, cross_validation=True, sort=RMSE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'RMSE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-05-02 04:36:05,523:INFO:Checking exceptions
2025-05-02 04:36:05,528:INFO:Preparing display monitor
2025-05-02 04:36:05,530:INFO:Initializing Linear Regression
2025-05-02 04:36:05,530:INFO:Total runtime is 1.0212262471516927e-06 minutes
2025-05-02 04:36:05,530:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:05,530:INFO:Initializing create_model()
2025-05-02 04:36:05,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:05,530:INFO:Checking exceptions
2025-05-02 04:36:05,530:INFO:Importing libraries
2025-05-02 04:36:05,530:INFO:Copying training dataset
2025-05-02 04:36:05,542:INFO:Defining folds
2025-05-02 04:36:05,542:INFO:Declaring metric variables
2025-05-02 04:36:05,542:INFO:Importing untrained model
2025-05-02 04:36:05,542:INFO:Linear Regression Imported successfully
2025-05-02 04:36:05,542:INFO:Starting cross validation
2025-05-02 04:36:05,544:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:09,059:INFO:Calculating mean and std
2025-05-02 04:36:09,060:INFO:Creating metrics dataframe
2025-05-02 04:36:09,063:INFO:Uploading results into container
2025-05-02 04:36:09,064:INFO:Uploading model into container now
2025-05-02 04:36:09,064:INFO:_master_model_container: 1
2025-05-02 04:36:09,065:INFO:_display_container: 2
2025-05-02 04:36:09,065:INFO:LinearRegression(n_jobs=-1)
2025-05-02 04:36:09,065:INFO:create_model() successfully completed......................................
2025-05-02 04:36:09,194:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:09,194:INFO:Creating metrics dataframe
2025-05-02 04:36:09,198:INFO:Initializing Lasso Regression
2025-05-02 04:36:09,199:INFO:Total runtime is 0.06115143299102783 minutes
2025-05-02 04:36:09,199:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:09,199:INFO:Initializing create_model()
2025-05-02 04:36:09,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:09,199:INFO:Checking exceptions
2025-05-02 04:36:09,199:INFO:Importing libraries
2025-05-02 04:36:09,200:INFO:Copying training dataset
2025-05-02 04:36:09,224:INFO:Defining folds
2025-05-02 04:36:09,224:INFO:Declaring metric variables
2025-05-02 04:36:09,224:INFO:Importing untrained model
2025-05-02 04:36:09,225:INFO:Lasso Regression Imported successfully
2025-05-02 04:36:09,225:INFO:Starting cross validation
2025-05-02 04:36:09,227:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:11,356:INFO:Calculating mean and std
2025-05-02 04:36:11,357:INFO:Creating metrics dataframe
2025-05-02 04:36:11,359:INFO:Uploading results into container
2025-05-02 04:36:11,359:INFO:Uploading model into container now
2025-05-02 04:36:11,360:INFO:_master_model_container: 2
2025-05-02 04:36:11,360:INFO:_display_container: 2
2025-05-02 04:36:11,360:INFO:Lasso(random_state=1994)
2025-05-02 04:36:11,360:INFO:create_model() successfully completed......................................
2025-05-02 04:36:11,453:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:11,453:INFO:Creating metrics dataframe
2025-05-02 04:36:11,456:INFO:Initializing Ridge Regression
2025-05-02 04:36:11,456:INFO:Total runtime is 0.09877307812372843 minutes
2025-05-02 04:36:11,456:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:11,456:INFO:Initializing create_model()
2025-05-02 04:36:11,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:11,456:INFO:Checking exceptions
2025-05-02 04:36:11,456:INFO:Importing libraries
2025-05-02 04:36:11,456:INFO:Copying training dataset
2025-05-02 04:36:11,470:INFO:Defining folds
2025-05-02 04:36:11,470:INFO:Declaring metric variables
2025-05-02 04:36:11,470:INFO:Importing untrained model
2025-05-02 04:36:11,470:INFO:Ridge Regression Imported successfully
2025-05-02 04:36:11,470:INFO:Starting cross validation
2025-05-02 04:36:11,472:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:13,448:INFO:Calculating mean and std
2025-05-02 04:36:13,448:INFO:Creating metrics dataframe
2025-05-02 04:36:13,451:INFO:Uploading results into container
2025-05-02 04:36:13,452:INFO:Uploading model into container now
2025-05-02 04:36:13,452:INFO:_master_model_container: 3
2025-05-02 04:36:13,452:INFO:_display_container: 2
2025-05-02 04:36:13,453:INFO:Ridge(random_state=1994)
2025-05-02 04:36:13,453:INFO:create_model() successfully completed......................................
2025-05-02 04:36:13,562:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:13,563:INFO:Creating metrics dataframe
2025-05-02 04:36:13,567:INFO:Initializing Elastic Net
2025-05-02 04:36:13,567:INFO:Total runtime is 0.13395185867945353 minutes
2025-05-02 04:36:13,567:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:13,567:INFO:Initializing create_model()
2025-05-02 04:36:13,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:13,567:INFO:Checking exceptions
2025-05-02 04:36:13,567:INFO:Importing libraries
2025-05-02 04:36:13,567:INFO:Copying training dataset
2025-05-02 04:36:13,589:INFO:Defining folds
2025-05-02 04:36:13,589:INFO:Declaring metric variables
2025-05-02 04:36:13,590:INFO:Importing untrained model
2025-05-02 04:36:13,590:INFO:Elastic Net Imported successfully
2025-05-02 04:36:13,590:INFO:Starting cross validation
2025-05-02 04:36:13,592:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:15,580:INFO:Calculating mean and std
2025-05-02 04:36:15,580:INFO:Creating metrics dataframe
2025-05-02 04:36:15,582:INFO:Uploading results into container
2025-05-02 04:36:15,583:INFO:Uploading model into container now
2025-05-02 04:36:15,583:INFO:_master_model_container: 4
2025-05-02 04:36:15,583:INFO:_display_container: 2
2025-05-02 04:36:15,583:INFO:ElasticNet(random_state=1994)
2025-05-02 04:36:15,584:INFO:create_model() successfully completed......................................
2025-05-02 04:36:15,693:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:15,693:INFO:Creating metrics dataframe
2025-05-02 04:36:15,697:INFO:Initializing Least Angle Regression
2025-05-02 04:36:15,697:INFO:Total runtime is 0.1694649855295817 minutes
2025-05-02 04:36:15,698:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:15,698:INFO:Initializing create_model()
2025-05-02 04:36:15,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:15,698:INFO:Checking exceptions
2025-05-02 04:36:15,698:INFO:Importing libraries
2025-05-02 04:36:15,698:INFO:Copying training dataset
2025-05-02 04:36:15,720:INFO:Defining folds
2025-05-02 04:36:15,720:INFO:Declaring metric variables
2025-05-02 04:36:15,720:INFO:Importing untrained model
2025-05-02 04:36:15,720:INFO:Least Angle Regression Imported successfully
2025-05-02 04:36:15,721:INFO:Starting cross validation
2025-05-02 04:36:15,723:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:17,718:INFO:Calculating mean and std
2025-05-02 04:36:17,718:INFO:Creating metrics dataframe
2025-05-02 04:36:17,720:INFO:Uploading results into container
2025-05-02 04:36:17,721:INFO:Uploading model into container now
2025-05-02 04:36:17,722:INFO:_master_model_container: 5
2025-05-02 04:36:17,722:INFO:_display_container: 2
2025-05-02 04:36:17,722:INFO:Lars(random_state=1994)
2025-05-02 04:36:17,722:INFO:create_model() successfully completed......................................
2025-05-02 04:36:17,819:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:17,820:INFO:Creating metrics dataframe
2025-05-02 04:36:17,824:INFO:Initializing Lasso Least Angle Regression
2025-05-02 04:36:17,824:INFO:Total runtime is 0.20490297476450603 minutes
2025-05-02 04:36:17,824:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:17,824:INFO:Initializing create_model()
2025-05-02 04:36:17,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:17,824:INFO:Checking exceptions
2025-05-02 04:36:17,824:INFO:Importing libraries
2025-05-02 04:36:17,824:INFO:Copying training dataset
2025-05-02 04:36:17,853:INFO:Defining folds
2025-05-02 04:36:17,853:INFO:Declaring metric variables
2025-05-02 04:36:17,854:INFO:Importing untrained model
2025-05-02 04:36:17,855:INFO:Lasso Least Angle Regression Imported successfully
2025-05-02 04:36:17,855:INFO:Starting cross validation
2025-05-02 04:36:17,859:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:19,913:INFO:Calculating mean and std
2025-05-02 04:36:19,914:INFO:Creating metrics dataframe
2025-05-02 04:36:19,917:INFO:Uploading results into container
2025-05-02 04:36:19,917:INFO:Uploading model into container now
2025-05-02 04:36:19,918:INFO:_master_model_container: 6
2025-05-02 04:36:19,918:INFO:_display_container: 2
2025-05-02 04:36:19,918:INFO:LassoLars(random_state=1994)
2025-05-02 04:36:19,918:INFO:create_model() successfully completed......................................
2025-05-02 04:36:20,065:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:20,065:INFO:Creating metrics dataframe
2025-05-02 04:36:20,069:INFO:Initializing Orthogonal Matching Pursuit
2025-05-02 04:36:20,069:INFO:Total runtime is 0.242330010732015 minutes
2025-05-02 04:36:20,070:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:20,070:INFO:Initializing create_model()
2025-05-02 04:36:20,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:20,070:INFO:Checking exceptions
2025-05-02 04:36:20,070:INFO:Importing libraries
2025-05-02 04:36:20,070:INFO:Copying training dataset
2025-05-02 04:36:20,095:INFO:Defining folds
2025-05-02 04:36:20,095:INFO:Declaring metric variables
2025-05-02 04:36:20,095:INFO:Importing untrained model
2025-05-02 04:36:20,095:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-02 04:36:20,096:INFO:Starting cross validation
2025-05-02 04:36:20,098:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:21,983:INFO:Calculating mean and std
2025-05-02 04:36:21,983:INFO:Creating metrics dataframe
2025-05-02 04:36:21,985:INFO:Uploading results into container
2025-05-02 04:36:21,985:INFO:Uploading model into container now
2025-05-02 04:36:21,986:INFO:_master_model_container: 7
2025-05-02 04:36:21,986:INFO:_display_container: 2
2025-05-02 04:36:21,986:INFO:OrthogonalMatchingPursuit()
2025-05-02 04:36:21,986:INFO:create_model() successfully completed......................................
2025-05-02 04:36:22,076:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:22,076:INFO:Creating metrics dataframe
2025-05-02 04:36:22,079:INFO:Initializing Bayesian Ridge
2025-05-02 04:36:22,080:INFO:Total runtime is 0.275834592183431 minutes
2025-05-02 04:36:22,080:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:22,080:INFO:Initializing create_model()
2025-05-02 04:36:22,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:22,080:INFO:Checking exceptions
2025-05-02 04:36:22,080:INFO:Importing libraries
2025-05-02 04:36:22,080:INFO:Copying training dataset
2025-05-02 04:36:22,103:INFO:Defining folds
2025-05-02 04:36:22,103:INFO:Declaring metric variables
2025-05-02 04:36:22,103:INFO:Importing untrained model
2025-05-02 04:36:22,103:INFO:Bayesian Ridge Imported successfully
2025-05-02 04:36:22,104:INFO:Starting cross validation
2025-05-02 04:36:22,106:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:23,798:INFO:Calculating mean and std
2025-05-02 04:36:23,798:INFO:Creating metrics dataframe
2025-05-02 04:36:23,801:INFO:Uploading results into container
2025-05-02 04:36:23,802:INFO:Uploading model into container now
2025-05-02 04:36:23,803:INFO:_master_model_container: 8
2025-05-02 04:36:23,803:INFO:_display_container: 2
2025-05-02 04:36:23,803:INFO:BayesianRidge()
2025-05-02 04:36:23,803:INFO:create_model() successfully completed......................................
2025-05-02 04:36:23,916:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:23,916:INFO:Creating metrics dataframe
2025-05-02 04:36:23,920:INFO:Initializing Passive Aggressive Regressor
2025-05-02 04:36:23,920:INFO:Total runtime is 0.3065051476160685 minutes
2025-05-02 04:36:23,920:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:23,920:INFO:Initializing create_model()
2025-05-02 04:36:23,920:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:23,920:INFO:Checking exceptions
2025-05-02 04:36:23,921:INFO:Importing libraries
2025-05-02 04:36:23,921:INFO:Copying training dataset
2025-05-02 04:36:23,942:INFO:Defining folds
2025-05-02 04:36:23,943:INFO:Declaring metric variables
2025-05-02 04:36:23,943:INFO:Importing untrained model
2025-05-02 04:36:23,943:INFO:Passive Aggressive Regressor Imported successfully
2025-05-02 04:36:23,944:INFO:Starting cross validation
2025-05-02 04:36:23,945:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:25,967:INFO:Calculating mean and std
2025-05-02 04:36:25,967:INFO:Creating metrics dataframe
2025-05-02 04:36:25,969:INFO:Uploading results into container
2025-05-02 04:36:25,970:INFO:Uploading model into container now
2025-05-02 04:36:25,970:INFO:_master_model_container: 9
2025-05-02 04:36:25,970:INFO:_display_container: 2
2025-05-02 04:36:25,970:INFO:PassiveAggressiveRegressor(random_state=1994)
2025-05-02 04:36:25,970:INFO:create_model() successfully completed......................................
2025-05-02 04:36:26,069:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:26,070:INFO:Creating metrics dataframe
2025-05-02 04:36:26,073:INFO:Initializing Huber Regressor
2025-05-02 04:36:26,073:INFO:Total runtime is 0.3423937638600667 minutes
2025-05-02 04:36:26,073:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:26,074:INFO:Initializing create_model()
2025-05-02 04:36:26,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:26,074:INFO:Checking exceptions
2025-05-02 04:36:26,074:INFO:Importing libraries
2025-05-02 04:36:26,074:INFO:Copying training dataset
2025-05-02 04:36:26,094:INFO:Defining folds
2025-05-02 04:36:26,094:INFO:Declaring metric variables
2025-05-02 04:36:26,094:INFO:Importing untrained model
2025-05-02 04:36:26,094:INFO:Huber Regressor Imported successfully
2025-05-02 04:36:26,095:INFO:Starting cross validation
2025-05-02 04:36:26,096:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:28,483:INFO:Calculating mean and std
2025-05-02 04:36:28,484:INFO:Creating metrics dataframe
2025-05-02 04:36:28,486:INFO:Uploading results into container
2025-05-02 04:36:28,486:INFO:Uploading model into container now
2025-05-02 04:36:28,487:INFO:_master_model_container: 10
2025-05-02 04:36:28,487:INFO:_display_container: 2
2025-05-02 04:36:28,487:INFO:HuberRegressor()
2025-05-02 04:36:28,487:INFO:create_model() successfully completed......................................
2025-05-02 04:36:28,578:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:28,578:INFO:Creating metrics dataframe
2025-05-02 04:36:28,582:INFO:Initializing K Neighbors Regressor
2025-05-02 04:36:28,582:INFO:Total runtime is 0.38420406182607014 minutes
2025-05-02 04:36:28,582:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:28,582:INFO:Initializing create_model()
2025-05-02 04:36:28,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:28,582:INFO:Checking exceptions
2025-05-02 04:36:28,582:INFO:Importing libraries
2025-05-02 04:36:28,583:INFO:Copying training dataset
2025-05-02 04:36:28,603:INFO:Defining folds
2025-05-02 04:36:28,603:INFO:Declaring metric variables
2025-05-02 04:36:28,603:INFO:Importing untrained model
2025-05-02 04:36:28,603:INFO:K Neighbors Regressor Imported successfully
2025-05-02 04:36:28,604:INFO:Starting cross validation
2025-05-02 04:36:28,605:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:31,011:INFO:Calculating mean and std
2025-05-02 04:36:31,012:INFO:Creating metrics dataframe
2025-05-02 04:36:31,014:INFO:Uploading results into container
2025-05-02 04:36:31,014:INFO:Uploading model into container now
2025-05-02 04:36:31,015:INFO:_master_model_container: 11
2025-05-02 04:36:31,015:INFO:_display_container: 2
2025-05-02 04:36:31,015:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-02 04:36:31,015:INFO:create_model() successfully completed......................................
2025-05-02 04:36:31,109:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:31,109:INFO:Creating metrics dataframe
2025-05-02 04:36:31,113:INFO:Initializing Decision Tree Regressor
2025-05-02 04:36:31,113:INFO:Total runtime is 0.42639334201812745 minutes
2025-05-02 04:36:31,113:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:31,114:INFO:Initializing create_model()
2025-05-02 04:36:31,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:31,114:INFO:Checking exceptions
2025-05-02 04:36:31,114:INFO:Importing libraries
2025-05-02 04:36:31,114:INFO:Copying training dataset
2025-05-02 04:36:31,135:INFO:Defining folds
2025-05-02 04:36:31,135:INFO:Declaring metric variables
2025-05-02 04:36:31,135:INFO:Importing untrained model
2025-05-02 04:36:31,135:INFO:Decision Tree Regressor Imported successfully
2025-05-02 04:36:31,136:INFO:Starting cross validation
2025-05-02 04:36:31,137:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:33,428:INFO:Calculating mean and std
2025-05-02 04:36:33,429:INFO:Creating metrics dataframe
2025-05-02 04:36:33,431:INFO:Uploading results into container
2025-05-02 04:36:33,431:INFO:Uploading model into container now
2025-05-02 04:36:33,432:INFO:_master_model_container: 12
2025-05-02 04:36:33,432:INFO:_display_container: 2
2025-05-02 04:36:33,432:INFO:DecisionTreeRegressor(random_state=1994)
2025-05-02 04:36:33,432:INFO:create_model() successfully completed......................................
2025-05-02 04:36:33,537:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:33,537:INFO:Creating metrics dataframe
2025-05-02 04:36:33,540:INFO:Initializing Random Forest Regressor
2025-05-02 04:36:33,540:INFO:Total runtime is 0.46684674819310507 minutes
2025-05-02 04:36:33,541:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:33,541:INFO:Initializing create_model()
2025-05-02 04:36:33,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:33,541:INFO:Checking exceptions
2025-05-02 04:36:33,541:INFO:Importing libraries
2025-05-02 04:36:33,541:INFO:Copying training dataset
2025-05-02 04:36:33,560:INFO:Defining folds
2025-05-02 04:36:33,560:INFO:Declaring metric variables
2025-05-02 04:36:33,560:INFO:Importing untrained model
2025-05-02 04:36:33,561:INFO:Random Forest Regressor Imported successfully
2025-05-02 04:36:33,561:INFO:Starting cross validation
2025-05-02 04:36:33,563:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:36,084:INFO:Calculating mean and std
2025-05-02 04:36:36,085:INFO:Creating metrics dataframe
2025-05-02 04:36:36,087:INFO:Uploading results into container
2025-05-02 04:36:36,087:INFO:Uploading model into container now
2025-05-02 04:36:36,088:INFO:_master_model_container: 13
2025-05-02 04:36:36,088:INFO:_display_container: 2
2025-05-02 04:36:36,088:INFO:RandomForestRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:36:36,088:INFO:create_model() successfully completed......................................
2025-05-02 04:36:36,179:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:36,179:INFO:Creating metrics dataframe
2025-05-02 04:36:36,182:INFO:Initializing Extra Trees Regressor
2025-05-02 04:36:36,182:INFO:Total runtime is 0.5108702659606934 minutes
2025-05-02 04:36:36,182:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:36,182:INFO:Initializing create_model()
2025-05-02 04:36:36,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:36,183:INFO:Checking exceptions
2025-05-02 04:36:36,183:INFO:Importing libraries
2025-05-02 04:36:36,183:INFO:Copying training dataset
2025-05-02 04:36:36,199:INFO:Defining folds
2025-05-02 04:36:36,199:INFO:Declaring metric variables
2025-05-02 04:36:36,199:INFO:Importing untrained model
2025-05-02 04:36:36,199:INFO:Extra Trees Regressor Imported successfully
2025-05-02 04:36:36,200:INFO:Starting cross validation
2025-05-02 04:36:36,201:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:38,795:INFO:Calculating mean and std
2025-05-02 04:36:38,795:INFO:Creating metrics dataframe
2025-05-02 04:36:38,797:INFO:Uploading results into container
2025-05-02 04:36:38,798:INFO:Uploading model into container now
2025-05-02 04:36:38,798:INFO:_master_model_container: 14
2025-05-02 04:36:38,798:INFO:_display_container: 2
2025-05-02 04:36:38,799:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:36:38,799:INFO:create_model() successfully completed......................................
2025-05-02 04:36:38,894:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:38,894:INFO:Creating metrics dataframe
2025-05-02 04:36:38,897:INFO:Initializing AdaBoost Regressor
2025-05-02 04:36:38,897:INFO:Total runtime is 0.5561270793279013 minutes
2025-05-02 04:36:38,897:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:38,898:INFO:Initializing create_model()
2025-05-02 04:36:38,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:38,898:INFO:Checking exceptions
2025-05-02 04:36:38,898:INFO:Importing libraries
2025-05-02 04:36:38,898:INFO:Copying training dataset
2025-05-02 04:36:38,917:INFO:Defining folds
2025-05-02 04:36:38,917:INFO:Declaring metric variables
2025-05-02 04:36:38,918:INFO:Importing untrained model
2025-05-02 04:36:38,918:INFO:AdaBoost Regressor Imported successfully
2025-05-02 04:36:38,918:INFO:Starting cross validation
2025-05-02 04:36:38,920:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:42,112:INFO:Calculating mean and std
2025-05-02 04:36:42,113:INFO:Creating metrics dataframe
2025-05-02 04:36:42,115:INFO:Uploading results into container
2025-05-02 04:36:42,116:INFO:Uploading model into container now
2025-05-02 04:36:42,116:INFO:_master_model_container: 15
2025-05-02 04:36:42,116:INFO:_display_container: 2
2025-05-02 04:36:42,116:INFO:AdaBoostRegressor(random_state=1994)
2025-05-02 04:36:42,116:INFO:create_model() successfully completed......................................
2025-05-02 04:36:42,215:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:42,215:INFO:Creating metrics dataframe
2025-05-02 04:36:42,219:INFO:Initializing Gradient Boosting Regressor
2025-05-02 04:36:42,219:INFO:Total runtime is 0.6114979624748231 minutes
2025-05-02 04:36:42,220:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:42,220:INFO:Initializing create_model()
2025-05-02 04:36:42,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:42,220:INFO:Checking exceptions
2025-05-02 04:36:42,220:INFO:Importing libraries
2025-05-02 04:36:42,220:INFO:Copying training dataset
2025-05-02 04:36:42,241:INFO:Defining folds
2025-05-02 04:36:42,241:INFO:Declaring metric variables
2025-05-02 04:36:42,242:INFO:Importing untrained model
2025-05-02 04:36:42,242:INFO:Gradient Boosting Regressor Imported successfully
2025-05-02 04:36:42,243:INFO:Starting cross validation
2025-05-02 04:36:42,244:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:36:47,041:INFO:Calculating mean and std
2025-05-02 04:36:47,041:INFO:Creating metrics dataframe
2025-05-02 04:36:47,043:INFO:Uploading results into container
2025-05-02 04:36:47,043:INFO:Uploading model into container now
2025-05-02 04:36:47,044:INFO:_master_model_container: 16
2025-05-02 04:36:47,044:INFO:_display_container: 2
2025-05-02 04:36:47,044:INFO:GradientBoostingRegressor(random_state=1994)
2025-05-02 04:36:47,044:INFO:create_model() successfully completed......................................
2025-05-02 04:36:47,139:INFO:SubProcess create_model() end ==================================
2025-05-02 04:36:47,139:INFO:Creating metrics dataframe
2025-05-02 04:36:47,143:INFO:Initializing Light Gradient Boosting Machine
2025-05-02 04:36:47,143:INFO:Total runtime is 0.693558712800344 minutes
2025-05-02 04:36:47,143:INFO:SubProcess create_model() called ==================================
2025-05-02 04:36:47,143:INFO:Initializing create_model()
2025-05-02 04:36:47,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:36:47,144:INFO:Checking exceptions
2025-05-02 04:36:47,144:INFO:Importing libraries
2025-05-02 04:36:47,144:INFO:Copying training dataset
2025-05-02 04:36:47,164:INFO:Defining folds
2025-05-02 04:36:47,164:INFO:Declaring metric variables
2025-05-02 04:36:47,164:INFO:Importing untrained model
2025-05-02 04:36:47,165:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-02 04:36:47,165:INFO:Starting cross validation
2025-05-02 04:36:47,167:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:50:11,069:INFO:Calculating mean and std
2025-05-02 04:50:11,070:INFO:Creating metrics dataframe
2025-05-02 04:50:11,073:INFO:Uploading results into container
2025-05-02 04:50:11,074:INFO:Uploading model into container now
2025-05-02 04:50:11,074:INFO:_master_model_container: 17
2025-05-02 04:50:11,074:INFO:_display_container: 2
2025-05-02 04:50:11,075:INFO:LGBMRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:50:11,075:INFO:create_model() successfully completed......................................
2025-05-02 04:50:11,186:INFO:SubProcess create_model() end ==================================
2025-05-02 04:50:11,187:INFO:Creating metrics dataframe
2025-05-02 04:50:11,189:INFO:Initializing Dummy Regressor
2025-05-02 04:50:11,189:INFO:Total runtime is 14.094324906667074 minutes
2025-05-02 04:50:11,189:INFO:SubProcess create_model() called ==================================
2025-05-02 04:50:11,189:INFO:Initializing create_model()
2025-05-02 04:50:11,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0427e99510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:50:11,189:INFO:Checking exceptions
2025-05-02 04:50:11,189:INFO:Importing libraries
2025-05-02 04:50:11,190:INFO:Copying training dataset
2025-05-02 04:50:11,202:INFO:Defining folds
2025-05-02 04:50:11,202:INFO:Declaring metric variables
2025-05-02 04:50:11,202:INFO:Importing untrained model
2025-05-02 04:50:11,202:INFO:Dummy Regressor Imported successfully
2025-05-02 04:50:11,202:INFO:Starting cross validation
2025-05-02 04:50:11,203:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2025-05-02 04:50:12,607:INFO:Calculating mean and std
2025-05-02 04:50:12,608:INFO:Creating metrics dataframe
2025-05-02 04:50:12,610:INFO:Uploading results into container
2025-05-02 04:50:12,611:INFO:Uploading model into container now
2025-05-02 04:50:12,611:INFO:_master_model_container: 18
2025-05-02 04:50:12,611:INFO:_display_container: 2
2025-05-02 04:50:12,612:INFO:DummyRegressor()
2025-05-02 04:50:12,612:INFO:create_model() successfully completed......................................
2025-05-02 04:50:12,701:INFO:SubProcess create_model() end ==================================
2025-05-02 04:50:12,701:INFO:Creating metrics dataframe
2025-05-02 04:50:12,705:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-05-02 04:50:12,706:INFO:Initializing create_model()
2025-05-02 04:50:12,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:50:12,706:INFO:Checking exceptions
2025-05-02 04:50:12,707:INFO:Importing libraries
2025-05-02 04:50:12,707:INFO:Copying training dataset
2025-05-02 04:50:12,722:INFO:Defining folds
2025-05-02 04:50:12,722:INFO:Declaring metric variables
2025-05-02 04:50:12,722:INFO:Importing untrained model
2025-05-02 04:50:12,722:INFO:Declaring custom model
2025-05-02 04:50:12,723:INFO:Random Forest Regressor Imported successfully
2025-05-02 04:50:12,724:INFO:Cross validation set to False
2025-05-02 04:50:12,724:INFO:Fitting Model
2025-05-02 04:50:18,162:INFO:RandomForestRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:50:18,162:INFO:create_model() successfully completed......................................
2025-05-02 04:50:18,349:INFO:Creating Dashboard logs
2025-05-02 04:50:18,349:INFO:Model: Random Forest Regressor
2025-05-02 04:50:18,374:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1994, 'verbose': 0, 'warm_start': False}
2025-05-02 04:50:18,420:INFO:Initializing predict_model()
2025-05-02 04:50:18,420:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f05796edea0>)
2025-05-02 04:50:18,420:INFO:Checking exceptions
2025-05-02 04:50:18,420:INFO:Preloading libraries
2025-05-02 04:50:19,008:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-02 04:50:19,128:INFO:SubProcess plot_model() called ==================================
2025-05-02 04:50:19,128:INFO:Initializing plot_model()
2025-05-02 04:50:19,128:INFO:plot_model(plot=residuals, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxp7phjpe, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:19,128:INFO:Checking exceptions
2025-05-02 04:50:19,175:INFO:Preloading libraries
2025-05-02 04:50:19,462:INFO:Copying training dataset
2025-05-02 04:50:19,463:INFO:Plot type: residuals
2025-05-02 04:50:20,161:INFO:Fitting Model
2025-05-02 04:50:20,164:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-02 04:50:21,168:INFO:Scoring test/hold-out set
2025-05-02 04:50:21,686:INFO:Saving '/tmp/tmpxp7phjpe/Residuals.png'
2025-05-02 04:50:21,716:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,719:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,720:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,720:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,721:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,721:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,722:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,722:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,723:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,728:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,729:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,731:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,732:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,742:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,743:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,743:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,750:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,769:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,771:WARNING:findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.
2025-05-02 04:50:21,771:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,825:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,849:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,849:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,866:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,866:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,867:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,867:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,868:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,869:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,872:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,875:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,922:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,922:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,955:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,956:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,993:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:21,993:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,024:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,024:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,025:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,025:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,025:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,025:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,026:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,026:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,026:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,028:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,029:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,029:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,029:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,032:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,032:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,032:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,033:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,034:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,034:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,035:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,036:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,038:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,039:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,041:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,042:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,042:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,043:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,043:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,044:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,044:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,045:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,051:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,114:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,115:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,119:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,136:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,137:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,150:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,151:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,151:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,152:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,152:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,153:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,155:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,155:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,156:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,158:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,158:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,160:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,161:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,162:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,162:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,163:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,163:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,164:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,164:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:22,234:INFO:Visual Rendered Successfully
2025-05-02 04:50:22,415:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:22,428:INFO:Initializing plot_model()
2025-05-02 04:50:22,428:INFO:plot_model(plot=error, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxp7phjpe, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:22,428:INFO:Checking exceptions
2025-05-02 04:50:22,458:INFO:Preloading libraries
2025-05-02 04:50:22,620:INFO:Copying training dataset
2025-05-02 04:50:22,620:INFO:Plot type: error
2025-05-02 04:50:22,810:INFO:Fitting Model
2025-05-02 04:50:22,811:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-02 04:50:22,811:INFO:Scoring test/hold-out set
2025-05-02 04:50:25,099:WARNING:2025/05/02 04:50:25 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID e0323c77f38f4eaa976573c9c9cf530e. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'n_jobs\' was already logged with value=\'-1\' for run ID=\'e0323c77f38f4eaa976573c9c9cf530e\'. Attempted logging new value \'None\'.")]')]
2025-05-02 04:50:25,104:INFO:Saving '/tmp/tmpxp7phjpe/Prediction Error.png'
2025-05-02 04:50:25,120:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,120:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,121:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,121:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,121:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,122:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,122:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,123:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,123:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,126:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,127:WARNING:findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.
2025-05-02 04:50:25,128:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,132:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,132:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,166:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,170:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,171:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,171:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,171:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,182:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,182:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,183:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,192:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,193:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,193:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,194:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,194:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,195:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,195:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,199:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,200:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,224:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,225:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,225:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,240:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,241:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,241:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,274:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,274:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,275:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,288:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,289:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,289:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,290:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,290:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,290:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,291:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,291:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,292:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,295:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,297:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,298:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,302:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,303:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,304:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,305:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,305:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,306:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,307:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,308:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,316:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,316:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,317:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,318:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,319:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,319:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,320:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,321:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,354:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,355:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,360:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,360:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,361:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,361:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,371:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,371:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,372:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,381:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,382:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,382:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,383:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,383:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,384:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,384:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,389:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,390:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,390:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,391:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,440:INFO:Visual Rendered Successfully
2025-05-02 04:50:25,609:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:25,625:INFO:Initializing plot_model()
2025-05-02 04:50:25,625:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpxp7phjpe, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:25,625:INFO:Checking exceptions
2025-05-02 04:50:25,674:INFO:Preloading libraries
2025-05-02 04:50:25,857:INFO:Copying training dataset
2025-05-02 04:50:25,857:INFO:Plot type: feature
2025-05-02 04:50:25,858:WARNING:No coef_ found. Trying feature_importances_
2025-05-02 04:50:25,985:INFO:Saving '/tmp/tmpxp7phjpe/Feature Importance.png'
2025-05-02 04:50:25,988:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,988:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,989:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,989:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,990:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,990:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,991:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,991:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,992:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,992:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,992:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,995:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,995:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,996:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:25,996:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,006:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,007:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,007:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,008:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,008:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,009:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,009:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,016:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,070:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,070:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,071:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,071:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,072:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,072:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,073:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,073:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,073:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,074:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,074:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,077:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,077:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,078:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,078:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,081:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,081:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,081:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,082:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,082:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,083:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,083:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,084:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,085:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,085:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,086:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,087:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,088:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,089:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,092:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,093:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,096:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,097:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,098:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,099:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,099:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,100:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,101:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,102:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,103:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,103:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,107:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,109:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:26,134:INFO:Visual Rendered Successfully
2025-05-02 04:50:26,272:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:26,289:INFO:SubProcess plot_model() end ==================================
2025-05-02 04:50:27,373:INFO:Creating Dashboard logs
2025-05-02 04:50:27,374:INFO:Model: Extra Trees Regressor
2025-05-02 04:50:27,393:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1994, 'verbose': 0, 'warm_start': False}
2025-05-02 04:50:27,560:INFO:Creating Dashboard logs
2025-05-02 04:50:27,562:INFO:Model: Light Gradient Boosting Machine
2025-05-02 04:50:27,582:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1994, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-05-02 04:50:27,751:INFO:Creating Dashboard logs
2025-05-02 04:50:27,751:INFO:Model: K Neighbors Regressor
2025-05-02 04:50:27,770:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-05-02 04:50:27,941:INFO:Creating Dashboard logs
2025-05-02 04:50:27,942:INFO:Model: Decision Tree Regressor
2025-05-02 04:50:27,962:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 1994, 'splitter': 'best'}
2025-05-02 04:50:28,203:INFO:Creating Dashboard logs
2025-05-02 04:50:28,204:INFO:Model: Gradient Boosting Regressor
2025-05-02 04:50:28,218:INFO:Logged params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 1994, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-05-02 04:50:28,365:INFO:Creating Dashboard logs
2025-05-02 04:50:28,365:INFO:Model: Ridge Regression
2025-05-02 04:50:28,379:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 1994, 'solver': 'auto', 'tol': 0.0001}
2025-05-02 04:50:28,522:INFO:Creating Dashboard logs
2025-05-02 04:50:28,522:INFO:Model: Linear Regression
2025-05-02 04:50:28,536:INFO:Logged params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': -1, 'positive': False}
2025-05-02 04:50:28,674:INFO:Creating Dashboard logs
2025-05-02 04:50:28,674:INFO:Model: Least Angle Regression
2025-05-02 04:50:28,688:INFO:Logged params: {'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'n_nonzero_coefs': 500, 'precompute': 'auto', 'random_state': 1994, 'verbose': False}
2025-05-02 04:50:28,829:INFO:Creating Dashboard logs
2025-05-02 04:50:28,829:INFO:Model: Bayesian Ridge
2025-05-02 04:50:28,843:INFO:Logged params: {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_init': None, 'compute_score': False, 'copy_X': True, 'fit_intercept': True, 'lambda_1': 1e-06, 'lambda_2': 1e-06, 'lambda_init': None, 'max_iter': None, 'n_iter': 'deprecated', 'tol': 0.001, 'verbose': False}
2025-05-02 04:50:28,992:INFO:Creating Dashboard logs
2025-05-02 04:50:28,993:INFO:Model: Huber Regressor
2025-05-02 04:50:29,010:INFO:Logged params: {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}
2025-05-02 04:50:29,171:INFO:Creating Dashboard logs
2025-05-02 04:50:29,171:INFO:Model: Lasso Regression
2025-05-02 04:50:29,185:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 1994, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-05-02 04:50:29,326:INFO:Creating Dashboard logs
2025-05-02 04:50:29,326:INFO:Model: Lasso Least Angle Regression
2025-05-02 04:50:29,339:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446049250313e-16, 'fit_intercept': True, 'fit_path': True, 'jitter': None, 'max_iter': 500, 'positive': False, 'precompute': 'auto', 'random_state': 1994, 'verbose': False}
2025-05-02 04:50:29,480:INFO:Creating Dashboard logs
2025-05-02 04:50:29,480:INFO:Model: Elastic Net
2025-05-02 04:50:29,494:INFO:Logged params: {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 1994, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}
2025-05-02 04:50:29,636:INFO:Creating Dashboard logs
2025-05-02 04:50:29,636:INFO:Model: AdaBoost Regressor
2025-05-02 04:50:29,651:INFO:Logged params: {'estimator': None, 'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50, 'random_state': 1994}
2025-05-02 04:50:29,792:INFO:Creating Dashboard logs
2025-05-02 04:50:29,793:INFO:Model: Orthogonal Matching Pursuit
2025-05-02 04:50:29,806:INFO:Logged params: {'fit_intercept': True, 'n_nonzero_coefs': None, 'precompute': 'auto', 'tol': None}
2025-05-02 04:50:29,947:INFO:Creating Dashboard logs
2025-05-02 04:50:29,948:INFO:Model: Passive Aggressive Regressor
2025-05-02 04:50:29,961:INFO:Logged params: {'C': 1.0, 'average': False, 'early_stopping': False, 'epsilon': 0.1, 'fit_intercept': True, 'loss': 'epsilon_insensitive', 'max_iter': 1000, 'n_iter_no_change': 5, 'random_state': 1994, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-05-02 04:50:30,112:INFO:Creating Dashboard logs
2025-05-02 04:50:30,112:INFO:Model: Dummy Regressor
2025-05-02 04:50:30,126:INFO:Logged params: {'constant': None, 'quantile': None, 'strategy': 'mean'}
2025-05-02 04:50:30,262:INFO:_master_model_container: 18
2025-05-02 04:50:30,262:INFO:_display_container: 2
2025-05-02 04:50:30,262:INFO:RandomForestRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:50:30,262:INFO:compare_models() successfully completed......................................
2025-05-02 04:50:30,263:INFO:Initializing finalize_model()
2025-05-02 04:50:30,263:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-05-02 04:50:30,263:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=1994)
2025-05-02 04:50:30,272:INFO:Initializing create_model()
2025-05-02 04:50:30,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=1994), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-05-02 04:50:30,272:INFO:Checking exceptions
2025-05-02 04:50:30,272:INFO:Importing libraries
2025-05-02 04:50:30,272:INFO:Copying training dataset
2025-05-02 04:50:30,275:INFO:Defining folds
2025-05-02 04:50:30,275:INFO:Declaring metric variables
2025-05-02 04:50:30,275:INFO:Importing untrained model
2025-05-02 04:50:30,275:INFO:Declaring custom model
2025-05-02 04:50:30,276:INFO:Random Forest Regressor Imported successfully
2025-05-02 04:50:30,277:INFO:Cross validation set to False
2025-05-02 04:50:30,277:INFO:Fitting Model
2025-05-02 04:50:36,034:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))])
2025-05-02 04:50:36,034:INFO:create_model() successfully completed......................................
2025-05-02 04:50:36,199:INFO:Creating Dashboard logs
2025-05-02 04:50:36,200:INFO:Model: Random Forest Regressor
2025-05-02 04:50:36,216:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 1994, 'verbose': 0, 'warm_start': False}
2025-05-02 04:50:36,240:INFO:SubProcess plot_model() called ==================================
2025-05-02 04:50:36,250:INFO:Initializing plot_model()
2025-05-02 04:50:36,250:INFO:plot_model(plot=residuals, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpgr6j1qv4, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:36,250:INFO:Checking exceptions
2025-05-02 04:50:36,303:INFO:Preloading libraries
2025-05-02 04:50:36,666:INFO:Copying training dataset
2025-05-02 04:50:36,666:INFO:Plot type: residuals
2025-05-02 04:50:36,926:INFO:Fitting Model
2025-05-02 04:50:36,927:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-02 04:50:37,756:INFO:Scoring test/hold-out set
2025-05-02 04:50:38,282:INFO:Saving '/tmp/tmpgr6j1qv4/Residuals.png'
2025-05-02 04:50:38,300:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,300:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,301:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,301:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,301:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,302:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,302:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,303:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,305:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,306:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,306:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,307:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,314:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,315:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,315:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,316:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,321:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,337:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,342:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,371:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,371:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,391:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,392:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,393:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,393:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,394:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,395:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,399:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,402:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,457:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,457:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,498:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,499:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,547:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,548:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,588:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,588:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,589:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,589:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,589:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,590:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,590:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,590:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,593:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,593:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,594:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,594:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,597:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,598:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,598:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,599:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,600:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,600:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,601:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,602:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,603:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,606:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,607:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,610:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,611:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,612:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,612:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,613:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,614:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,614:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,618:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,704:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,706:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,711:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,740:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,740:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,761:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,761:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,762:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,762:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,763:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,764:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,767:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,768:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,769:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,771:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,772:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,775:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,776:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,777:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,778:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,778:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,779:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,780:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:38,887:INFO:Visual Rendered Successfully
2025-05-02 04:50:39,123:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:39,173:INFO:Initializing plot_model()
2025-05-02 04:50:39,173:INFO:plot_model(plot=error, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpgr6j1qv4, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:39,173:INFO:Checking exceptions
2025-05-02 04:50:39,231:INFO:Preloading libraries
2025-05-02 04:50:39,625:INFO:Copying training dataset
2025-05-02 04:50:39,625:INFO:Plot type: error
2025-05-02 04:50:39,890:INFO:Fitting Model
2025-05-02 04:50:39,891:WARNING:/home/juansmartinez/Documents/thesis/venv/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-02 04:50:39,892:INFO:Scoring test/hold-out set
2025-05-02 04:50:42,114:WARNING:2025/05/02 04:50:42 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID a69b902d571241f8830f6f2f777e9e27. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'n_jobs\' was already logged with value=\'-1\' for run ID=\'a69b902d571241f8830f6f2f777e9e27\'. Attempted logging new value \'None\'.")]')]
2025-05-02 04:50:42,121:INFO:Saving '/tmp/tmpgr6j1qv4/Prediction Error.png'
2025-05-02 04:50:42,142:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,142:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,143:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,144:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,144:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,145:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,145:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,146:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,146:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,150:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,154:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,154:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,208:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,214:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,214:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,215:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,216:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,230:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,230:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,231:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,244:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,245:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,245:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,246:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,247:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,247:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,248:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,253:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,255:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,288:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,289:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,289:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,308:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,309:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,310:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,353:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,354:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,354:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,372:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,373:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,373:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,374:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,374:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,375:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,375:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,376:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,376:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,380:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,385:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,385:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,391:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,392:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,393:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,394:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,395:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,396:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,397:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,398:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,409:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,410:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,411:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,412:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,413:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,414:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,415:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,416:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,459:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,461:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,467:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,468:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,468:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,469:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,487:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,487:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,488:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,501:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,502:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,502:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,503:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,504:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,504:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,505:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,511:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,512:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,513:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,514:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:42,579:INFO:Visual Rendered Successfully
2025-05-02 04:50:42,865:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:42,918:INFO:Initializing plot_model()
2025-05-02 04:50:42,918:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpgr6j1qv4, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f042d05f9d0>, system=False)
2025-05-02 04:50:42,919:INFO:Checking exceptions
2025-05-02 04:50:42,988:INFO:Preloading libraries
2025-05-02 04:50:43,500:INFO:Copying training dataset
2025-05-02 04:50:43,501:INFO:Plot type: feature
2025-05-02 04:50:43,502:WARNING:No coef_ found. Trying feature_importances_
2025-05-02 04:50:43,687:INFO:Saving '/tmp/tmpgr6j1qv4/Feature Importance.png'
2025-05-02 04:50:43,691:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,691:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,692:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,692:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,693:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,694:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,694:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,695:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,695:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,696:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,696:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,700:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,700:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,701:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,702:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,715:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,715:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,716:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,716:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,717:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,718:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,718:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,727:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,802:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,803:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,803:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,804:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,804:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,805:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,805:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,806:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,807:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,807:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,808:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,811:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,812:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,813:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,813:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,816:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,817:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,818:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,818:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,819:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,819:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,820:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,821:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,822:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,823:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,824:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,825:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,826:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,827:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,833:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,834:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,838:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,840:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,841:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,842:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,843:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,844:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,845:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,846:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,847:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,848:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,852:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,855:WARNING:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif
2025-05-02 04:50:43,888:INFO:Visual Rendered Successfully
2025-05-02 04:50:44,063:INFO:plot_model() successfully completed......................................
2025-05-02 04:50:44,099:INFO:SubProcess plot_model() end ==================================
2025-05-02 04:50:45,994:INFO:_master_model_container: 18
2025-05-02 04:50:45,994:INFO:_display_container: 2
2025-05-02 04:50:46,008:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))])
2025-05-02 04:50:46,008:INFO:finalize_model() successfully completed......................................
2025-05-02 04:50:46,155:INFO:Initializing save_model()
2025-05-02 04:50:46,155:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))]), model_name=results/models_results/auto_ml_wo_time_top_3__log=True__out=False__nor=True__mul=False__pca=False/best_models/pycaret_best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleI...
                                    transformer=OneHotEncoder(cols=['state_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-02 04:50:46,155:INFO:Adding model into prep_pipe
2025-05-02 04:50:46,155:WARNING:Only Model saved as it was a pipeline.
2025-05-02 04:50:46,622:INFO:results/models_results/auto_ml_wo_time_top_3__log=True__out=False__nor=True__mul=False__pca=False/best_models/pycaret_best_model.pkl saved in current working directory
2025-05-02 04:50:46,632:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['latitude', 'longitude', 'TMAX',
                                             'TMIN', 'phh2o', 'ocd', 'cec',
                                             'sand', 'silt', 'clay', 'PRCP',
                                             'SMS_-8', 'TAVG', 'WS10M',
                                             'RH2M'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['state_name', 'county_name'],
                                    transformer=SimpleImputer(stra...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['county_name'],
                                    transformer=TargetEncoder(cols=['county_name'],
                                                              handle_missing='return_nan'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=1994))])
2025-05-02 04:50:46,632:INFO:save_model() successfully completed......................................
